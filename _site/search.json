[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "POSTS ✏️",
    "section": "",
    "text": "Hands-on DATAVIZ + ML + DL\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nr에서 Spinner로 만드는 Graph Net\n\n\n\n\n\n\nR package\n\n\nGNN\n\n\n\nR아두면 쓸데있는 패키지 이야기 05 Spinner package\n\n\n\n\n\n2023/04/03\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\n그래프 신경망\n\n\n\n\n\n\nGNN\n\n\nGRAPH\n\n\nTRANSLATION\n\n\n\n[번역] A Gentle Introduction to Graph Neural Networks ③\n\n\n\n\n\n2023/04/01\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\n그래프 데이터로 풀 수 있는 문제\n\n\n\n\n\n\nGNN\n\n\nGRAPH\n\n\nTRANSLATION\n\n\n\n[번역] A Gentle Introduction to Graph Neural Networks ②\n\n\n\n\n\n2023/03/17\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\n그래프는 세상 어디에나 있다\n\n\n\n\n\n\nGNN\n\n\nGRAPH\n\n\nTRANSLATION\n\n\n\n[번역] A Gentle Introduction to Graph Neural Networks ①\n\n\n\n\n\n2023/03/16\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\npure function과 친해지려면 purrr 합시다\n\n\n\n\n\n\nR package\n\n\npurrr\n\n\n\nR아두면 쓸데있는 패키지 이야기 05 purrr package\n\n\n\n\n\n2023/01/01\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\n내가 원하는 주식 종목 정보 한번에 불러오기\n\n\n\n\n\n\nQuant\n\n\ntidyquant\n\n\n\nR고보면 쉬운 퀀트 분석 01 주식정보 불러오기\n\n\n\n\n\n2022/09/18\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\n한글 폰트 깨짐 현상 Ragg package로 부셔드림\n\n\n\n\n\n\nR package\n\n\nRagg\n\n\n\nR아두면 쓸데있는 패키지 이야기 04 Ragg package\n\n\n\n\n\n2022/09/04\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\niris 대신 penguins package 씁시다\n\n\n\n\n\n\nR package\n\n\npalmerpenguins\n\n\n\nR아두면 쓸데있는 패키지 이야기 03 palmerpenguins package\n\n\n\n\n\n2022/05/27\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\n득표율을 한 눈에! 득표율 지도 시각화\n\n\n\n\n\n\nR\n\n\nVisualization\n\n\n\ngeofacet package로 대한민국 카토그램 만들기\n\n\n\n\n\n2022/03/20\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nbump chart를 그리고 싶을 때, ggbump package\n\n\n\n\n\n\nR package\n\n\nggbump\n\n\n\nR아두면 쓸데있는 패키지 이야기 02 ggbump package\n\n\n\n\n\n2022/02/20\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\ndata frame의 진화, tibble package\n\n\n\n\n\n\nR package\n\n\ntibble\n\n\n\nR아두면 쓸데있는 패키지 이야기 01 tibble package\n\n\n\n\n\n2021/05/02\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "프로그래밍 언어 그 자체를 가지고 명령어를 통해 작업을 하는 건 많이 어렵습니다. 불편하기도 하고요. 그럴 때 사용하는 게 바로 IDE(통합계발환경, Intergrated Development Environment)입니다. Python을 이용할 때 사용하는 PyCharm이나 Jupyter Notebook, 혹은 MS에서 나온 텍스트 에디터 VS Code가 대표적인 IDE라고 할 수 있을겁니다. R의 가장 대표 IDE는 RStudio입니다. 그런데 이 RStudio가 갑자기 이름을 바꾼다고 선언했습니다. 아마 8월 중으로 이름표를 새로 바꿀 것 같은데요, 새로운 이름은 Posit입니다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "오렌지맨숀",
    "section": "",
    "text": "방송국에서 데이터 저널리스트로 일하는 주인장이 꾸며갈\n귤 향 가득한, 오렌지맨숀입니다."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "오렌지 맨숀🍊",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\n\n\n\n\nR고보면 쉬운 퀀트 분석 01 주식정보 불러오기\n\n\n\n\n\n\n2022/09/18\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nR아두면 쓸데있는 패키지 이야기 04 Ragg package\n\n\n\n\n\n\n2022/09/04\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nR, Python, Julia 모두 Quarto로 모여라\n\n\n\n\n\n\n2022/08/27\n\n\n6 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nRStudio가 갑자기 Posit으로 이름을 고치는 이유는 뭘까\n\n\n\n\n\n\n2022/08/21\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nR아두면 쓸데있는 패키지 이야기 03 palmerpenguins package\n\n\n\n\n\n\n2022/05/27\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\ngeofacet package로 대한민국 카토그램 만들기\n\n\n\n\n\n\n2022/03/20\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nR아두면 쓸데있는 패키지 이야기 02 ggbump package\n\n\n\n\n\n\n2022/02/20\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nR아두면 쓸데있는 패키지 이야기 01 tibble package\n\n\n\n\n\n\n2021/05/02\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/blog_post/post.html",
    "href": "posts/blog_post/post.html",
    "title": "더미 블로그 / This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n구독자 혹시 맬서스라는 이름 들어봤어? 윗글은 영국의 고전 경제학자 토마스 맬서스가 1798년 쓴 <인구론>의 일부야. 맬서스는 <인구론>을 통해 임금, 토지, 식량 등의 생존 자원은 1, 2, 3, 4… 이렇게 산술급수로 증가하지만 인구는 1, 2, 4, 8… 기하급수적으로 증가한다는 걸 지적했어.\n인구 증가 문제를 해결하지 않으면 사회적으로 큰 문제가 생길 것이라고 경고했지.\n맬서스의 경고가 가장 극심했던 시절은 1960년대야. 1968년 전 세계의 인구 증가율이 역대 최대치인 2.1%를 기록했고, “이대로 가다간 인구 폭발로 세계가 종말을 맞이하는 것 아니야”라는 불안한 목소리가 여기저기 나오기도 했어. 이 영향으로 만들어진 정책이 바로 산아제한 정책이야. “덮어놓고 낳다 보면 거지꼴을 못 면한다”는 구호로 진행된 우리나라를 포함해 일본, 중국 등 동아시아에서 산아제한 정책은 효과적이었어.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/post-with-code/post-with-code.html",
    "href": "posts/post-with-code/post-with-code.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html#posit이-뭔데",
    "href": "posts/welcome/index.html#posit이-뭔데",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "Posit이 뭔데?",
    "text": "Posit이 뭔데?\nPosit을 사전에서 찾아보면 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다로 나옵니다. 토론 과정에서 아이디어를 제시하는 경우 posit이라는 단어를 쓰는 셈인거죠. RStudio(IDE 이름이 회사 이름이기도 합니다)에서는 posit이라는 단어가 데이터 분석가, 데이터 과학자들의 업무와 잘 어울린다는 판단을 했고, RStudio의 새로운 이름으로 Posit을 결정했다고 발표했습니다. 회사명도 Posit으로 바뀔 예정입니다."
  },
  {
    "objectID": "posts/welcome/index.html#rtudio가-이름을-바꾸는-이유는",
    "href": "posts/welcome/index.html#rtudio가-이름을-바꾸는-이유는",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "RTudio가 이름을 바꾸는 이유는?",
    "text": "RTudio가 이름을 바꾸는 이유는?\nR을\u001c\n\n바뀌는 이유 1. A broader focus\n\n“We want to make scientific communication better for everyone”\n\n\nRstudio는 이미 python을 지원하고 있음\n\n\nR 인터페이스로 python을 할 수 있는 reticulate 패키지도 있고\n\n\n하지만 python 이용자가 Rstudio를 이용하는 걸 본 적은 없음. 대부분 다 jupyter 쓰지\n\n\n혹은 VS code를 쓰지\n\n“That name has started to feel increasing constraining”\n\nRstudio라는 이름이 가지는 한계 / R만 개발할 수 있는 IDE\n\n\nR 이름 뗄 테니까 다른 언어(python, Julia 등)도 우리 개발환경으로 들어와라라고 유혹하는 것\n\n바뀌는 이유 2. A large community\n\n“We want to help more parts of science become as open, dynamic, inclusive, and diverse as the community we belong to”\n\n\n비교적 잘 운영되고 있는 R community\n\n\n하지만 python community와 비교했을 때 확장의 한계도 있다\n\n\n역시나 다른 커뮤니티와의 융합을 목적으로 둠\n\n\n그렇다고 R에서 python으로의 전환까지 이어지진 않을 것임\n\n\n해들리 위컴 왈\n“I’m not going to stop writing R code” “I’m not going to learn Python.”\n\n\n이와 궤를 같이하는 변화가 바로 Quarto\n\n\n차세대 Rmarkdown인 Quarto에서는 jupyter, VS code, Observable javascript를 기본적으로 실행할 수 있음\n\n2. Posit이 뭔데\n\nPosit의 실제 뜻 / 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다\n\n\n토론을 할 때 아이디어를 제시하는 경우 posit이라는 단어를 씀\n\n\n데이터 분석가, 과학자들의 업무와 잘 어울리는 단어 posit을 새로운 IDE의 이름으로 결정\n\n\n\n홈페이지는 8월 중으로 오픈 예정 https://posit.co/\n\n\nSpeaker notes (press ‘s’ when presenting to switch to speaker mode)."
  },
  {
    "objectID": "posts/welcome/index.html#rstudio가-이름을-바꾸는-이유는",
    "href": "posts/welcome/index.html#rstudio가-이름을-바꾸는-이유는",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "RStudio가 이름을 바꾸는 이유는?",
    "text": "RStudio가 이름을 바꾸는 이유는?\nR을\n\n바뀌는 이유 1. A broader focus\n\n“We want to make scientific communication better for everyone”\n\n\nRstudio는 이미 python을 지원하고 있음\n\n\nR 인터페이스로 python을 할 수 있는 reticulate 패키지도 있고\n\n\n하지만 python 이용자가 Rstudio를 이용하는 걸 본 적은 없음. 대부분 다 jupyter 쓰지\n\n\n혹은 VS code를 쓰지\n\n“That name has started to feel increasing constraining”\n\nRstudio라는 이름이 가지는 한계 / R만 개발할 수 있는 IDE\n\n\nR 이름 뗄 테니까 다른 언어(python, Julia 등)도 우리 개발환경으로 들어와라라고 유혹하는 것\n\n바뀌는 이유 2. A large community\n\n“We want to help more parts of science become as open, dynamic, inclusive, and diverse as the community we belong to”\n\n\n비교적 잘 운영되고 있는 R community\n\n\n하지만 python community와 비교했을 때 확장의 한계도 있다\n\n\n역시나 다른 커뮤니티와의 융합을 목적으로 둠\n\n\n그렇다고 R에서 python으로의 전환까지 이어지진 않을 것임\n\n\n해들리 위컴 왈\n“I’m not going to stop writing R code” “I’m not going to learn Python.”\n\n\n이와 궤를 같이하는 변화가 바로 Quarto\n\n\n차세대 Rmarkdown인 Quarto에서는 jupyter, VS code, Observable javascript를 기본적으로 실행할 수 있음\n\n2. Posit이 뭔데\n\nPosit의 실제 뜻 / 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다\n\n\n토론을 할 때 아이디어를 제시하는 경우 posit이라는 단어를 씀\n\n\n데이터 분석가, 과학자들의 업무와 잘 어울리는 단어 posit을 새로운 IDE의 이름으로 결정\n\n\n\n홈페이지는 8월 중으로 오픈 예정 https://posit.co/\n\n\nSpeaker notes (press ‘s’ when presenting to switch to speaker mode)."
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html",
    "href": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "프로그래밍 언어 그 자체를 가지고 명령어를 통해 작업을 하는 건 많이 어렵습니다. 불편하기도 하고요. 그럴 때 사용하는 게 바로 IDE(통합계발환경, Intergrated Development Environment)입니다. Python을 이용할 때 사용하는 PyCharm이나 Jupyter Notebook, 혹은 MS의 텍스트 에디터 VS Code가 대표적인 IDE라고 할 수 있을겁니다.\nRStudio는 R의 가장 대표 IDE입니다. 그런데 이 RStudio가 지난 7월 말, 본인들의 이름을 바꾼다고 선언했습니다. 아마 8월 중으로 이름표를 새로 바꿀 것 같은데요, 그들이 공개한 RStudio의 새로운 이름은 Posit입니다. RStudio는 왜 갑자기 이름을 Posit으로 바꾸려는걸까요?"
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#posit이-뭔데",
    "href": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#posit이-뭔데",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "Posit이 뭔데?",
    "text": "Posit이 뭔데?\nPosit을 사전에서 찾아보면 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다로 나옵니다. 토론 과정에서 아이디어를 제시하는 경우 posit이라는 단어를 쓰는 셈인거죠. RStudio(IDE 이름이 회사 이름이기도 합니다)에서는 posit이라는 단어가 데이터 분석가, 데이터 과학자들의 업무와 잘 어울린다는 판단을 했고, RStudio의 새로운 이름으로 Posit을 결정했다고 발표했습니다. 회사명도 Posit으로 바뀔 예정입니다."
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#rstudio가-이름을-바꾸는-이유는",
    "href": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#rstudio가-이름을-바꾸는-이유는",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "RStudio가 이름을 바꾸는 이유는",
    "text": "RStudio가 이름을 바꾸는 이유는\n\n1. A Broader Focus\n\n“That name has started to feel increasing constraining.”\n\n데이터 관련 분석 프로그래밍, 혹은 데이터 사이언스에서 R은 항상 Python과 비교됩니다. 데이터 관련 공부를 시작하면서 R과 Python 사이의 양자택일은 쉽지 않은 고민이죠. 전반적인 흐름은 Python에게 웃어주고 있는 모양세입니다. 여기에 Julia까지 참전하면서 R의 입지는 점점 줄어들고 있습니다. R 이름을 딱 박고 있는 RStudio 입장에서 반길일이 아니죠.\nRStudio가 여지껏 가만히 있었던 건 아닙니다. RStudio는 이미 Python을 지원하고 있습니다. R 인터페이스로 Python을 할 수 있는 reticulate 패키지도 있고요. 하지만 Python 이용자가 RStudio를 이용하는 건 쉽지 않은 선택입니다. 이미 잘 갖춰진 Python 전용 IDE를 쓰지 뭣하러 RStudio를 씁니까. 아니면 호환성 좋은 VS code를 쓰면 되죠.\nRStudio의 수석과학자 해들리 위컴은 RStudio라는 이름이 가지는 한계를 인정했습니다. 누가봐도 RStudio는 R만 개발할 수 있는 IDE로 느껴집니다. 그래서 그들은 선택을 한 겁니다. 우리 프로그램에 R 이름 뗄 테니까, Python, Julia 등 다른 언어 쓰는 사람들도 우리 개발환경으로 들어오라고요.\n\n\n\n2. A Large Community\nR community는 RStudio를 중심으로 비교적 잘 운영되고 있습니다. 하지만 위에서 언급한것처럼 규모 측면이나 확장성 측면에서 한계도 명확하죠. RStudio는 이번 Posit으로의 개편을 통해 다른 커뮤니티와의 융합을 목적으로 두고 있습니다. 그렇다고 R에서 Python으로의 전환이 이뤄지진 않을 겁니다.\n\n“I’m not going to stop writing R code. I’m not going to learn Python.”\n\n해들리 위컴이 이렇게 밝힌 이상 Python으로의 거대한 전환은 없을 것 같네요. Posit으로의 변화에 발맞춰 또 다른 변화가 있으니 바로 Quarto입니다. 차세대 Rmarkdown인 Quarto에서는 Jupyter, VS code, Observable Javascript를 기본적으로 실행할 수 있다고 합니다. Quarto에 대해서는 다음 포스트를 통해 더 깊이 이야기를 해보도록 하겠습니다. 여튼 개편될 Posit은 아마 8월 이후에나 만나볼 수 있을 것 같습니다. 홈페이지는 8월 중으로 오픈 예정이라고 합니다."
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#section",
    "href": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#section",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "R을 공부하는 제 입장에서 이번 RStudio의 변화는 반길일입니다."
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#posit의-뜻은",
    "href": "posts/220821_Rstudio-is-becoming-Posit/post_220821.html#posit의-뜻은",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "Posit의 뜻은",
    "text": "Posit의 뜻은\nPosit을 사전에서 찾아보면 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다로 나옵니다. 토론 과정에서 아이디어를 제시하는 경우 posit이라는 단어를 쓰는 셈인거죠. RStudio(IDE 이름이 회사 이름이기도 합니다)에서는 posit이라는 단어가 데이터 분석가, 데이터 과학자들의 업무와 잘 어울린다는 판단을 했고, RStudio의 새로운 이름으로 Posit을 결정했다고 발표했습니다. 회사명도 Posit으로 바뀔 예정입니다.\n조금 더 지켜봐야겠지만 R을 공부하는 제 입장에서 이번 RStudio의 변화는 반길만한 일입니다. 여러 언어 환경에 있는 사람들을 한 IDE에 모아둘 수 있다면 협업도 더 원활하게 이뤄질테니까요. 앞으로 발표될 Posit에 대한 정보는 꾸준히 정리해보겠습니다."
  },
  {
    "objectID": "posts/210502_tibble-package/index.html",
    "href": "posts/210502_tibble-package/index.html",
    "title": "data frame의 진화, tibble package",
    "section": "",
    "text": "tidyverse 패키지를 사용하면 data.frame 대신 사용하게되는 tibble. 오늘 알아볼 R package는 tibble입니다. tibble 패키지의 역사부터 기존의 data.frame과는 어떻게 다른지 정리해봅니다.\n\n\n\n2014년 1월, dplyr 패키지에선 data.frame을 tbl_df이라는 서브클래스로 사용했습니다. 이전의 data.frame과 다르게 출력된 결과가 콘솔창을 다 뒤덮지도 않고 칼럼명 아래에 자료형을 표현해주는 강점이 있었죠. 이 tbl_df가 지금의 tibble 패키지의 시초입니다. tbl_df를 [티블-디프]로 읽다가 뒤에 df는 떨어져나가고 tbl남 남아 결국엔 tibble이 되었죠. 참고로 패키지를 만든 해들리 위컴은 뉴질랜드 사람인데, 뉴질랜드인들이 table을 tibble이라고 발음한다고 합니다.\n\n\n\n\n위대한 패키지 tidyverse의 일원인만큼 tibble 로고의 뒷 배경은 tidyverse 세계관을 공유하고 있습니다. 우주 배경을 뒤에 두고 표가 그려져있죠. 그 위엔 TIBBLE 이라는 이름표가 적혀있고요. 폰트 스타일은 스타트랙을 닮았는데, 스타트랙에는 tibble과 유사한 tribble이라는 크리쳐가 등장합니다. tribble은 tibble 패키지의 함수로도 등장하는데 이건 뒤에서 설명 드리겠습니다. tibble 이름표를 잘 보면 TI33으로도 읽을 수 있는데 공학용 계산기로 유명한 텍사스 인스트루먼트(TI)에서 만든 동명의 모델이 있죠. (물론 의도한지는 모르겠지만요)"
  },
  {
    "objectID": "posts/210502_tibble-package/index.html#all-about-tibble",
    "href": "posts/210502_tibble-package/index.html#all-about-tibble",
    "title": "data frame의 진화, tibble package",
    "section": "All about tibble",
    "text": "All about tibble\n\nas.tibble\n아이리스(붓꽃) 데이터가 담겨있는 iris 데이터를 가지고 살펴보겠습니다. 총 150개의 로(row)와 5개의 칼럼(column)으로 이뤄진 데이터프레임(data.frame)입니다. 만일 코드에 그냥 iris라고 입력한다면 콘솔창에는 150개의 행을 보실 수 있을텐데요. 그걸 막기 위해 iris 데이터의 머릿부분만 불러오라는 함수 head( )를 써보았어요.\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n이번엔 tibble 패키지를 이용해볼까요. 여기서 사용할 함수는 as_tibble( )입니다. 무언가를 tibble로 만들어주는 고마운 함수입니다. 새로운 iris tibble 녀석을 tbl_iris에 할당했습니다. 그리고 불러와봅시다. tibble은 그냥 tbl_iris라고 입력해도 콘솔창을 다 뒤덮지않는군요. 10개의 행을 보여주고는 나머지 140개가 남아있다고 깨알같이 설명해줍니다. 게다가 5개의 칼럼이 어떤 녀석인지 밑에다가 자료형을 설명해주고 있군요. 착한 녀석이죠. 혹여나 이러한 편의를 무시하고 모든 행을 다 보고 싶은 경우에는 옵션을 통해 바꿔줄 수 있습니다.\n\nlibrary(tibble)\n\ntbl_iris &lt;- as_tibble(iris)\ntbl_iris\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n# 행이 n개를 넘어가면 m개만 출력하고 싶다면\n# options(tibble.print_max = n, tibble.print_min = m)\n\n# 모든 행을 다 보고 싶다면\n# option(tibble.print_max = Inf)\n\n# 콘솔창의 폭은 고려말고 모든 열을 다 보고 싶다면\n# option(tibble.width = Inf)\n\n\n\n\ntibble\n본격적으로 tibble을 만들어봅니다. tibble( )을 이용하면 후딱 tibble을 생성할 수 있답니다. tibble( ) 함수는 data.frame( ) 함수와는 다르게 변수의 이름을 바꾸지 않아요. 예를 들어볼게요. 오렌지 맨숀라는 칼럼에 숫자 1을 넣은 data.frame을 만들어볼거에요. 동일하게 tibble로도 만들어보고요.\n\n# 오렌지 맨숀이라는 이름의 칼럼을 가진 데이터를 만들어봅니다\n\nlibrary(tibble)\n\ndata.frame(`오렌지 맨숀` = 1)\n\n  오렌지.맨숀\n1           1\n\ntibble(`오렌지 맨숀` = 1)\n\n# A tibble: 1 × 1\n  `오렌지 맨숀`\n          &lt;dbl&gt;\n1             1\n\n\n칼럼 이름에 공백이 들어가게 되면 data.frame은 공백을 온점으로 바꿔줍니다. 오렌지 맨숀 대신 오렌지.맨숀이 되었죠? 반면 tibble은 변수의 이름을 바꾸지 않고 그대로 내비두죠. 이러한 tibble의 유연함은 공백말고 다른 비정상적인 문자도 칼럼 이름에 넣을 수 있게 했어요.\n\n# tibble은 비정상적 문자도 칼럼명에 넣을 수 있습니다\n# 물론 백틱(`)으로 묶어야 합니다\n\ntb &lt;- tibble(\n  `:^)` = \"smile\", \n  ` ` = \"space\",\n  `2021` = \"number\"\n)\n\ntb\n\n# A tibble: 1 × 3\n  `:^)` ` `   `2021`\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 smile space number\n\n\n\n\n\ntribble\n\ntibble을 만들 수 있는 또다른 방법은 함수 tribble을 사용하는겁니다. 스타 트렉의 커크 함장에게 눈처럼 내리는 동물이 바로 트리블이랍니다. 트리블은 복실복실한 털과 귀여운 목소리 탓에 애완용으로 많이 키워졌는데 다만 한가지 주의해야할 부분은 바로 번식이랍니다. 한 번 번식을 시작하면 끝도 없이 증식해버려서 자칫하면 손을 쓸 수 없을지도 몰라요.\ntibble 패키지에 있는 tribble은 transposed tibble의 줄임말입니다. 단어 그대로 전치된 티블이라는 뜻이지요. 기존의 tibble 입력 형식이 colname = data 같은 가로형이었다면 tribble에서는 세로형으로 입력할 수 있지요. 간단하게 적은 양의 데이터를 코드로 입력할 때에는 tribble을 쓰면 편리합니다.\n\n# tribble 함수에서 칼럼명은 ~로 시작해야 합니다\n# 데이터 구분은 ,로 하고요\n\ntribble(\n  ~x, ~y, ~z,\n  \"a\", 21, \"2000\",\n  \"b\", 31, \"1990\"\n)\n\n# A tibble: 2 × 3\n  x         y z    \n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 a        21 2000 \n2 b        31 1990 \n\n\n\n\n\ntibble_row\ntibble을 만들 수 있는 또 다른 방법. tibble_row( )가 있어요. 기본적으로 data.frame과 tibble은 벡터들의 모음입니다. 여기서 잠깐, 벡터는 동일한 유형의 데이터가 여러개 묶여있는 형식을 뜻해요. 수치형 벡터도 있을 테고, 문자형 벡터도 있을 거고요, 논리형 벡터도 존재해요. 함수 등과 같이 특별한 타입의 데이터들은 벡터가 아니여요. class를 가지고 있는 일부 요소들은 벡터이기도 하고 아닌 녀석도 있죠.\ntibble_row 이야기를 하는데 갑자기 벡터 이야기를 해서 뜬금없다고 생각할 수 있지만 다 이유가 있답니다. 기존 함수들로는 벡터가 아닌 데이터(스칼라)를 tibble 안에 담을 수 없었어요. 하지만 tibble_row 함수와 함께라면 스칼라도 tibble 안에 넣을 수 있게 되죠. tibble_row 함수는 한 행(row)을 차지하는 데이터프레임을 구성해줍니다. 즉 한 열에 크기가 1인 녀석만 들어갈 수 있지만 그 대신 스칼라 데이터도 넣을 수 있게 된 거죠. 참고로 저장되는 스칼라는 list 형태로 포장됩니다.\n\n# vector가 아닌 scalar 데이터를 만들어봅니다\n# lm(linear model)과 time 데이터를 써 보겠습니다\n\nmodel &lt;- lm(y ~ x, data.frame(x = 1:5, y = 3:7), model = FALSE)\ntime &lt;- Sys.time()\n\ntibble(time)\n\n# A tibble: 1 × 1\n  time               \n  &lt;dttm&gt;             \n1 2024-03-03 21:30:41\n\n\nmodel의 경우 vector가 아니여서 tibble에 담기지 않아요. 반면 time 데이터는 들어갈 수 있어요. 하지만 tibble_row 함수를 사용한다면 어떨까요. tibble_row와 함께라면 vector와 scalar 상관없이 tibble에 담을 수 있습니다.\n\ntibble_row(model)\n\n# A tibble: 1 × 1\n  model \n  &lt;list&gt;\n1 &lt;lm&gt;"
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/index.html",
    "href": "posts/220821_Rstudio-is-becoming-Posit/index.html",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "프로그래밍 언어 그 자체를 가지고 명령어를 통해 작업을 하는 건 많이 어렵습니다. 불편하기도 하고요. 그럴 때 사용하는 게 바로 IDE(통합계발환경, Intergrated Development Environment)입니다. Python을 이용할 때 사용하는 PyCharm이나 Jupyter Notebook, 혹은 MS의 텍스트 에디터 VS Code가 대표적인 IDE라고 할 수 있을겁니다.\nRStudio는 R의 가장 대표 IDE입니다. 그런데 이 RStudio가 지난 7월 말, 본인들의 이름을 바꾼다고 선언했습니다. 아마 8월 중으로 이름표를 새로 바꿀 것 같은데요, 그들이 공개한 RStudio의 새로운 이름은 Posit입니다. RStudio는 왜 갑자기 이름을 Posit으로 바꾸려는걸까요?"
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/index.html#rstudio가-이름을-바꾸는-이유는",
    "href": "posts/220821_Rstudio-is-becoming-Posit/index.html#rstudio가-이름을-바꾸는-이유는",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "RStudio가 이름을 바꾸는 이유는",
    "text": "RStudio가 이름을 바꾸는 이유는\n\n1. A Broader Focus\n\n“That name has started to feel increasing constraining.”\n\n데이터 관련 분석 프로그래밍, 혹은 데이터 사이언스에서 R은 항상 Python과 비교됩니다. 데이터 관련 공부를 시작하면서 R과 Python 사이의 양자택일은 쉽지 않은 고민이죠. 전반적인 흐름은 Python에게 웃어주고 있는 모양세입니다. 여기에 Julia까지 참전하면서 R의 입지는 점점 줄어들고 있습니다. R 이름을 딱 박고 있는 RStudio 입장에서 반길일이 아니죠.\nRStudio가 여지껏 가만히 있었던 건 아닙니다. RStudio는 이미 Python을 지원하고 있습니다. R 인터페이스로 Python을 할 수 있는 reticulate 패키지도 있고요. 하지만 Python 이용자가 RStudio를 이용하는 건 쉽지 않은 선택입니다. 이미 잘 갖춰진 Python 전용 IDE를 쓰지 뭣하러 RStudio를 씁니까. 아니면 호환성 좋은 VS code를 쓰면 되죠.\nRStudio의 수석과학자 해들리 위컴은 RStudio라는 이름이 가지는 한계를 인정했습니다. 누가봐도 RStudio는 R만 개발할 수 있는 IDE로 느껴집니다. 그래서 그들은 선택을 한 겁니다. 우리 프로그램에 R 이름 뗄 테니까, Python, Julia 등 다른 언어 쓰는 사람들도 우리 개발환경으로 들어오라고요.\n\n\n\n2. A Large Community\nR community는 RStudio를 중심으로 비교적 잘 운영되고 있습니다. 하지만 위에서 언급한것처럼 규모 측면이나 확장성 측면에서 한계도 명확하죠. RStudio는 이번 Posit으로의 개편을 통해 다른 커뮤니티와의 융합을 목적으로 두고 있습니다. 그렇다고 R에서 Python으로의 전환이 이뤄지진 않을 겁니다.\n\n“I’m not going to stop writing R code. I’m not going to learn Python.”\n\n해들리 위컴이 이렇게 밝힌 이상 Python으로의 거대한 전환은 없을 것 같네요. Posit으로의 변화에 발맞춰 또 다른 변화가 있으니 바로 Quarto입니다. 차세대 Rmarkdown인 Quarto에서는 Jupyter, VS code, Observable Javascript를 기본적으로 실행할 수 있다고 합니다. Quarto에 대해서는 다음 포스트를 통해 더 깊이 이야기를 해보도록 하겠습니다. 여튼 개편될 Posit은 아마 10월 이후에나 만나볼 수 있을 것 같습니다. 홈페이지는 10월 중으로 오픈 예정이라고 합니다."
  },
  {
    "objectID": "posts/220821_Rstudio-is-becoming-Posit/index.html#posit의-뜻은",
    "href": "posts/220821_Rstudio-is-becoming-Posit/index.html#posit의-뜻은",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "Posit의 뜻은",
    "text": "Posit의 뜻은\nPosit을 사전에서 찾아보면 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다로 나옵니다. 토론 과정에서 아이디어를 제시하는 경우 posit이라는 단어를 쓰는 셈인거죠. RStudio(IDE 이름이 회사 이름이기도 합니다)에서는 posit이라는 단어가 데이터 분석가, 데이터 과학자들의 업무와 잘 어울린다는 판단을 했고, RStudio의 새로운 이름으로 Posit을 결정했다고 발표했습니다. 회사명도 Posit으로 바뀔 예정입니다.\n조금 더 지켜봐야겠지만 R을 공부하는 제 입장에서 이번 RStudio의 변화는 반길만한 일입니다. 여러 언어 환경에 있는 사람들을 한 IDE에 모아둘 수 있다면 협업도 더 원활하게 이뤄질테니까요. 앞으로 발표될 Posit에 대한 정보는 꾸준히 정리해보겠습니다."
  },
  {
    "objectID": "posts/220220_ggbump-package/index.html",
    "href": "posts/220220_ggbump-package/index.html",
    "title": "bump chart를 그리고 싶을 때, ggbump package",
    "section": "",
    "text": "ggplot2는 grammar of graphics(a.k.a. gg)을 토대로 시각화를 만드는 패키지입니다. 2는 ver.2의 의미를 담았죠. gg는 릴랜드 윌킨스의 동명의 책 The Grammar of Graphics에서 따온 건데, 이 책에서 릴랜드는 데이터를 어떻게 시각적으로 표현할 것인지에 대해 다룹니다. gg에 대한 이야기는 나중에 다른 포스트에서 다루도록 하겠습니다.\nggplot2 패키지의 문법 기반 위에서 돌아가는 서브 패키지들은 보통 gg라는 접두사로 시작됩니다. ggbump 역시 ggplot2의 일원이라고 이해할 수 있어요. 그렇다면 bump는 무엇을 의미하는 걸까요? 자동차의 범퍼, 혹은 놀이동산의 범퍼카를 떠올리면 bump의 의미를 유추할 수 있어요. bump는 바로, 충돌을 의미합니다. 충돌과 차트, 어떤 연관이 있는 걸까요?\n\n\n\n\n\n\n\n2022 May Bumps, Corpus Christi College\n\n\n영국의 케임브리지 대학에는 The bump라고 불리는 조정 경기가 있습니다. 케임브리지를 가로지르는 캠 강(river Cam) 은 나란히 경주하기에는 너무 좁아서 한 줄로 경주하는 독특한 조정 경주를 진행해왔어요. 19세기 초부터 시작된 이 경기 이름이 바로 The bump입니다. The bump의 경주 방식은 이렇습니다. 우선 강을 따라 한 줄로 경기를 시작합니다. 각 선수들은 전속력으로 노를 저어 앞에 있는 보트를 따라잡고 충돌(bump)하죠. 그렇게 되면 앞에 있는 조정 팀을 추월한 것으로 인정, 순위가 올라가게 됩니다. 주최 측에서는 경기의 진행 상황을 매핑하는 차트를 그려서 제공했는데, 이 차트를 bump chart라고 불렀습니다. 아래 차트는 2020년 사순절에 치러진 대회(Lent Bump)의 남자부 경기 결과입니다. 어떤 차트인지 감이 오죠?\n\n\n\n\n\n\n로고에는 3개의 노드(점), 노드에 연결된 시그모이드 곡선이 보입니다. 시그모이드(Sigmoid) 곡선은 S자 모양의 부드러운 곡선을 의미합니다. Sigmoid라는 단어의 뜻이 S자 모양이거든요. 시그모이드 곡선은 로지스틱 방정식, 정규분포의 누적분포함수에서 확인할 수 있습니다. 아래 차트를 보면 정규분포의 누적분포함수의 부드러운 S자 곡선을 확인할 수 있습니다.\n\nlibrary(tidyverse)\n\n# ggplot2에서 주요 확률분포 곡선을 그릴 때는 stat_function을 활용하면 됩니다\n# 정규분포(norm)의 누적분포함수를 그릴 땐 fun = pnorm 조건을 쓰세요\n# 마찬가지로 지수분포(exp)에서 누적분포함수를 그릴 땐 fun = pexp 조건을 쓰면 됩니다.\n\nggplot(data.frame(X = c(-3, 3)), aes(x = X)) +\n  stat_function(fun = pnorm, colour = \"black\", size = 1) +\n  ggtitle(\"Cumulative Normal Distribution of X ~ N(0,1)\") +\n  theme_classic()\n\n\n\n\n\n\n\n# 참고로 접두사 p는 누적분포함수(CDF)를 의미하고, \n# 접두사 q는 누적분포함수(CDF)의 역함수인 분위수함수를, \n# 접두사 r은 무작위 난수 샘플을 의미합니다\n\nggbump package를 활용하면 시그모이드 곡선도 그릴 수 있습니다. 그럼 본격적으로 ggbump 패키지에 대해서 살펴보도록 하죠."
  },
  {
    "objectID": "posts/220220_ggbump-package/index.html#all-about-ggbump",
    "href": "posts/220220_ggbump-package/index.html#all-about-ggbump",
    "title": "bump chart를 그리고 싶을 때, ggbump package",
    "section": "All about ggbump",
    "text": "All about ggbump\n\ngeom_sigmoid\n\nlibrary(tidyverse)\nlibrary(ggbump)\n\ndf &lt;- data.frame(x = 1:6,\n                 y = 5:10,\n                 xend = 7,\n                 yend = -5:0)\n\nhead(df)\n\n  x  y xend yend\n1 1  5    7   -5\n2 2  6    7   -4\n3 3  7    7   -3\n4 4  8    7   -2\n5 5  9    7   -1\n6 6 10    7    0\n\n\n시그모이드 곡선에 필요한 변수는 시작점, 끝점, 그룹 정도입니다. 시작점의 위치는 (x, y) 변수에, 끝점의 위치는 (xend, yend) 변수에 넣으면 되죠. 그리고 어떤 점끼리 이어지는지 그룹을 결정해주면 됩니다. 위의 데이터를 가지고 시그모이드 곡선을 그려보면 총 6개의 선이 그려집니다. (1, 5)와 (7, -5)를 잇는 곡선을 포함해서 말이죠.\n\nlibrary(tidyverse)\nlibrary(ggbump)\n\n# geom_sigmoid 함수에서 x, y, xend, yend, group 변수를 지정해주면 됩니다.\n# geom_sigmoid 외의 함수는 점(geom_point)과 라벨(geom_text)을 위한 함수입니다.\n\nggplot(df) +\n  geom_sigmoid(aes(x = x, xend = xend, y = y, yend = yend, group = factor(x)), color = \"black\") +\n  geom_point(aes(x = x, y = y)) +\n  geom_point(aes(x = xend, y = yend)) +\n  geom_text(aes(x = x, y = y, label = paste0(\"(\", x, \", \", y, \")\")), vjust = 1.8, size = 3) +\n  geom_text(aes(x = xend, y = yend, label = paste0(\"(\", xend, \", \", yend, \")\")), \n            vjust = 1.4, size = 3) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\ngeom_bump\nbump chart를 그리기 위해선 geom_bump 함수를 사용하면 됩니다. 간단하게 가상의 데이터를 만들어 보겠습니다. 대한민국을 포함해 총 5개 국가(Korea, Japan, China, Russia, India)의 임의 데이터입니다. 아래와 같이 나라명과 연도(2020, 2021, 2022), 그리고 임의의 value값이 포함돼있습니다.\n\ndf &lt;- tibble(country = c(\"Korea\", \"Korea\", \"Korea\", \"Japan\", \"Japan\", \"Japan\", \"China\", \"China\", \"China\", \"Russia\", \"Russia\", \"Russia\", \"India\", \"India\", \"India\"),\n             year = c(2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022),\n             value = c(500, 200, 100, 400, 300, 400, 200, 400, 200, 500, 400, 300, 300, 300, 100))\n\nhead(df)\n\n# A tibble: 6 × 3\n  country  year value\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Korea    2020   500\n2 Korea    2021   200\n3 Korea    2022   100\n4 Japan    2020   400\n5 Japan    2021   300\n6 Japan    2022   400\n\n\ngeom_bump 함수를 사용하려면 rank 값이 필요합니다. 각 연도별로 묶어서 value값에 따라 rank 값을 부여하면 되겠습니다. rank 함수를 사용하면 됩니다.\n\n# ties.method는 만일 value값이 동등할경우 어떻게 계산할 것인지 결정하는 부분입니다.\n# 보통은 min(동률 순위 중 낮은 값 출력), max(동률 순위 중 높은 값 출력)을 사용합니다.\n# 여기선 그냥 겹치지 않게 그리기 위해 random method(순서 상관없이 랜덤)를 선택했습니다.\n\ndf &lt;- df |&gt;\n  group_by(year) |&gt;\n  mutate(rank = rank(value, ties.method = \"random\")) |&gt;\n  ungroup()\n\nhead(df)\n\n# A tibble: 6 × 4\n  country  year value  rank\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Korea    2020   500     4\n2 Korea    2021   200     1\n3 Korea    2022   100     2\n4 Japan    2020   400     3\n5 Japan    2021   300     2\n6 Japan    2022   400     5\n\n\nrank값이 잘 나왔군요. rank값은 값이 크면 클수록 더 높은 숫자가 부여됩니다. 2020년 한국의 value는 500, 일본의 value는 400인데 한국이 4위, 일본이 3위인 걸 보면 알 수 있죠. 우리가 보통 생각하는 순위와는 반대입니다. 위에서 rank를 계산할 때 -value로 계산한다면 이 부분은 해결할 수 있습니다. 여기선 그래프를 그릴 때 y축을 돌려버리는 걸로 처리하겠습니다.\n\nlibrary(wesanderson)\n\nggplot(df, aes(year, rank, color = country)) +\n  geom_bump() +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  scale_y_reverse() +\n  scale_color_manual(values = wes_palette(\"Zissou1\", n = 5))\n\n\n\n\n\n\n\n\n부드러운 시그모이드 곡선으로 이뤄진 범프 차트가 만들어졌습니다. scale_color_manual에 들어있는 wes_palette는 이름에서 유추할 수 있듯 웨스 앤더슨 감독의 색감이 담긴 컬러 팔레트입니다. 이 차트에서는 웨스 앤더슨 감독의 2004년 작 &lt;스티브 지소와의 해저 생활(The Life Aquatic With Steve Zissou)&gt;의 색상을 사용했습니다.\n\n\n\nThe Life Aquatic with Steve Zissou, Wes Anderson\n\n\n여기서 조금 더 꾸며볼까요? bump line의 폭을 늘리고 점도 찍어보고, 해당 라인이 어떤 국가를 의미하는지 라벨도 달아보겠습니다. 축은 있으면 보기 싫으니 선을 다 없애버립시다. 그리고 x축은 정수 연도만 남겨야 할 것 같고요. 정리해보면 이렇게 될 겁니다.\n\nggplot(df, aes(year, rank, color = country)) +\n  geom_bump(size = 5, smooth = 8, alpha = 0.8) +\n  geom_point(size = 5) +\n  geom_text(data = df %&gt;% filter(year == min(year)),\n            aes(x = year, label = country), size = 5, hjust = 0, vjust = -1) +\n  geom_text(data = df %&gt;% filter(year == max(year)),\n            aes(x = year, label = country), size = 5, hjust = 1, vjust = -1) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid.major = element_blank()) +\n  scale_x_continuous(limits = c(2019.95, 2022.05),\n                     breaks = seq(2020, 2022, 1)) +\n  scale_y_reverse(limits = c(5, 0.5)) +\n  labs(y = \"RANK\",\n       x = NULL) +\n  scale_color_manual(values = wes_palette(\"Zissou1\", n = 5))"
  },
  {
    "objectID": "posts/220527_palmerpenguins-package/index.html",
    "href": "posts/220527_palmerpenguins-package/index.html",
    "title": "iris 대신 penguins package 씁시다",
    "section": "",
    "text": "오늘 소개할 R package는 palmerpenguins package입니다. 남극의 파머 군도에 있는 3곳의 섬에서 관찰된 3종의 펭귄 데이터가 담겨져 있죠.\n\n\n\n파머 군도에 있는 Dreams Island, Torgersen Island, Biscoe Point에는 세 종의 펭귄이 살고 있습니다. 턱끈 펭귄(Chinstrap), 젠투 펭귄(Gentoo), 아델리 펭귄(Adélie) 이렇게 말이죠. palmerpenguins package에는 이 세 펭귄의 크기, 성별 정보가 담겨있습니다. 펭귄들의 데이터는 미국의 장기 생태 연구 네트워크(US Long Term Ecological Research Network)에서 운영하는 프로그램의 일부로, 파머 군도에서 2007년부터 2009년까지 크리스틴 고먼 박사에 의해 수집됐습니다.\n\n\n\n\nR을 이용하는 유저 중에 iris 데이터를 한 번이라도 안 써본 유저는 없을 겁니다. iris 데이터는 로널드 피셔(Ronald Fisher)의 1936년 논문에 포함되어 있던 유서 깊은 자료입니다. R에 기본적으로 내장되어 있는 데이터이기도 하고 기본적인 R 연산, 시각화를 공부하는데 iris만한 데이터가 없죠. 그런데 이 iris 데이터를 이제 그만 쓰자는 목소리가 나오고 있어요. 바로 로널드 피셔 때문이죠.\n\n\n\n\n피셔는 통계학자이자 유전학자이자 진화생물학자였습니다. 현대 통계학에 지대한 공을 세운 학자로 알려져있습니다. 통계학자 앤더스 할(Anders Hald)은 피셔를 두고 현대 통계학의 토대를 거의 혼자서 만들어낸 천재로 지칭할 정도죠. Bootstrap을 처음으로 제안한 브래들리 에프론(스탠퍼드 대학교 통계학과 교수)도 로널드 피셔를 20세기 통계에서 가장 중요한 인물이라고 말할 정도입니다.\nF-검정, F-분포의 F가 바로 피셔의 F입니다. 피셔가 F-분포를 처음 제안했고, 조지 W 스네데코가 이후에 완성하면서 처음 제안한 피셔를 기려 F-분포, F-검정이라고 명명한거죠. 그래서 F-분포를 피셔-스네데코 분포라고도 합니다\n전체 대상(모집단)의 특성(모수)을 파악하기 위해 표본을 추출해 추론하는 건 현대 통계에서 아주 당연한 접근방식이죠? 이 흐름을 만든 게 바로 로널드 피셔입니다. 피셔는 모집단과 표본집단을 구분짓고, 일부(표본집단)를 통해 전체(모집단)에 대한 분석이 가능하다는 걸 귀무가설로 증명해 냈습니다. 귀무가설(null hypothesis)도 피셔가 정의한 개념입니다.\n그리고 이걸 발전시켜서 추측통계학, 이른바 추계학(stochastic)을 탄생시키죠. 추계학은 통계의 범위를 수학뿐만 아니라 여론조사, 제품검사, 의약품의 효과 등 사회과학의 방법론까지 확장시켰습니다. 20세기 통계에서 가장 중요한 인물이라고 칭하는 게 부족함이 없어보입니다.\n그런데 그 대단한 피셔가 우생학자로도 유명했습니다. BLM 시위 이후 피셔의 우생학자로서의 삶이 다시 재조명되면서 과학 분야 전반에서 정화의 흐름이 나오고 있습니다. 영국의 명문대학 유니버시티 칼리지 런던은 피셔의 이름이 붙은 연구 센터의 이름을 Center for Computational Biology로 바꾸기도 했죠. 그래서 iris를 과연 계속 써야하는지에 대한 논의가 나온 겁니다. 그 대안으로 떠오른 데이터셋이 바로 palmerpenguins package의 펭귄 데이터입니다."
  },
  {
    "objectID": "posts/220527_palmerpenguins-package/index.html#all-about-package",
    "href": "posts/220527_palmerpenguins-package/index.html#all-about-package",
    "title": "iris 대신 penguins package 씁시다",
    "section": "All about package",
    "text": "All about package\n\npenguins\n파머 군도에서 수집된 원자료는 penguins_raw에 담겨있습니다. 관측치를 모두 활용하고 싶다면 penguins_raw를 불러오면 됩니다. 아마 대부분의 경우에는 penguins 데이터면 충분할겁니다. penguins 데이터에는 8개의 변수, 344개의 개체 정보가 들어가 있습니다. bill_length와 bill_depth는 펭귄의 부리의 크기를 나타낸 정보입니다. 아래 그림을 보면 length와 depth의 차이를 알 수 있어요.\n\n\npalmerpenguins::penguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n# species : 펭귄 종을 나타내는 factor형 변수(Adélie, Chinstrap, Gentoo)\n# island : 남극 파머 군도의 섬을 나타내는 factor형 변수(Biscoe, Dreams, Torgersen)\n# bill_length_mm : 펭귄 부리의 길이를 ㎜단위로 나타낸 number형 변수\n# bill_depth_mm : 펭귄 부리의 깊이를 ㎜단위로 나타낸 number형 변수\n# flipper_length_mm : 펭귄 물갈퀴의 길이를 ㎜단위로 나타낸 integer형 변수\n# body_mass_g : 펭귄 몸무게를 g단위로 나타낸 integer형 변수\n# sex : 펭귄 성별을 나타낸 factor형 변수(female, male)\n# year : 연구 시점이 담긴 integer형 변수(2007, 2008, 2009)\n\n\n\nSimpson’s paradox\niris대신 제시되는 데이터셋인만큼 기본적인 시각화를 연습하는데 penguins 패키지는 부족함이 없습니다. 펭귄 부리의 길이와 깊이를 가지고 scatter plot을 그려보겠습니다. geom_smooth로 상관관계를 살펴보면 음의 상관관계가 있다고 볼 수 있겠네요.\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_classic()\n\n\n\n\n\n\n\n\n하지만 종별로 나눠서 살펴보면 어떨까요? 이번엔 Adélie, Chinstrap, Gentoo 세 종별로 scatter plot을 그려서 상관관계를 살펴보겠습니다. 종별로 보면 부리의 길이와 깊이는 양의 상관관계가 있어 보입니다. 야생의 데이터에서 확인할 수 있는 심슨의 역설(Simpson’s Paradox)의 아주 좋은 사례입니다. 영국의 통계학자 에드워드 심슨이 정리한 이 역설은 각각의 변수를 살피지 않고 전체 통계만 보고 판단하다가 발생할 수 있는 함정입니다.\n\nlibrary(palmerpenguins)\n\nggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 2) + \n  geom_smooth(method = \"lm\", se = FALSE, aes(color = species)) +\n  scale_color_manual(values = c(\"darkorange\",\"darkorchid\",\"cyan4\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/220827_quarto/index.html",
    "href": "posts/220827_quarto/index.html",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "",
    "text": "RStudio는 자사의 2022년 컨퍼런스 rstudio::conf(2022)에서 발표한 여러 소식 가운데 가장 중요한 소식으로 이렇게 4가지를 꼽았습니다.\n\nRStudio의 이름은 Posit으로 바꾼다\n새로운 오픈소스 기반의 과학기술 출판 시스템, Quarto\nShiny 생태계의 새로운 발전\ntidymodel의 업데이트\n\n1번은 이미 이 포스트에서 다루었죠? 그 연장선이라고 볼 수 있는 Quarto가 이번 게시물의 주제입니다. Quarto는 R Markdown에 이은 RStudio의 차세대 R 출판 플랫폼입니다. 기존의 R Markdown을 이용하면 R code sript를 Word, HTML, PDF, PPT 등 다양한 문서 형식으로 만들 수 있었습니다. 웹을 통한 출판(Bookdown)까지도 가능했죠.\n\n그런데 이 R Markdwon이 어느새 10년 가까이 지났습니다. 기능의 편리함은 지적할만한 게 없었지만 R Markdown 생태계가 너무 커져버렸죠. 관련 생태계가 커졌다는 건 오히려 반길 일이지만 덕지덕지 붙어버린 서드파티 패키지들이 많아진 게 문제였습니다. 더 이상 통일된 하나의 R Markdown의 제작과 작업이 되질 못했습니다. 과학, 기술 블로그를 만들 땐 distill package를 사용하고, 웹 프레젠테이션 파일을 만들 땐 xaringan(사륜안) package를 사용하고…\n그래서 등장한 게 바로 이 Quarto입니다. R Markdown과 마찬가지로 Knitr와 Pandoc을 기반으로 하고 있고요. 궁극적으로 R Studio는 Quarto 생태계에 다른 언어를 사용하는 사람들끼리 모을 생각을 하고 있습니다. 그래서 저번 Posit 이야기의 연장선이라고 말씀을 드린 겁니다. 그 이유 때문인지 Quarto는 R의 내장 라이브러리가 아닌 독립 소프트웨어로 제작되었습니다. 새로운 시스템 Quarto 단어가 생소할 텐데, Quarto는 4절판을 의미합니다. 8페이지 분량의 텍스트를 두 번 접어서 네 장을 만드는 형식을 뜻하죠. 출판 역사에 의미가 있는 단어를 골랐다고 합니다.\n\n\n\nhttps://quarto.org/docs/get-started/\nQuarto는 위 링크에서 받을 수 있습니다. 링크를 들어가면 나오는 홈페이지에서도 확인할 수 있지만 Quarto는 R 뿐만 아니라 VS code, Jupyter에서도 활용할 수 있습니다."
  },
  {
    "objectID": "posts/220827_quarto/index.html#quarto-vs-r-markdown",
    "href": "posts/220827_quarto/index.html#quarto-vs-r-markdown",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "Quarto vs R Markdown",
    "text": "Quarto vs R Markdown\n\n\n\n\n\nQuarto의 구조를 알기 위해선 R Markdown에 대한 이해가 필요합니다.일단 R Markdown 시스템은 위의 그림과 같습니다. Rmd(R 마크다운) 파일을 knitr package를 통해 md(마크다운) 파일로 만들고, pandoc 라이브러리를 통해 문서, PPT, 웹페이지, 책의 형태로 퍼블리싱 되는 거죠. knitr은 2012년 Yihui Xie에 의해 개발된 패키지입니다. Knitr 패키지를 이용하면 동적 리포트를 생성할 수 있게 해주죠. md 파일을 다양한 형식으로 변환할 때에는 pandoc 라이브러리를 활용합니다. 정리해보면 기존 R Markdown은 Rmd 파일을 여러가지 형태의 문서로 퍼블리싱 해주는 시스템이라고 할 수 있겠네요.\n\nQuarto도 비슷합니다. R Markdown과 마찬가지로 Knitr과 pandoc을 활용합니다. 달라진 건 적용 대상입니다. 기존 시스템에선 Rmd만 가능했다면 이제는 Python도 가능합니다. jupyter까지 활용하게 되면서 Python에서 qmd(Qarto markdown) 파일을 작성하면 jupyter를 통해 md 파일로 변환해 여러가지 결과물을 만들어 낼 수 있게 된거죠.\n\n\n\n구분\nR Markdown\nQuarto\n\n\n\n\n기본 포맷\nhtml_document\npdf_document\nword_document\nhtml\npdf\nword\n\n\n비머 포맷(발표자료)\nbeamer_presentation\nbeamer\n\n\nPPT\npowerpoint_presentation\npptx\n\n\nHTML Slides\nxaringan\nioslides\nrevealjs\nrevealjs"
  },
  {
    "objectID": "posts/220827_quarto/index.html#quarto의-미래",
    "href": "posts/220827_quarto/index.html#quarto의-미래",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "Quarto의 미래",
    "text": "Quarto의 미래\n\n\n\nR & stats illustrations by @allison_horst\n\n\nRStudio의 이번 Qaurto 발표는 결국 Posit과 비슷합니다. Python과 Julia 등 다른 언어들까지 포함하는 IDE인 Posit을 발표하고, 새롭게 출시한 Quarto에는 jupyter를 지원하면서 다른 언어 이용자들을 R 커뮤니티에 끌어들이겠다는 겁니다. Python 이용자들도 충분히 웹사이트와 블로그, 책을 만들 수 있다고 유혹하는 것이죠. RStudio의 CEO가 발표한 내용을 살펴보면 미래에는 마치 Google Docs에서 사람들이 자유롭게 문서를 편집하듯이 여러 언어를 사용하는 이용자들이 Quarto 문서를 통해 협업을 하길 구상하고 있더라고요. 물론 아직까지 그런 환경이 갖춰져 있는 건 아니지만, 꽤나 매력적인 미래의 모습입니다. 하루빨리 그런 환경이 오길 바라면서 이번 포스트를 마무리하겠습니다."
  },
  {
    "objectID": "posts/220827_quarto/index.html#r-markdown과-차이점",
    "href": "posts/220827_quarto/index.html#r-markdown과-차이점",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "R Markdown과 차이점",
    "text": "R Markdown과 차이점\n\n\n\n\n\nQuarto의 구조를 알기 위해선 R Markdown에 대한 이해가 필요합니다. 일단 R Markdown 시스템은 위의 그림과 같습니다. Rmd(R 마크다운) 파일을 knitr package를 통해 md(마크다운) 파일로 만들고, pandoc 라이브러리를 통해 문서, PPT, 웹페이지, 책의 형태로 퍼블리싱되는 거죠. knitr은 2012년 Yihui Xie에 의해 개발된 패키지입니다. Knitr 패키지를 이용하면 동적 리포트를 생성할 수 있게 해주죠. md 파일을 다양한 형식으로 변환할 때에는 pandoc 라이브러리를 활용합니다. 정리해보면 기존 R Markdown은 Rmd 파일을 여러 가지 형태의 문서로 퍼블리싱해주는 시스템이라고 할 수 있겠네요.\n\n\n\nR & stats illustrations by @allison_horst\n\n\nQuarto도 비슷합니다. R Markdown과 마찬가지로 Knitr과 pandoc을 활용합니다. 달라진 건 적용 대상입니다. 기존 시스템에선 Rmd만 가능했다면 이제는 Python도 가능합니다. jupyter까지 활용하게 되면서 Python에서 qmd(Qarto markdown) 파일을 작성하면 jupyter를 통해 md 파일로 변환해 다양한 결과물을 만들어 낼 수 있게 된 거죠.\n\n\nQuarto vs R Markdown\n\n\n\n\n\n\n\n\n구분\nR Markdown\nQuarto\n\n\n\n\n기본 포맷\nhtml_document\npdf_document\nword_document\nhtml\npdf\nword\n\n\n비머 포맷(발표자료)\nbeamer_presentation\nbeamer\n\n\nPPT\npowerpoint_presentation\npptx\n\n\nHTML 슬라이드\nxaringan\nioslides\nrevealjs\n\n\nrevealjs\n\n\n블로그 및 웹사이트\nblogdown\ndistill\nQuarto Websites\nQuarto Blogs\n\n\n책\nbookdown\nQuarto Books\n\n\n인터랙티브\nShiny Documents\nQuarto Interactive Documents\n\n\nPaged HTML\npagedown\n2022 여름 공개 예정\n\n\nJournal Articles\nrticles\n2022 여름 공개 예정\n\n\n대시보드\nflexdashboard\n2022 가을 공개 예정\n\n\n\n다양한 포맷을 만들기 위해 여러 패키지를 사용했던 R Markdown과 달리, Quarto에서는 Quarto 시스템으로 다 들어왔습니다. 예전 R을 활용해 기술 블로그를 만들기 위해 distll package를 사용했지만, 이젠 Quarto의 Quarto Websites, Blogs를 활용하면 됩니다. 이 블로그도 Quarto Blogs를 이용해 만들었습니다. 아직 공개되지 않은 대시보드와 Journal Articles, Paged HTML도 곧 공개될 예정입니다."
  },
  {
    "objectID": "posts/220320_geofacet/index.html",
    "href": "posts/220320_geofacet/index.html",
    "title": "득표율을 한 눈에! 득표율 지도 시각화",
    "section": "",
    "text": "FiveThirtyEight의 2020 미 대선 선거결과 시각화\n\n\n해외 언론에서 선거 결과를 시각화한 기사를 볼 때마다 드는 생각이 있습니다. “아 우리나라도 저렇게 격자형태로 시각화하면 멋드러지지 않을까…” 국내에서는 시군구 혹은 읍면동 단위로 색을 칠하는 형태가 대부분이지 그 안에 그래프를 넣어서 시각화하기가 힘들어요. 미국은 50개 주에 1개의 특별구로 이루어졌으니, 필요한 격자는 51개 뿐이지만 우리나라의 시군구는 250개. 큰 권역 구분 정도는 다양한 시각화를 시도할 수 있지만 시군구 단위로 하기엔 부담이 될 수 있는거죠.\n\n\n\n\n그래도 해보고 싶습니다. 우리나라도 시군구 단위로 멋드러지게 만들고 싶어요. 그래서(!) 시군구 단위 그리드 만들어 봤습니다. 활용한 패키지는 geofacet입니다. geofacet은 말 그대로 지리적 정보(geo)로 면(facet)을 분할해 볼 수 있는 패키지인데요, 이 패키지가 좋은 건 Grid Designer라는 기능을 통해 자기만의 그리드를 만들 수 있다는 거죠. 그래서 지도를 펼치고 250개 시군구의 위치를 하나하나 지정해가며 만들어 봤습니다. geofacet package에도 제출해 놓았습니다. 여기에서 확인할 수 있어요.\n\nlibrary(readr)\nmygrid &lt;- read_csv(\"kr_sgg.csv\", col_types = cols(code = col_character()))\n\nhead(mygrid[,c(1,3,4,2)])\n\n# A tibble: 6 × 4\n  code    row   col name               \n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              \n1 11110     5     7 서울특별시 종로구  \n2 11140     6     7 서울특별시 중구    \n3 11170     7     7 서울특별시 용산구  \n4 11200     6     8 서울특별시 성동구  \n5 11215     7     8 서울특별시 광진구  \n6 11230     5     8 서울특별시 동대문구\n\n\n만들어 놓은 대한민국 시군구 단위 그리드 구조는 아주 간단합니다. 이름, row, col, code 정도로 이루어져 있죠. geofacet 함수는 그리드의 행(row)과 열(col)을 인식해서 그 모양에 맞춰 facet해 주는 구조입니다. 이 그리드를 가지고 그려보면 이런 모양이 나옵니다.\n\ngeofacet::grid_preview(mygrid)\n\n\n\n\n\n\n\n\n짜잔~ 면적이 서로 다른 시군구를 동일한 면적 단위로 표현했기때문에 실제 위치와는 차이가 있을 수 있습니다. 시군구 그리드에 적용된 코드는 행정안전부에서 제공하고 있는 행정표준코드를 따라서 만들어 놓았습니다. 종로구(11110), 중구(11140) 이런식으로 말이죠. 시군구 단위의 여러 데이터들을 합쳐서 시각화, 분석할 일 있으면 행정코드 기준으로 정리한다면 간단하게 할 수 있을 겁니다."
  },
  {
    "objectID": "posts/220320_geofacet/index.html#geo_grid-ggplot",
    "href": "posts/220320_geofacet/index.html#geo_grid-ggplot",
    "title": "득표율을 한 눈에! 득표율 지도 시각화",
    "section": "geo_grid + ggplot",
    "text": "geo_grid + ggplot\n\n선거 데이터 만들기\n이제 여기에 해야할 것은 각각의 시군구에 그래프를 넣어보는 겁니다. 이번 대통령 선거 득표 정보를 바탕으로 그래프를 넣어보려고 해요. 선관위 개표 데이터를 정리해서 다음과 같은 데이터(PE_20)를 만들어 봤습니다.\n\nlibrary(readxl)\nlibrary(tibble)\n\nPE_20 &lt;- read_excel(\"Presidential_Election_2022.xlsx\")\nPE_20 &lt;- as_tibble(PE_20)\n\nhead(PE_20)\n\n# A tibble: 6 × 21\n   code 구분  시군구명 선거인수 투표수 이재명 윤석열 심상정 오준호 허경영 이백윤\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 11110 서울… 종로구     129968 100629  46130  49172   3115     53    558     42\n2 11140 서울… 중구       111448  84998  38244  42906   2310     46    463     19\n3 11170 서울… 용산구     199077 152068  60063  85047   4374     67    755     37\n4 11200 서울… 성동구     252087 197240  84411 103880   5365    123    969     50\n5 11215 서울… 광진구     303582 235471 109922 113733   7072    155   1416     52\n6 11230 서울… 동대문구   300928 232106 108171 112890   6416    151   1304     44\n# ℹ 10 more variables: 옥은호 &lt;dbl&gt;, 김경재 &lt;dbl&gt;, 조원진 &lt;dbl&gt;, 김재연 &lt;dbl&gt;,\n#   이경희 &lt;dbl&gt;, 김민찬 &lt;dbl&gt;, 계 &lt;dbl&gt;, 무효투표수 &lt;dbl&gt;, 기권수 &lt;dbl&gt;,\n#   개표율 &lt;dbl&gt;\n\n\nPE_20 데이터에는 각 시군구 단위로 후보별 득표수를 넣어 두었습니다. 시군구별 선거인수, 후보별 득표수, 무효투표수, 기권수 등… 이 데이터로 시각화를 바로 할 순 없습니다. 우리에게 필요한 건 각 후보별 득표율이니까, 조금 더 정제할 필요가 있죠. 일단 득표율 TOP3 후보의 득표율을 계산해보겠습니다. 득표율은 후보별 투표수를 전체 투표수 - 무효투표수로 나누면 됩니다.\n\nlibrary(dplyr)\n\nPE_20 &lt;- PE_20 |&gt; mutate(lee_R = 이재명 / (투표수 - 무효투표수),\n                         yoon_R = 윤석열 / (투표수 - 무효투표수),\n                         sim_R = 심상정 / (투표수 - 무효투표수))\n\nPE_20_rate &lt;- PE_20 |&gt; select(c(code, lee_R, yoon_R, sim_R, 구분, 시군구명))\nhead(PE_20_rate)\n\n# A tibble: 6 × 6\n   code lee_R yoon_R  sim_R 구분       시군구명\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   \n1 11110 0.464  0.495 0.0313 서울특별시 종로구  \n2 11140 0.454  0.510 0.0274 서울특별시 중구    \n3 11170 0.399  0.564 0.0290 서울특별시 용산구  \n4 11200 0.432  0.532 0.0275 서울특별시 성동구  \n5 11215 0.472  0.488 0.0304 서울특별시 광진구  \n6 11230 0.471  0.492 0.0279 서울특별시 동대문구\n\n\n제대로 계산되었는지 비교해봅시다. 선관위 홈페이지에서 살펴보면 종로구에서 3명의 후보의 득표율이 46.42%, 49.48%, 3.13%였고, 중구에서의 득표율이 각각 45.42%, 50.96%, 2.74% 군요. 계산된 것과 비교해보니 맞는것 같습니다. 계산된 데이터는 wide form인데 시각화를 위해선 long form으로 조정할 필요가 있어요.\n\n\n\nlong form 으로 만들기\nlong form으로 바꾸는 법은 여러가지가 있지만 여기선 2개를 소개해드리겠습니다. 먼저 tidyr 패키지의 gather 함수. gather 함수가 직관적이지 않다면 그 대안으로 나온 pivot_longer를 사용하는 것도 방법입니다. 두 함수의 결과는 같으니까 원하는 것 사용하면 될 겁니다. tidyr 패키지 제작자인 해들리 위컴은 새로 나온 pivot_longer 함수를 추천하고 있어요.\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nPE_20_final &lt;- PE_20_rate |&gt; gather(key = \"cand\", value = \"rate\", lee_R, yoon_R, sim_R)\n\n# key: long form 데이터로 바꾸었을 때 이름이 될 칼럼명\n# value: long form 데이터로 바꾸었을 때 값이 들어갈 칼럼명\n# PE_20_rate의 칼럼 중 후보별 득표율 칼럼 3개(lee_R, yoon_R, sim_R)를 써주면 됩니다.\n\nhead(PE_20_final)\n\n# A tibble: 6 × 5\n   code 구분       시군구명 cand   rate\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;\n1 11110 서울특별시 종로구   lee_R 0.464\n2 11140 서울특별시 중구     lee_R 0.454\n3 11170 서울특별시 용산구   lee_R 0.399\n4 11200 서울특별시 성동구   lee_R 0.432\n5 11215 서울특별시 광진구   lee_R 0.472\n6 11230 서울특별시 동대문구 lee_R 0.471\n\nPE_20_final2 &lt;- PE_20_rate |&gt; pivot_longer(cols = ends_with(\"R\"), \n                                           names_to = \"cand\",\n                                           values_to = \"rate\")\n\n# cols: long form 데이터로 바꾸고 싶은 칼럼들(lee_R, yoon_R, sim_R)\n# ends_with: 동일한 단어로 끝나는 애들만 고를 때 사용하는 함수(tidyselect package의 함수)\n# names_to : long form 데이터로 바꾸었을 때 lee_R, yoon_R, sim_R이 들어갈 칼럼 이름\n# values_to : long form 데이터로 바꾸었을 때 value 값에 들어갈 칼럼 이름\n\nhead(PE_20_final2)\n\n# A tibble: 6 × 5\n   code 구분       시군구명 cand     rate\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;\n1 11110 서울특별시 종로구   lee_R  0.464 \n2 11110 서울특별시 종로구   yoon_R 0.495 \n3 11110 서울특별시 종로구   sim_R  0.0313\n4 11140 서울특별시 중구     lee_R  0.454 \n5 11140 서울특별시 중구     yoon_R 0.510 \n6 11140 서울특별시 중구     sim_R  0.0274\n\n\n\n\n\nggplot 그래프 그리기\n데이터도 정리가 되었겠다… 이제 이것을 가지고 그래프로 그려서 그리드에 넣으면 끝입니다. 일단 후보별 득표율을 가지고 지역별로 들어갈 바 차트가 어떤 모양이 될지, 샘플을 만들어보겠습니다. 서울특별시 종로구(code = 11110)를 가지고 예시로 그려봅시다.\n\n# 그래프를 그렸을 때 기호순으로 나열될 수 있도록 factor level을 부여해줍니다.\n# coord_flip()를 사용하면 후보의 순서가 뒤집어지기때문에 factor level은 역순으로.\n# 각 후보에 맞춰서 컬러 팔레트 설정해줍니다.\n\nPE_20_final$cand &lt;- factor(PE_20_final$cand, levels = c(\"sim_R\", \"yoon_R\", \"lee_R\"))\ndata_11110 &lt;- PE_20_final |&gt; filter(code == 11110)\n\nlibrary(tidyverse)\n\nggplot(data_11110, aes(x = cand, y = rate, fill = cand)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(values = c(\"#F7EF99\", \"#fc7b84\", \"#008EC6\")) +\n  theme_minimal() +\n  theme(\n    strip.background = element_blank(),\n    strip.text.x = element_blank(),\n    axis.text.y = element_blank()\n    )\n\n\n\n\n\n\n\n\n\n\n최종 시각화\n이제 이 그래프를 250개 시군구에 넣으면 됩니다. 어떻게? geofacet::facet_geo 함수를 쓰면 단 한 줄이면 만들 수 있습니다. 전국 지도에서 3위 후보의 득표율이 보이질 않으니… 일단 제외하고 1, 2위 후보만 시각화를 해 보겠습니다.\n\n# 위의 코드에서 추가된 건 facet_geo()뿐\n# 만들어 놓은 그리드(mygrid)와 join할 데이터(code)를 입력하면 끝\n# 시각화 정리는 theme에서 약간의 조정으로 마무리\n\nlibrary(geofacet)\n\nggplot(subset(PE_20_final, cand != \"sim_R\"), aes(x = cand, y = rate, fill = cand)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(values = c(\"#fc7b84\", \"#008EC6\")) +\n  facet_geo(~ code, grid = mygrid) +\n  theme_minimal() +\n  theme(\n    strip.background = element_blank(),\n    strip.text.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank()\n  ) + \n  scale_y_continuous(breaks = c(.5, 1), limits = c(0, 1))\n\n\n\n\n\n\n\n\n짜잔! 이러면 우리가 원했던 250개 시군구 그리드에 각각의 후보별 득표율을 그릴수 있게 되었습니다."
  },
  {
    "objectID": "posts/220904_Ragg/index.html",
    "href": "posts/220904_Ragg/index.html",
    "title": "한글 폰트 깨짐 현상 Ragg package로 부셔드림",
    "section": "",
    "text": "R에서 데이터를 잘 정제해서 시각화를 만들면 항상 한글의 벽에 부딫히곤 합니다. 한글을 인식하지 못하는 경우에는 인코딩을 해결하면 깨짐현상을 막을 수 있죠. 그렇다면 이미지를 추출할 때 한글이 깨지는 경우는 어떻게 할까요? 여기 그 예시가 있습니다. 대한민국의 주요 도시의 위치를 나타내기 위해 이런 데이터 셋을 만들어봤어요. tibble package에서 소개했던 tibble::tribble 함수를 이용해봤습니다. 세계화 시대에 맞춰 도시명에는 한글과 영어, 그리고 한자까지 포함했고요.\n\nlibrary(tibble)\n\nROK_city &lt;- tribble(\n  ~City, ~Lat, ~Lon,\n  \"울산(Ulsan, 蔚山)\", 35.549999, 129.316666,\n  \"광주(Gwangju, 光州)\", 35.166668, 126.916664,\n  \"대전(Daejeon, 大田)\", 36.351002, 127.385002,\n  \"대구(Daegu, 大邱)\", 35.866669, 128.600006,\n  \"부산(Busan, 釜山)\", 35.166668, 129.066666,\n  \"청주(Chungju, 淸州)\", 36.981304, 127.935905,\n  \"원주(Wonju, 原州)\", 37.342220, 127.920158,\n  \"인천(Incheon, 仁川)\", 37.456257, 126.705208,\n  \"서울(Seoul)\", 37.532600,127.024612\n)\n\n\n이 데이터셋을 바탕으로 지도를 그려봤습니다. 지도의 제목은 &lt;🇰🇷대한민국(大韓民國)의 주요 도시 위치&gt;로 해봤습니다. 그래프 제목에 이모지 정도는 써 줘야 그래도 웹 3.0 시대를 살고 있다고 할 수 있지 않겠습니까? 그렇게 만들어본 그래프의 모습입니다.\n\n\n\n\n처참한 모습입니다. 영어를 제외한 모든 글자를 인식하지 못하는군요. 하지만 걱정하지 마세요. 해결책이 있습니다. 바로 Ragg package를 이용하면 됩니다."
  },
  {
    "objectID": "posts/220904_Ragg/index.html#rapp-package",
    "href": "posts/220904_Ragg/index.html#rapp-package",
    "title": "한글 폰트 깨짐 현상 Rapp package로 부셔드림",
    "section": "Rapp Package",
    "text": "Rapp Package\nRapp가 무슨 뜻?\nRapp package 사용법\nRapp package를 사용하는 법은 아주 간단합니다. 일반적인 package를 설치하듯 R에 Rapp package를 설치하면 됩니다. intall.package(\"ragg\") 이렇게 말이죠. 개발버전의 Rapp package를 사용하고 싶다면 devtools::install_github(\"r-lib/ragg\")를 이용하면 됩니다. 설치한 다음엔 RStudio의 옵션창으로 가 봅시다. 일반 옵션에서 Graphics 항목에서 Graphics Device를 기존 (Default)로 되어있던 것을 AGG로 변경하면 끝입니다. 아래 스크린샷을 참고하시면 이해하기 편할겁니다."
  },
  {
    "objectID": "posts/220904_Ragg/index.html#ragg-package",
    "href": "posts/220904_Ragg/index.html#ragg-package",
    "title": "한글 폰트 깨짐 현상 Ragg package로 부셔드림",
    "section": "Ragg Package",
    "text": "Ragg Package\nRagg가 뭐지?\n\nRapp package는 Maxim Shemanarev라는 개발자가 개발한 AGG(Anti-Grain Geometry) 라이브러리를 기반으로 만들어진 R용 그래픽 패키지입니다. R과 AGG가 만나 Ragg package로 탄생했죠. Rag가 누더기, 조각이라는 뜻이 있는만큼 패키지 로고는 천 조각의 모습을 하고 있습니다. R의 그래픽 패키지로 가장 많이 알려진 건 grDevices package일 겁니다. 색상, 폰트를 자유롭게 이용하기 위해, 이제는 grDevices 대신 Ragg를 사용하면 됩니다. AGG는 grDevices에서 제공하는 표준 래스터 장치보다 더 높은 성능과 더 높은 품질을 제공하고 있습니다.\n\nRapp package 사용법\nRapp package를 사용하는 법은 아주 간단합니다. 일반적인 package를 설치하듯 R에 Rapp package를 설치하면 됩니다. intall.package(\"ragg\") 이렇게 말이죠. devtools::install_github(\"r-lib/ragg\")로 개발버전의 Rapp package를 사용해도 됩니다. 설치한 다음엔 RStudio의 옵션창으로 가 봅시다. 일반 옵션에서 Graphics 항목에서 Graphics Device를 기존 (Default)로 되어있던 것을 AGG로 변경하면 끝입니다. 아래 스크린샷을 참고하시면 이해하기 편할겁니다.\n\n\n\n\n\nAPP 환경에서 만드는 그래프\n이제 다시 그래프를 만들어봅시다. 대한민국의 지도를 만들기 위해 rnaturalearth package의 ne_countries 함수를 이용했습니다. rnaturalearth package는 과학 데이터의 장벽을 낮추기 위한 프로젝트 중 하나인 ropensci package에 포함되어 있는데요, ropensci는 나중에 따로 다뤄보겠습니다. 여튼 rnaturalearth::ne_countries 함수를 사용해보겠습니다.\n\nlibrary(rnaturalearth)\n\nkorea &lt;- rnaturalearth::ne_countries(\n  scale = 10, \n  country = \"South Korea\", \n  returnclass = \"sf\"\n)\n\n불러온 대한민국 데이터를 ggplot2::geom_sf에 넣어 지도를 그려보겠습니다.\n\nlibrary(ggplot2)\nlibrary(ragg)\n\nggplot() + \n  geom_sf(\n    data = korea, \n    fill = \"#C3ECB1\", \n    colour = \"#D5D8DB\", \n    size = 0.2\n  ) + \n  ggrepel::geom_label_repel(\n    data = ROK_city,\n    aes(Lon, Lat, label = City), \n    fill = \"#FFFFFF88\",\n    box.padding = unit(5, \"mm\")\n  ) + \n  geom_point(data = ROK_city, aes(Lon, Lat)) +\n  ggtitle(\"대한민국(大韓民國)의 주요 도시 위치🇰🇷\") +\n  theme_void() +\n  theme(panel.background = element_rect(\"#AADAFE\"),\n        plot.title = element_text(margin = margin(5, 5, 5, 5)))\n\n\n\n\n\n\n\n짜잔~ rapp 패키지로 APP 환경을 이용하면 한글과 이모지, 한자가 깨지지 않는 이미지를 손쉽게 얻을 수 있습니다."
  },
  {
    "objectID": "posts/220918_quant/index.html",
    "href": "posts/220918_quant/index.html",
    "title": "내가 원하는 주식 종목 정보 한번에 불러오기",
    "section": "",
    "text": "R을 활용해 주식을 분석하는 방법엔 다양한 선택지가 있습니다. 주식정보 사이트에서 데이터를 크롤링해 분석하는 방법, 그리고 패키지를 활용하는 방법 등… R의 퀀트 분석에서 가장 유명한 패키지는 아마 quantmod package일 겁니다. quantmod package를 이용하면 주식, 환율, 원자재 등 다양한 경제 데이터를 활용해 분석할 수 있습니다. 하지만 오늘은 tidyquant package를 활용해 퀀트 분석을 정리해보려고 합니다.\ntidyquant package는 zoo, xts, quantmod, TTR 등의 정량 데이터 및 시계열 데이터 분석 패키지를 통합해 제공해주고 있습니다. 거기에 패키지 이름에서 알 수 있듯 tidyverse 생태계의 도구를 사용해서 퀀트 분석을 할 수 있도록 설계되어 있죠. ggplot2를 이용한 시각화도 물론 가능합니다. 그럼 본격적으로 tidyquant package를 이용해 퀀트 분석을 시작해보겠습니다."
  },
  {
    "objectID": "posts/220918_quant/index.html#주식정보-불러오기",
    "href": "posts/220918_quant/index.html#주식정보-불러오기",
    "title": "내가 원하는 주식 종목 정보 한번에 불러오기",
    "section": "주식정보 불러오기",
    "text": "주식정보 불러오기\n우선 tidyquant package를 설치해야겠죠? install.packages(\"tidyquant\")를 입력해 tidyquant package를 설치합니다. 설치된 패키지를 불러옵시다. 거기에 tidyverse까지 함께 불러오겠습니다.\n\nlibrary(tidyquant)\nlibrary(tidyverse)\n\n\ntq_get()\ntq_get() 함수는 주식 관련 정보를 불러오는 가장 기본 함수입니다. get에 어떤 매개변수를 넣느냐에 따라 어느때는 주식정보를 얻을 수 있고, 또 어느때는 원자재 데이터를 가지고 올 수 있습니다. tq_get()함수의 주요 데이터 소스는 아래와 같습니다.\n\n\n\n\n\n\n데이터 소스\n데이터\n\n\n\nYahoo Finance\n기본적인 주가 정보는 Yahoo Finance의 API를 활용합니다\n\n\nFRED\n금리, 원자재 등 경제 관련 다양한 데이터는 세인트루이스 연준에서 제공하는 FRED(Federal Reserve Economic Data)를 활용합니다\n\n\nQuandl\n경제, 에너지 등의 데이터를 다루는 캐나다의 데이터 공유 플랫폼 회사 Quandl의 금융 API를 활용합니다\n\n\nTiingo\n주가 데이터, 코인 데이터 등을 제공해주는 Tiingo API도 사용할 수 있습니다\n\n\nAlpha Vantage\nTiingo와 비슷하게 주가, 코인 데이터 등을 제공해주는 Alpha Vantage API를 활용할 수 있습니다\n\n\nBloomberg\n블룸버그 경제 API도 사용할 수 있는데, 이 API는 유료 계정이 있어야 사용 가능합니다\n\n\n\n\nYahoo Finance부터 Bloomberg까지 다양한 매개변수가 있지만 이번 포스트에선 주가 정보를 불러오는 것에 집중해보겠습니다. 주가 정보 데이터는 Yahoo Finance에서 가져옵니다. 함수에 입력할 변수들도 간단합니다. 원하는 회사의 종목명과 시점만 적어주면 끝이죠. 예를 들어 2000년 1월 1일부터 2022년 8월 31일까지 엔비디아의 주가를 불러와본다고 해 봅시다. 엔비디아의 종목명은 NVDA이고, 주식 가격을 불러오기 위해 get에 넣을 매개변수는 stock.prices 입니다.\n\ntq_get(\"NVDA\",\n       get = \"stock.prices\",\n       from = \"2000-01-01\",\n       to = \"2022-08-31\")\n\n# A tibble: 5,702 × 8\n   symbol date        open  high   low close   volume adjusted\n   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 NVDA   2000-01-03 0.984 0.992 0.919 0.975 30091200    0.895\n 2 NVDA   2000-01-04 0.958 0.961 0.901 0.949 30048000    0.871\n 3 NVDA   2000-01-05 0.922 0.938 0.905 0.918 18835200    0.842\n 4 NVDA   2000-01-06 0.918 0.918 0.823 0.858 12048000    0.787\n 5 NVDA   2000-01-07 0.854 0.882 0.841 0.872  7118400    0.800\n 6 NVDA   2000-01-10 0.875 0.938 0.859 0.901 23985600    0.827\n 7 NVDA   2000-01-11 0.896 0.906 0.865 0.865 14812800    0.793\n 8 NVDA   2000-01-12 0.865 0.866 0.831 0.842 12355200    0.773\n 9 NVDA   2000-01-13 0.841 0.885 0.831 0.878 13219200    0.805\n10 NVDA   2000-01-14 0.891 0.952 0.888 0.915 60456000    0.840\n# ℹ 5,692 more rows\n\n\n짜잔~ 함수를 돌리면 tibble 형태의 데이터가 불러와집니다. 총 8열의 데이터에는 개장 시점의 가격부터 일일 거래량까지 기본적인 주식 정보가 담겨 있습니다. adjusted 열에는 주식 분할 및 배당 등 시장이 마감된 이후 주가에 영향을 줄 수 있는 변수까지 적용된 수정 가격이 들어가 있습니다.\n해외 주식만 가능한 건 아닙니다. 물론 우리나라 주식도 가능하죠. 이번엔 2000년 1월 1일부터 2022년 8월 31일까지 삼성전자의 주식 정보를 가져와 보겠습니다. Yahoo Finance에서 삼성전자의 종목명은 005930.KS 입니다. 입력하면 마찬가지로 tibble 형태의 삼성전자 주가 데이터를 불러올 수 있습니다.\n\ntq_get(\"005930.KS\",\n       get = \"stock.prices\",\n       from = \"2000-01-01\",\n       to = \"2022-08-31\")\n\n# A tibble: 5,690 × 8\n   symbol    date        open  high   low close   volume adjusted\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 005930.KS 2000-01-04  6000  6110  5660  6110 74195000    4470.\n 2 005930.KS 2000-01-05  5800  6060  5520  5580 74680000    4082.\n 3 005930.KS 2000-01-06  5750  5780  5580  5620 54390000    4111.\n 4 005930.KS 2000-01-07  5560  5670  5360  5540 40305000    4053.\n 5 005930.KS 2000-01-10  5600  5770  5580  5770 46880000    4221.\n 6 005930.KS 2000-01-11  5820  6100  5770  5770 59745000    4221.\n 7 005930.KS 2000-01-12  5610  5740  5600  5720 29220000    4185.\n 8 005930.KS 2000-01-13  5600  5740  5560  5710 41190000    4177.\n 9 005930.KS 2000-01-14  5720  5880  5680  5830 49375000    4265.\n10 005930.KS 2000-01-17  6000  6180  5920  6100 63505000    4463.\n# ℹ 5,680 more rows\n\n\n\n주가 시각화\n엔비디아 주가 데이터(조정가)로 간단히 그래프를 그려보겠습니다.\n\nNV_prices &lt;- tq_get(\"NVDA\",\n                    get = \"stock.prices\",\n                    from = \"2000-01-01\",\n                    to = \"2022-08-31\")\n\nggplot(NV_prices) +\n  geom_line(aes(date, adjusted), color = \"black\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n이번엔 삼성전자 주가 데이터로 그래프를 그려보겠습니다. 이번에는 최고가도 표시해봤습니다.\n\nlibrary(scales)\n\nSE_prices &lt;- tq_get(\"005930.KS\",\n                    get = \"stock.prices\",\n                    from = \"2000-01-01\",\n                    to = \"2022-08-31\")\n\nggplot(SE_prices) +\n  geom_line(aes(date, adjusted), color = \"black\") +\n  geom_point(data = subset(SE_prices, adjusted == max(adjusted)), \n             aes(date, adjusted), color = \"red\") +\n  geom_text(data = subset(SE_prices, adjusted == max(adjusted)),\n             aes(date - 500, adjusted, label = scales::comma(adjusted)))+\n  scale_y_continuous(labels = comma) +\n  theme_minimal()"
  },
  {
    "objectID": "daily.html",
    "href": "daily.html",
    "title": "DIARY 🤯",
    "section": "",
    "text": "이것 저것 잡다한 생각들\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\n\n\n\n사랑하는 소년이 얼음 밑에 살아서\n\n\n\nBook\n\n\nReview\n\n\n\n시간의 흐름 시인선 첫번째 주인공 한정원\n\n\n\n2024/01/08\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "daily/211001/index.html",
    "href": "daily/211001/index.html",
    "title": "pull() : Extract a single column",
    "section": "",
    "text": "오늘의 함수는 dplyr 패키지의 pull() 함수입니다. pull() 함수는 $ 연산자와 비슷한 기능을 합니다. $ 연산자는 R에서 데이터 객체의 특정 부분을 추출할 때 사용하는데요. pull() 함수는 파이프 연산자 내에서 $보다 사용하기 편리하다는 장점이 있습니다.\n\n\n\npull(.data, var = -1, name = NULL, ...)\n\n\n\n.data : data.frame, tibble을 넣을 수 있습니다. 거기에 dbplyr, dtplyr package의 data.table backend도 가능합니다. var : 추출할 변수의 이름을 넣습니다. 숫자도 가능한데 양수는 왼쪽부터 순서, 음수는 오른쪽부터 순서를 나타냅니다. name : 변수 이름을 알 경우엔 name이라는 파라미터를 써도 됩니다.\n\n\n입력한 데이터와 동일한 사이즈의 vector가 나옵니다.\n\n\n\nlibrary(dplyr)\n\n# mtcars 데이터를 가지고 pull() 함수의 예를 들어보겠습니다.\n# mtcars 데이터의 구조는 이러합니다.\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n# -1을 입력하면 mtcars 데이터의 맨 오른쪽 칼럼인 carb가 나옵니다\nmtcars |> pull(-1)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n# 칼럼 명 'carb'을 바로 써도 같은 결과가 나옵니다\nmtcars |> pull(carb)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n\n\n\ndplyr에 있는 또다른 비슷한 함수인 select와의 차이점은 뭘까요? 일단 결과 값이 다릅니다.  pull은 단일 열을 벡터로 변환해 결과로 내보냅니다. 반면 select는 하나 이상의 열을 데이터프레임으로 변환하죠.\n\nfruits <- data.frame(orange = 1:5, lemon = 5:1)\n\n# select를 써서 orange 열(1개의 열)을 가져오면 data.frame이 나옵니다\nfruits |> select(orange) |>str()\n\n'data.frame':   5 obs. of  1 variable:\n $ orange: int  1 2 3 4 5\n\n# 이번엔 pull을 이용하면 int value가 들어간 벡터가 나옵니다\nfruits |> pull(orange) |> str()\n\n int [1:5] 1 2 3 4 5\n\n# data.frame에서 pull과 의미가 동일한 함수 -> .[, \"name\"]\nfruits %>% .[ , \"orange\"] %>% str()\n\n int [1:5] 1 2 3 4 5"
  },
  {
    "objectID": "daily/211001/index.html#deep-select-vs-pull의-차이는",
    "href": "daily/211001/index.html#deep-select-vs-pull의-차이는",
    "title": "pull()",
    "section": "[Deep] select vs pull의 차이는?",
    "text": "[Deep] select vs pull의 차이는?\ndplyr에 있는 또다른 비슷한 함수인 select와의 차이점은 뭘까? 일단 결과 값이 다르다. pull은 단일 열을 벡터로 변환해 결과로 내보냄 반면 select는 하나 이상의 열을 데이터프레임으로 변환\n\nfruits <- data.frame(orange = 1:5, lemon = 5:1)\n\n# select를 써서 orange 열(1개의 열)을 가져오면\nfruits |> select(orange) |>str()\n\n'data.frame':   5 obs. of  1 variable:\n $ orange: int  1 2 3 4 5\n\n# 이번엔 pull을 이용\nfruits |> pull(orange) |> str()\n\n int [1:5] 1 2 3 4 5\n\n# data.frame에서 pull과 의미가 동일한 함수 -> .[, \"name\"\\\n# .를 써야하니 %>% 연산자를 사용하겠음\nfruits %>% .[ , \"orange\"] %>% str()\n\n int [1:5] 1 2 3 4 5"
  },
  {
    "objectID": "daily/211002/index.html",
    "href": "daily/211002/index.html",
    "title": "nest() : Create a list-column of data frames",
    "section": "",
    "text": "오늘의 함수는 tidyr 패키지의 nest() 함수입니다. nest() 함수는 데이터프레임을 중첩시킬 때 사용합니다.  중첩(nest)된 데이터프레임은 하나 이상의 열이 리스트인 데이터프레임을 의미합니다. \n\n\n\nnest(.data, ..., names_sep = NULL, .key = deprecated())\n\n\n\n.data : data.frame, tibble을 넣을 수 있습니다. … : 중첩될 칼럼을 입력합니다. tidy-select expression을 활용해 선택 가능합니다. name_sep : 중첩될 칼럼의 이름을 정합니다. NULL(기본값)일 경우엔 기존 이름이 그래도 유지됩니다. .key : 예전 버전의 nest 함수에서 사용한 영역(중첩될 칼럼의 이름 설정)으로 현재 문법에서는 사용하지 않습니다.\n\n\n\nlibrary(tidyverse)\n\n# tibble 함수를 통해 중첩된 tibble을 만들어보겠습니다.\n# g와 data라는 2개의 열의 tibble이지만 data 열은 리스트의 형태입니다.\ndf1 <- tibble(\n  g = c(1, 2, 3),\n  data = list(\n    tibble(x = 1, y = 2),\n    tibble(x = 4:5, y = 6:7),\n    tibble(x = 10)\n  )\n)\n\ndf1\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 1]>\n\n# 이번엔 nest 함수를 통해 중첩된 tibble을 만들어보겠습니다.\ndf2 <- tribble(\n  ~g, ~x, ~y,\n   1,  1,  2,\n   2,  4,  6,\n   2,  5,  7,\n   3, 10, NA\n)\n\ndf2 |> nest(data = c(x, y))\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n# tidy-select argument를 이용해서 데이터를 선택할 수도 있습니다.\ndf2 |> nest(data = any_of(c(\"x\", \"y\")))\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\ndf2 |> nest(data = !g)\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n\nnest() 함수에는 중첩될 변수를 지정합니다. any_of(), starts_with() 등 tidy_select argument를 이용해서도 지정 가능합니다.  g를 기준으로 x와 y를 중첩하는 형태이기때문에 nest() 함수에 c(x, y)를 입력했습니다.\n\n\ndplyr::group_by()를 이용하는 것도 방법입니다.  중첩될 변수를 지정하는 것보다 group_by()를 이용해 중첩시키는 게 직관적입니다. \n\nlibrary(dplyr)\n\ndf2 |> group_by(g) |> nest()\n\n# A tibble: 3 × 2\n# Groups:   g [3]\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n# group_by + nest = group_nest\n# dplyr 패키지의 group_nest는 tibble을 중첩할 때 두 과정을 한번에 처리합니다.\ndf2 |> group_nest(g)\n\n# A tibble: 3 × 2\n      g               data\n  <dbl> <list<tibble[,2]>>\n1     1            [1 × 2]\n2     2            [2 × 2]\n3     3            [1 × 2]\n\n# 중첩된 데이터프레임을 만들어서 각각의 그룹에 따라 모델을 만들고, 예측 list도 생성할 수 있습니다.\nmtcars_nested <- mtcars |>\n  group_by(cyl) |>\n  nest()\n\nmtcars_nested\n\n# A tibble: 3 × 2\n# Groups:   cyl [3]\n    cyl data              \n  <dbl> <list>            \n1     6 <tibble [7 × 10]> \n2     4 <tibble [11 × 10]>\n3     8 <tibble [14 × 10]>\n\n# lm 모델 생성\nmtcars_nested <- mtcars_nested |>\n  mutate(model = map(data, function(df) lm(mpg ~ wt, data = df)))\n\nmtcars_nested\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               model \n  <dbl> <list>             <list>\n1     6 <tibble [7 × 10]>  <lm>  \n2     4 <tibble [11 × 10]> <lm>  \n3     8 <tibble [14 × 10]> <lm>  \n\n# 만들어진 모델을 통해 예측값을 계산해봅니다.\nmtcars_nested <- mtcars_nested |>\n  mutate(model = map(model, predict))\n\nmtcars_nested\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               model     \n  <dbl> <list>             <list>    \n1     6 <tibble [7 × 10]>  <dbl [7]> \n2     4 <tibble [11 × 10]> <dbl [11]>\n3     8 <tibble [14 × 10]> <dbl [14]>"
  },
  {
    "objectID": "daily/211003/index.html",
    "href": "daily/211003/index.html",
    "title": "unnest() : Flatten back out into regular columns",
    "section": "",
    "text": "오늘의 함수는 tidyr 패키지의 unnest() 함수입니다. \nunnest() 함수는 중첩된 데이터프레임을 풀 때 사용합니다.\n\n\n\nunnest(\n  data,\n  cols,\n  ...,\n  keep_empty = FALSE,\n  ptype = NULL,\n  names_sep = NULL,\n  names_repair = \"check_unique\",\n  .drop = deprecated(),\n  .id = deprecated(),\n  .sep = deprecated(),\n  .preserve = deprecated()\n)\n\n\n\ndata : data.frame, tibble을 넣을 수 있습니다. col : 중첩된 상태를 해제할 칼럼을 입력합니다. tidy-select expression을 활용해 선택 가능합니다. keep_empty : 기본적으로 unnest() 함수는 각 요소별로 하나의 출력 행을 가져옵니다. NULL값이나 비어있는 경우엔 해당 행이 출력에서 삭제됩니다. 모든 행을 출력하려면 keep_empty = TRUE로 표시해야 합니다. name_sep : 풀어지는 칼럼의 이름을 정합니다. NULL(기본값)일 경우엔 기존 이름이 그래도 유지됩니다. names_repair : 출력되는 데이터프레임에 유효한 이름이 있는지 확인하는 데 사용합니다.\n\n\n\nlibrary(tidyverse)\n\n# tibble 함수를 통해 중첩된 tibble을 만들어보겠습니다.\ndf1 <- tibble(\n  x = 1:3,\n  y = list(\n    NULL,\n    tibble(a = 1, b = 2),\n    tibble(a = 1:3, b = 3:1)\n  )\n)\n\ndf1\n\n# A tibble: 3 × 2\n      x y               \n  <int> <list>          \n1     1 <NULL>          \n2     2 <tibble [1 × 2]>\n3     3 <tibble [3 × 2]>\n\n# unnest 함수를 통해 중첩된 tibble을 unnest 해보겠습니다.\ndf1 |> unnest(y)\n\n# A tibble: 4 × 3\n      x     a     b\n  <int> <dbl> <dbl>\n1     2     1     2\n2     3     1     3\n3     3     2     2\n4     3     3     1\n\n# keep_empty = TRUE로 처리할 경우 NULL값이 들어있던 1행도 출력됩니다.\ndf1 |> unnest(y, keep_empty = TRUE)\n\n# A tibble: 5 × 3\n      x     a     b\n  <int> <dbl> <dbl>\n1     1    NA    NA\n2     2     1     2\n3     3     1     3\n4     3     2     2\n5     3     3     1\n\n\n\n\n이번에는 unnest() 함수를 통해 중첩을 푸는 과정에서 칼럼의 이름이 어떻게 결정되는지 확인해보겠습니다. palmerpenguins 패키지에 있는 펭귄 데이터를 불러와 종별로 총 4가지의 데이터(펭귄의 부리 길이, 깊이, 물갈퀴 길이, 몸무게)의 분위값을 정리해보겠습니다.\n\nlibrary(palmerpenguins)\n\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE))))\n\n# A tibble: 3 × 5\n  species   bill_depth_mm    bill_length_mm   flipper_length_mm body_mass_g     \n  <fct>     <list>           <list>           <list>            <list>          \n1 Adelie    <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n2 Chinstrap <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n3 Gentoo    <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n\n\n펭귄 종 별로 4가지 데이터에 대한 분위값이 각각 tibble 형태로 담겨 있습니다. 이걸 unnest() 함수를 통해 풀어보겠습니다.\n\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)))) |>\n  unnest()\n\n# A tibble: 9 × 9\n  species   name  value name1 value1 name2 value2 name3 value3\n  <fct>     <chr> <dbl> <chr>  <dbl> <chr>  <dbl> <chr>  <dbl>\n1 Adelie    25%    17.5 25%     36.8 25%      186 25%    3350 \n2 Adelie    50%    18.4 50%     38.8 50%      190 50%    3700 \n3 Adelie    75%    19   75%     40.8 75%      195 75%    4000 \n4 Chinstrap 25%    17.5 25%     46.3 25%      191 25%    3488.\n5 Chinstrap 50%    18.4 50%     49.6 50%      196 50%    3700 \n6 Chinstrap 75%    19.4 75%     51.1 75%      201 75%    3950 \n7 Gentoo    25%    14.2 25%     45.3 25%      212 25%    4700 \n8 Gentoo    50%    15   50%     47.3 50%      216 50%    5000 \n9 Gentoo    75%    15.7 75%     49.6 75%      221 75%    5500 \n\n\n문제가 발생했습니다. 중첩이 풀린 데이터의 칼럼이 모두 name과 value로 표시되어 구분할 수 없게 되었습니다. 이럴때 사용하는 게 바로 names_repair와 names_sep입니다. 우선 names_repair는 check_unique가 기본값으로 되어 있습니다. 겹치는 변수가 없도록 name, name2, name3 같은 고유의 이름을 부여해주죠. 하지만 우리는 각 칼럼이 어떤 데이터인지 이름을 알고 싶습니다. 이럴 땐 name_sep을 사용합니다. 구분자를 무엇으로 할 지 설정해주면 해당 칼럼과 구분자를 합쳐서 칼럼명을 부여해줍니다.\n\n# names_sep = \"_\" 입력\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)))) |>\n  unnest(names_sep = \"_\")\n\n# A tibble: 9 × 9\n  species   bill_depth…¹ bill_…² bill_…³ bill_…⁴ flipp…⁵ flipp…⁶ body_…⁷ body_…⁸\n  <fct>     <chr>          <dbl> <chr>     <dbl> <chr>     <dbl> <chr>     <dbl>\n1 Adelie    25%             17.5 25%        36.8 25%         186 25%       3350 \n2 Adelie    50%             18.4 50%        38.8 50%         190 50%       3700 \n3 Adelie    75%             19   75%        40.8 75%         195 75%       4000 \n4 Chinstrap 25%             17.5 25%        46.3 25%         191 25%       3488.\n5 Chinstrap 50%             18.4 50%        49.6 50%         196 50%       3700 \n6 Chinstrap 75%             19.4 75%        51.1 75%         201 75%       3950 \n7 Gentoo    25%             14.2 25%        45.3 25%         212 25%       4700 \n8 Gentoo    50%             15   50%        47.3 50%         216 50%       5000 \n9 Gentoo    75%             15.7 75%        49.6 75%         221 75%       5500 \n# … with abbreviated variable names ¹​bill_depth_mm_name, ²​bill_depth_mm_value,\n#   ³​bill_length_mm_name, ⁴​bill_length_mm_value, ⁵​flipper_length_mm_name,\n#   ⁶​flipper_length_mm_value, ⁷​body_mass_g_name, ⁸​body_mass_g_value\n\n\n\n\n리스트와 리스트가 중첩된 복잡한 데이터프레임을 풀려면 unnest() 함수를 두 번 사용하면 됩니다. 복잡하게 중첩된 데이터라면 hoist(), unnest_wider(), unnest_longer() 함수를 사용하면 좋습니다. 위 3개의 함수는 이른바 rectangling 작업에 사용되는 함수인데 이 녀석들은 나중에 따로 정리해보겠습니다.\n\ndf2 <- tibble(\n  a = list(c(\"a\", \"b\"), \"c\"),\n  b = list(1:2, 3),\n  c = c(11, 22)\n)\n\ndf2\n\n# A tibble: 2 × 3\n  a         b             c\n  <list>    <list>    <dbl>\n1 <chr [2]> <int [2]>    11\n2 <chr [1]> <dbl [1]>    22\n\n# unnest를 이용해 동시에 여러 열의 중첩을 해제할 수 있습니다.\ndf2 |> unnest(c(a, b))\n\n# A tibble: 3 × 3\n  a         b     c\n  <chr> <dbl> <dbl>\n1 a         1    11\n2 b         2    11\n3 c         3    22\n\n# 단계적으로 중첩을 해제하면 다음과 같은 결과를 얻습니다.\ndf2 |> unnest(a) |> unnest(b)\n\n# A tibble: 5 × 3\n  a         b     c\n  <chr> <dbl> <dbl>\n1 a         1    11\n2 a         2    11\n3 b         1    11\n4 b         2    11\n5 c         3    22"
  },
  {
    "objectID": "orange.html",
    "href": "orange.html",
    "title": "오렌지 맨숀",
    "section": "",
    "text": "귤 향 가득한, 오렌지 맨숀입니다."
  },
  {
    "objectID": "daily/211004/index.html",
    "href": "daily/211004/index.html",
    "title": "pull() : Extract a single column",
    "section": "",
    "text": "오늘의 함수는 dplyr 패키지의 pull() 함수입니다.  pull() 함수는 $ 연산자와 비슷한 기능을 합니다.  $ 연산자는 R에서 데이터 객체의 특정 부분을 추출할 때 사용하는데요.  pull() 함수는 파이프 연산자 내에서 $보다 사용하기 편리하다는 장점이 있습니다.\n\n\n\n\npull(.data, var = -1, name = NULL, ...)\n\n\n\n\n\n.data : data.frame, tibble을 넣을 수 있습니다. 거기에 dbplyr, dtplyr package의 data.table backend도 가능합니다.  var : 추출할 변수의 이름을 넣습니다. 숫자도 가능한데 양수는 왼쪽부터 순서, 음수는 오른쪽부터 순서를 나타냅니다.  name : 변수 이름을 알 경우엔 name이라는 파라미터를 써도 됩니다.\n\n\n\n\n입력한 데이터와 동일한 사이즈의 vector가 나옵니다.\n\n\n\n\n\nlibrary(dplyr)\n\n# mtcars 데이터를 가지고 pull() 함수의 예를 들어보겠습니다.\n# mtcars 데이터의 구조는 이러합니다.\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n# -1을 입력하면 mtcars 데이터의 맨 오른쪽 칼럼인 carb가 나옵니다\nmtcars |&gt; pull(-1)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n# 칼럼 명 'carb'을 바로 써도 같은 결과가 나옵니다\nmtcars |&gt; pull(carb)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n\n\n\n\n\ndplyr에 있는 또다른 비슷한 함수인 select와의 차이점은 뭘까요? 일단 결과 값이 다릅니다.  pull은 단일 열을 벡터로 변환해 결과로 내보냅니다. 반면 select는 하나 이상의 열을 데이터프레임으로 변환하죠.\n\nfruits &lt;- data.frame(orange = 1:5, lemon = 5:1)\n\n# select를 써서 orange 열(1개의 열)을 가져오면 data.frame이 나옵니다\nfruits |&gt; select(orange) |&gt;str()\n\n'data.frame':   5 obs. of  1 variable:\n $ orange: int  1 2 3 4 5\n\n# 이번엔 pull을 이용하면 int value가 들어간 벡터가 나옵니다\nfruits |&gt; pull(orange) |&gt; str()\n\n int [1:5] 1 2 3 4 5\n\n# data.frame에서 pull과 의미가 동일한 함수 -&gt; .[, \"name\"]\nfruits %&gt;% .[ , \"orange\"] %&gt;% str()\n\n int [1:5] 1 2 3 4 5"
  },
  {
    "objectID": "daily/211005/index.html",
    "href": "daily/211005/index.html",
    "title": "nest() : Create a list-column of data frames",
    "section": "",
    "text": "오늘의 함수는 tidyr 패키지의 nest() 함수입니다. nest() 함수는 데이터프레임을 중첩시킬 때 사용합니다.  중첩(nest)된 데이터프레임은 하나 이상의 열이 리스트인 데이터프레임을 의미합니다. \n\n\n\nnest(.data, ..., names_sep = NULL, .key = deprecated())\n\n\n\n.data : data.frame, tibble을 넣을 수 있습니다. … : 중첩될 칼럼을 입력합니다. tidy-select expression을 활용해 선택 가능합니다. name_sep : 중첩될 칼럼의 이름을 정합니다. NULL(기본값)일 경우엔 기존 이름이 그래도 유지됩니다. .key : 예전 버전의 nest 함수에서 사용한 영역(중첩될 칼럼의 이름 설정)으로 현재 문법에서는 사용하지 않습니다.\n\n\n\nlibrary(tidyverse)\n\n# tibble 함수를 통해 중첩된 tibble을 만들어보겠습니다.\n# g와 data라는 2개의 열의 tibble이지만 data 열은 리스트의 형태입니다.\ndf1 <- tibble(\n  g = c(1, 2, 3),\n  data = list(\n    tibble(x = 1, y = 2),\n    tibble(x = 4:5, y = 6:7),\n    tibble(x = 10)\n  )\n)\n\ndf1\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 1]>\n\n# 이번엔 nest 함수를 통해 중첩된 tibble을 만들어보겠습니다.\ndf2 <- tribble(\n  ~g, ~x, ~y,\n   1,  1,  2,\n   2,  4,  6,\n   2,  5,  7,\n   3, 10, NA\n)\n\ndf2 |> nest(data = c(x, y))\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n# tidy-select argument를 이용해서 데이터를 선택할 수도 있습니다.\ndf2 |> nest(data = any_of(c(\"x\", \"y\")))\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\ndf2 |> nest(data = !g)\n\n# A tibble: 3 × 2\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n\nnest() 함수에는 중첩될 변수를 지정합니다. any_of(), starts_with() 등 tidy_select argument를 이용해서도 지정 가능합니다.  g를 기준으로 x와 y를 중첩하는 형태이기때문에 nest() 함수에 c(x, y)를 입력했습니다.\n\n\ndplyr::group_by()를 이용하는 것도 방법입니다.  중첩될 변수를 지정하는 것보다 group_by()를 이용해 중첩시키는 게 직관적입니다. \n\nlibrary(dplyr)\n\ndf2 |> group_by(g) |> nest()\n\n# A tibble: 3 × 2\n# Groups:   g [3]\n      g data            \n  <dbl> <list>          \n1     1 <tibble [1 × 2]>\n2     2 <tibble [2 × 2]>\n3     3 <tibble [1 × 2]>\n\n# group_by + nest = group_nest\n# dplyr 패키지의 group_nest는 tibble을 중첩할 때 두 과정을 한번에 처리합니다.\ndf2 |> group_nest(g)\n\n# A tibble: 3 × 2\n      g               data\n  <dbl> <list<tibble[,2]>>\n1     1            [1 × 2]\n2     2            [2 × 2]\n3     3            [1 × 2]\n\n# 중첩된 데이터프레임을 만들어서 각각의 그룹에 따라 모델을 만들고, 예측 list도 생성할 수 있습니다.\nmtcars_nested <- mtcars |>\n  group_by(cyl) |>\n  nest()\n\nmtcars_nested\n\n# A tibble: 3 × 2\n# Groups:   cyl [3]\n    cyl data              \n  <dbl> <list>            \n1     6 <tibble [7 × 10]> \n2     4 <tibble [11 × 10]>\n3     8 <tibble [14 × 10]>\n\n# lm 모델 생성\nmtcars_nested <- mtcars_nested |>\n  mutate(model = map(data, function(df) lm(mpg ~ wt, data = df)))\n\nmtcars_nested\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               model \n  <dbl> <list>             <list>\n1     6 <tibble [7 × 10]>  <lm>  \n2     4 <tibble [11 × 10]> <lm>  \n3     8 <tibble [14 × 10]> <lm>  \n\n# 만들어진 모델을 통해 예측값을 계산해봅니다.\nmtcars_nested <- mtcars_nested |>\n  mutate(model = map(model, predict))\n\nmtcars_nested\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               model     \n  <dbl> <list>             <list>    \n1     6 <tibble [7 × 10]>  <dbl [7]> \n2     4 <tibble [11 × 10]> <dbl [11]>\n3     8 <tibble [14 × 10]> <dbl [14]>"
  },
  {
    "objectID": "daily/211006/index.html",
    "href": "daily/211006/index.html",
    "title": "unnest() : Flatten back out into regular columns",
    "section": "",
    "text": "오늘의 함수는 tidyr 패키지의 unnest() 함수입니다. \nunnest() 함수는 중첩된 데이터프레임을 풀 때 사용합니다.\n\n\n\nunnest(\n  data,\n  cols,\n  ...,\n  keep_empty = FALSE,\n  ptype = NULL,\n  names_sep = NULL,\n  names_repair = \"check_unique\",\n  .drop = deprecated(),\n  .id = deprecated(),\n  .sep = deprecated(),\n  .preserve = deprecated()\n)\n\n\n\ndata : data.frame, tibble을 넣을 수 있습니다. col : 중첩된 상태를 해제할 칼럼을 입력합니다. tidy-select expression을 활용해 선택 가능합니다. keep_empty : 기본적으로 unnest() 함수는 각 요소별로 하나의 출력 행을 가져옵니다. NULL값이나 비어있는 경우엔 해당 행이 출력에서 삭제됩니다. 모든 행을 출력하려면 keep_empty = TRUE로 표시해야 합니다. name_sep : 풀어지는 칼럼의 이름을 정합니다. NULL(기본값)일 경우엔 기존 이름이 그래도 유지됩니다. names_repair : 출력되는 데이터프레임에 유효한 이름이 있는지 확인하는 데 사용합니다.\n\n\n\nlibrary(tidyverse)\n\n# tibble 함수를 통해 중첩된 tibble을 만들어보겠습니다.\ndf1 <- tibble(\n  x = 1:3,\n  y = list(\n    NULL,\n    tibble(a = 1, b = 2),\n    tibble(a = 1:3, b = 3:1)\n  )\n)\n\ndf1\n\n# A tibble: 3 × 2\n      x y               \n  <int> <list>          \n1     1 <NULL>          \n2     2 <tibble [1 × 2]>\n3     3 <tibble [3 × 2]>\n\n# unnest 함수를 통해 중첩된 tibble을 unnest 해보겠습니다.\ndf1 |> unnest(y)\n\n# A tibble: 4 × 3\n      x     a     b\n  <int> <dbl> <dbl>\n1     2     1     2\n2     3     1     3\n3     3     2     2\n4     3     3     1\n\n# keep_empty = TRUE로 처리할 경우 NULL값이 들어있던 1행도 출력됩니다.\ndf1 |> unnest(y, keep_empty = TRUE)\n\n# A tibble: 5 × 3\n      x     a     b\n  <int> <dbl> <dbl>\n1     1    NA    NA\n2     2     1     2\n3     3     1     3\n4     3     2     2\n5     3     3     1\n\n\n\n\n이번에는 unnest() 함수를 통해 중첩을 푸는 과정에서 칼럼의 이름이 어떻게 결정되는지 확인해보겠습니다. palmerpenguins 패키지에 있는 펭귄 데이터를 불러와 종별로 총 4가지의 데이터(펭귄의 부리 길이, 깊이, 물갈퀴 길이, 몸무게)의 분위값을 정리해보겠습니다.\n\nlibrary(palmerpenguins)\n\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE))))\n\n# A tibble: 3 × 5\n  species   bill_depth_mm    bill_length_mm   flipper_length_mm body_mass_g     \n  <fct>     <list>           <list>           <list>            <list>          \n1 Adelie    <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n2 Chinstrap <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n3 Gentoo    <tibble [3 × 2]> <tibble [3 × 2]> <tibble [3 × 2]>  <tibble [3 × 2]>\n\n\n펭귄 종 별로 4가지 데이터에 대한 분위값이 각각 tibble 형태로 담겨 있습니다. 이걸 unnest() 함수를 통해 풀어보겠습니다.\n\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)))) |>\n  unnest()\n\n# A tibble: 9 × 9\n  species   name  value name1 value1 name2 value2 name3 value3\n  <fct>     <chr> <dbl> <chr>  <dbl> <chr>  <dbl> <chr>  <dbl>\n1 Adelie    25%    17.5 25%     36.8 25%      186 25%    3350 \n2 Adelie    50%    18.4 50%     38.8 50%      190 50%    3700 \n3 Adelie    75%    19   75%     40.8 75%      195 75%    4000 \n4 Chinstrap 25%    17.5 25%     46.3 25%      191 25%    3488.\n5 Chinstrap 50%    18.4 50%     49.6 50%      196 50%    3700 \n6 Chinstrap 75%    19.4 75%     51.1 75%      201 75%    3950 \n7 Gentoo    25%    14.2 25%     45.3 25%      212 25%    4700 \n8 Gentoo    50%    15   50%     47.3 50%      216 50%    5000 \n9 Gentoo    75%    15.7 75%     49.6 75%      221 75%    5500 \n\n\n문제가 발생했습니다. 중첩이 풀린 데이터의 칼럼이 모두 name과 value로 표시되어 구분할 수 없게 되었습니다. 이럴때 사용하는 게 바로 names_repair와 names_sep입니다. 우선 names_repair는 check_unique가 기본값으로 되어 있습니다. 겹치는 변수가 없도록 name, name2, name3 같은 고유의 이름을 부여해주죠. 하지만 우리는 각 칼럼이 어떤 데이터인지 이름을 알고 싶습니다. 이럴 땐 name_sep을 사용합니다. 구분자를 무엇으로 할 지 설정해주면 해당 칼럼과 구분자를 합쳐서 칼럼명을 부여해줍니다.\n\n# names_sep = \"_\" 입력\npenguins |> \n  select(c(species, bill_depth_mm, bill_length_mm, flipper_length_mm, body_mass_g)) |>\n  group_by(species) |>\n  summarise_all(.funs = function(x) list(enframe(\n    quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)))) |>\n  unnest(names_sep = \"_\")\n\n# A tibble: 9 × 9\n  species   bill_depth…¹ bill_…² bill_…³ bill_…⁴ flipp…⁵ flipp…⁶ body_…⁷ body_…⁸\n  <fct>     <chr>          <dbl> <chr>     <dbl> <chr>     <dbl> <chr>     <dbl>\n1 Adelie    25%             17.5 25%        36.8 25%         186 25%       3350 \n2 Adelie    50%             18.4 50%        38.8 50%         190 50%       3700 \n3 Adelie    75%             19   75%        40.8 75%         195 75%       4000 \n4 Chinstrap 25%             17.5 25%        46.3 25%         191 25%       3488.\n5 Chinstrap 50%             18.4 50%        49.6 50%         196 50%       3700 \n6 Chinstrap 75%             19.4 75%        51.1 75%         201 75%       3950 \n7 Gentoo    25%             14.2 25%        45.3 25%         212 25%       4700 \n8 Gentoo    50%             15   50%        47.3 50%         216 50%       5000 \n9 Gentoo    75%             15.7 75%        49.6 75%         221 75%       5500 \n# … with abbreviated variable names ¹​bill_depth_mm_name, ²​bill_depth_mm_value,\n#   ³​bill_length_mm_name, ⁴​bill_length_mm_value, ⁵​flipper_length_mm_name,\n#   ⁶​flipper_length_mm_value, ⁷​body_mass_g_name, ⁸​body_mass_g_value\n\n\n\n\n리스트와 리스트가 중첩된 복잡한 데이터프레임을 풀려면 unnest() 함수를 두 번 사용하면 됩니다. 복잡하게 중첩된 데이터라면 hoist(), unnest_wider(), unnest_longer() 함수를 사용하면 좋습니다. 위 3개의 함수는 이른바 rectangling 작업에 사용되는 함수인데 이 녀석들은 나중에 따로 정리해보겠습니다.\n\ndf2 <- tibble(\n  a = list(c(\"a\", \"b\"), \"c\"),\n  b = list(1:2, 3),\n  c = c(11, 22)\n)\n\ndf2\n\n# A tibble: 2 × 3\n  a         b             c\n  <list>    <list>    <dbl>\n1 <chr [2]> <int [2]>    11\n2 <chr [1]> <dbl [1]>    22\n\n# unnest를 이용해 동시에 여러 열의 중첩을 해제할 수 있습니다.\ndf2 |> unnest(c(a, b))\n\n# A tibble: 3 × 3\n  a         b     c\n  <chr> <dbl> <dbl>\n1 a         1    11\n2 b         2    11\n3 c         3    22\n\n# 단계적으로 중첩을 해제하면 다음과 같은 결과를 얻습니다.\ndf2 |> unnest(a) |> unnest(b)\n\n# A tibble: 5 × 3\n  a         b     c\n  <chr> <dbl> <dbl>\n1 a         1    11\n2 a         2    11\n3 b         1    11\n4 b         2    11\n5 c         3    22"
  },
  {
    "objectID": "daily/211007/index.html",
    "href": "daily/211007/index.html",
    "title": "jsonedit() : Provide a interactive view of lists",
    "section": "",
    "text": "오늘의 함수는 listviewer 패키지의 jsonedit() 함수입니다. listviewer 패키지는 list 형태의 데이터를 인터랙티브 페이지에서 수정할 수 있는 함수들을 제공합니다. 그 중 하나인 jsonedit() 함수를 살펴보도록 하겠습니다.\n\n\n\njsonedit(listdata = NULL, \n         mode = \"tree\", \n         modes = c(\"code\", \"form\", \"text\", \"tree\", \"view\"),\n         ..., \n         width = NULL, \n         height = NULL,\n         elementId = NULL)\n\n\n\nlistdata : 확인할 list, string 데이터를 넣습니다. list를 위한 함수이지만 다른 형태의 데이터도 JSON으로 변환되기 때문에 데이터프레임을 넣어도 사실 상관없습니다 mode : 인터랙티브 페이지에 처음으로 뜨는 mode를 설정합니다. 기본값은 tree입니다.\n\n\n\nlibrary(tibble)\nlibrary(listviewer)\n\n# tibble 함수를 통해 중첩된 tibble을 만들어보겠습니다.\ndf1 <- tibble(\n  x = 1:3,\n  y = list(\n    NULL,\n    tibble(a = 1, b = 2),\n    tibble(a = 1:3, b = 3:1)\n  )\n)\n\n# jsonedit 함수로 df1 살펴보기\njsonedit(df1)\n\n\n\n\n# data.frame도 jsonedit 함수에 입력이 가능합니다\njsonedit(mtcars)"
  },
  {
    "objectID": "daily/211008/index.html",
    "href": "daily/211008/index.html",
    "title": "accumulate() : Accumulate intermediate results",
    "section": "",
    "text": "오늘의 함수는 purrr 패키지의 accumulate() 함수입니다. Two-Table Verbs 함수를 사용해서 3개 이상의 데이터테이블을 처리할 땐 reduce() 함수를 사용합니다. 그런데 그와 유사한 accumulate() 함수는 중간 단계를 모두 유지해줍니다.\n\n\n\naccumulate(.x, .f, ..., .init, .dir = c(\"forward\", \"backward\"))\n\naccumulate2(.x, .y, .f, ..., .init)\n\n\n\n.x : 리스트나 atomic vector가 들어갑니다 .f : accumulate() 함수에서는 Two-Table Verbs 함수가, accumulate2() 함수에는 그 이상의 함수를 사용할 수 있습니다. .dir : accumulate의 방향을 정합니다.\n\n\n\nlibrary(tidyverse)\nlibrary(purrr)\n\nnumber <- sample(10)\nnumber\n\n [1]  1  2  4  7  8  3 10  9  6  5\n\n# reduce 함수로 다 더하면?\nnumber |> reduce(`+`)\n\n[1] 55\n\n# accumulate는 각 단계를 유지해서 누적합을 계산합니다.\nnumber |> accumulate(`+`)\n\n [1]  1  3  7 14 22 25 35 44 50 55"
  },
  {
    "objectID": "daily/211012/index.html",
    "href": "daily/211012/index.html",
    "title": "enframe() : Convert vectors to data frames",
    "section": "",
    "text": "오늘의 함수는 tibble 패키지의 enframe() 함수입니다. enframe() 함수는 atomic vector나 리스트를 1개 혹은 2개의 칼럼을 가진 데이터프레임으로 만들어줍니다. 리스트를 enframe() 함수에 넣고 돌리면 중첩된 tibble이 나옵니다. 만일 2개의 칼럼의 데이터프레임을 vector 혹은 리스트로 변환하고 싶으면 deframe() 함수를 사용하면 됩니다.\n\n\n\n\nenframe(x, name = \"name\", value = \"value\")\n\ndeframe(x)\n\n\n\n\n\nx : enframe() 함수에는 벡터가, deframe() 함수에는 1~2열 짜리 데이터프레임이 들어갑니다  name, value : name과 value로 지정하고 싶은 텍스트를 입력합니다. 만약 name이 NULL이라면 1열의 데이터프레임이 출력됩니다.\n\n\n\n\n\nlibrary(tibble)\n\n# 1부터 3까지 Unnamed Numeric vector를 enframe에 넣으면\nenframe(1:3)\n\n# A tibble: 3 × 2\n   name value\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# 이번엔 Named Numeric vector를 입력해봅니다\nenframe(c(a = 1, b = 2, c = 3))\n\n# A tibble: 3 × 2\n  name  value\n  &lt;chr&gt; &lt;dbl&gt;\n1 a         1\n2 b         2\n3 c         3\n\n# list를 입력하면 중첩된 tibble이 나옵니다\nlist_example &lt;- list(\n  a = 1,\n  b = \"orange\",\n  c = 2:3,\n  d = c(delta = 4)\n)\n\nenframe(list_example)\n\n# A tibble: 4 × 2\n  name  value    \n  &lt;chr&gt; &lt;list&gt;   \n1 a     &lt;dbl [1]&gt;\n2 b     &lt;chr [1]&gt;\n3 c     &lt;int [2]&gt;\n4 d     &lt;dbl [1]&gt;\n\n# deframe은 1~2개의 칼럼을 가지고 있는 데이터프레임만 사용가능합니다\ndeframe(enframe(3:1))\n\n1 2 3 \n3 2 1 \n\ndeframe(tibble(a = as.list(1:3)))\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3"
  },
  {
    "objectID": "daily/211013/index.html",
    "href": "daily/211013/index.html",
    "title": "reduce() : Reduce a list to a single value",
    "section": "",
    "text": "오늘의 함수는 purrr 패키지의 reduce() 함수입니다. r에서 데이터테이블을 join하거나 교집합(intersect)을 한다거나 혹은 합집합(union)을 하려면 테이블이 2개일 경우에만 가능합니다. 그래서 이런 함수들을 Two-Table Verbs라고도 하죠. 그런데 그 이상의 데이터테이블을 가지고 교집합, 합집한 등의 함수를 적용하고 싶다면 어떻게 해야할까요? 그럴 때 사용하는 함수가 바로 reduce()입니다. reduce()함수는 벡터의 요소를 하나의 값으로 결합, 반복해주는 작업을 실행합니다. 이런 식입니다. 1:3에다가 f라는 함수를 reduce()하면 f(f(1, 2), 3) 이런 식으로 적용합니다.\n\n\n\n\nreduce(.x, .f, ..., .init, .dir = c(\"forward\", \"backward\"))\n\nreduce2(.x, .y, .f, ..., .init)\n\n\n\n\n\n.x : 리스트나 atomic vector가 들어갑니다  .f : reduce() 함수에서는 Two-Table Verbs 함수가, reduce2() 함수에는 그 이상의 함수를 사용할 수 있습니다.  .dir : reduce의 방향을 정합니다.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(purrr)\n\n# +로 예를 들어봅시다 1부터 3까지 reduce 함수로 더해봅니다\n1:3 |&gt; reduce(`+`)\n\n[1] 6\n\nreduce(1:3, `+`)\n\n[1] 6\n\n# 이번엔 1부터 10까지 곱해보겠습니다\nreduce(1:10, `*`)\n\n[1] 3628800\n\n# 10!과 값이 당연히 같습니다\nfactorial(10)\n\n[1] 3628800\n\n# dplyr 패키지의 join 함수를 reduce 함수와 함께 써보겠습니다\ndfs &lt;- list(\n  age = tibble(name = \"John\", age = 30),\n  sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n  trt = tibble(name = \"Mary\", treatment = \"A\")\n)\ndfs\n\n$age\n# A tibble: 1 × 2\n  name    age\n  &lt;chr&gt; &lt;dbl&gt;\n1 John     30\n\n$sex\n# A tibble: 2 × 2\n  name  sex  \n  &lt;chr&gt; &lt;chr&gt;\n1 John  M    \n2 Mary  F    \n\n$trt\n# A tibble: 1 × 2\n  name  treatment\n  &lt;chr&gt; &lt;chr&gt;    \n1 Mary  A        \n\ndfs |&gt;reduce(full_join)\n\n# A tibble: 2 × 4\n  name    age sex   treatment\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n1 John     30 M     &lt;NA&gt;     \n2 Mary     NA F     A        \n\n\n\n\n\nreduce를 적용할 함수 f가 덧셈이나 곱셈처럼 순서가 안 중요한 함수일 수 있지만 대부분의 다른 함수에서는 순서가 중요할 수 있습니다.\n\n# + 는 방향을 뒤로해도 결과가 달라지지 않습니다. 당연하게도\nreduce(1:3, `+`)\n\n[1] 6\n\nreduce(1:3, `+`, .dir = \"backward\")\n\n[1] 6\n\n# 하지만 다른 함수는 순서가 중요합니다\nstr(reduce(1:4, list))\n\nList of 2\n $ :List of 2\n  ..$ :List of 2\n  .. ..$ : int 1\n  .. ..$ : int 2\n  ..$ : int 3\n $ : int 4\n\nstr(reduce(1:4, list, .dir = \"backward\"))\n\nList of 2\n $ : int 1\n $ :List of 2\n  ..$ : int 2\n  ..$ :List of 2\n  .. ..$ : int 3\n  .. ..$ : int 4"
  },
  {
    "objectID": "daily/211014/index.html",
    "href": "daily/211014/index.html",
    "title": "accumulate() : Accumulate intermediate results",
    "section": "",
    "text": "오늘의 함수는 purrr 패키지의 accumulate() 함수입니다. Two-Table Verbs 함수를 사용해서 3개 이상의 데이터테이블을 처리할 땐 reduce() 함수를 사용합니다. 그런데 그와 유사한 accumulate() 함수는 중간 단계를 모두 유지해줍니다.\n\n\n\n\naccumulate(.x, .f, ..., .init, .dir = c(\"forward\", \"backward\"))\n\naccumulate2(.x, .y, .f, ..., .init)\n\n\n\n\n\n.x : 리스트나 atomic vector가 들어갑니다  .f : accumulate() 함수에서는 Two-Table Verbs 함수가, accumulate2() 함수에는 그 이상의 함수를 사용할 수 있습니다.  .dir : accumulate의 방향을 정합니다.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(purrr)\n\nnumber &lt;- sample(10)\nnumber\n\n [1]  6 10  8  9  3  2  7  4  1  5\n\n# reduce 함수로 다 더하면?\nnumber |&gt; reduce(`+`)\n\n[1] 55\n\n# accumulate는 각 단계를 유지해서 누적합을 계산합니다.\nnumber |&gt; accumulate(`+`)\n\n [1]  6 16 24 33 36 38 45 49 50 55"
  },
  {
    "objectID": "daily/211011/index.html",
    "href": "daily/211011/index.html",
    "title": "say() : Print messages with various animals",
    "section": "",
    "text": "오늘의 함수는 cowsay 패키지의 say() 함수입니다. 패키지 이름에서 알 수 있듯 say() 함수를 사용하면 소를 비롯한 여러 동물들의 아스키 아트로 텍스트를 출력할 수 있습니다. 아스키 아트는 텍스트와 특수문자만을 이용해서 그림을 표현하는 것을 말합니다.\n\n\n\nsay(what = \"Hello world!\",\n    by = \"cat\",\n    type = NULL,\n    what_color = NULL,\n    by_color = NULL,\n    length = 18,\n    fortune = NULL,\n    ...\n)\n\n\n\nwhat : 출력하고 싶은 말을 넣으세요 by : 어떤 동물이 말을 하도록 하고 싶나요? type : message(기본값), warning, print, string 등 출력 타입을 선택합니다 what_color : 출력할 말의 색깔을 정합니다 by_color : 동물의 색깔을 정합니다 length : 만일 longcat을 선택했다면 longcat의 길이를 정해주세요\n\n\n\nlibrary(cowsay)\n\n# 닭이 꼬끼오하고 울게 해보겠습니다.\nsay(\"꼬끼오\", by = \"chicken\")\n\n\n ----- \n꼬끼오 \n ------ \n    \\   \n     \\\n         _\n       _/ }\n      `>' \\\n      `|   \\\n       |   /'-.     .-.\n        \\'     ';`--' .'\n         \\'.    `'-./\n          '.`-..-;`\n            `;-..'\n            _| _|\n            /` /` [nosig]\n  \n\n# cowsay 패키지에서 제공해주는 아스키아트는 총 44마리입니다.\nsort(names(animals))\n\n [1] \"ant\"          \"anxiouscat\"   \"bat\"          \"bat2\"         \"behindcat\"   \n [6] \"bigcat\"       \"buffalo\"      \"cat\"          \"chicken\"      \"chuck\"       \n[11] \"clippy\"       \"cow\"          \"daemon\"       \"duck\"         \"duckling\"    \n[16] \"egret\"        \"endlesshorse\" \"facecat\"      \"fish\"         \"frog\"        \n[21] \"ghost\"        \"grumpycat\"    \"hypnotoad\"    \"longcat\"      \"longtailcat\" \n[26] \"monkey\"       \"mushroom\"     \"owl\"          \"pig\"          \"poop\"        \n[31] \"pumpkin\"      \"rabbit\"       \"shark\"        \"shortcat\"     \"signbunny\"   \n[36] \"smallcat\"     \"snowman\"      \"spider\"       \"squirrel\"     \"squirrel2\"   \n[41] \"stretchycat\"  \"trilobite\"    \"turkey\"       \"yoda\"        \n\n# 아스키아트에는 cat()함수를 이용해 접근할 수 있습니다.\n# 호박 아스키아트에 접근해보죠.\npumpkin <- animals[[\"pumpkin\"]]\ncat(pumpkin)\n\n\n ----- \n%s \n ------ \n    \\   \n     \\\n                  ___\n               ___)__|_\n          .-*'          '*-,\n         /      /|   |\\     \\\n        ;      /_|   |_\\     ;\n        ;   |\\           /|  ;\n        ;   | ''--...--'' |  ;\n         \\  ''---.....--''  /\n          ''*-.,_______,.-*'  [nosig]\n  \n\n# longcat에게 말을 시킨다면 longcat의 길이도 정해주세요\nsay(what = \"음메\",\n    by = \"longcat\",\n    length = \"20\")\n\n\n ----- \n음메 \n ------ \n    \\   \n     \\\n    .ﾊ,,ﾊ\n    ( ﾟωﾟ)\n    |つ  つ\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    |    |\n    U \"  U\n        [BoingBoing]"
  },
  {
    "objectID": "posts/230101_purrr/index.html",
    "href": "posts/230101_purrr/index.html",
    "title": "pure function과 친해지려면 purrr 합시다",
    "section": "",
    "text": "데이터를 요리조리 만지다보면, 혹은 R을 조금 더 본격 프로그래밍적으로 접근하고 싶어서 이것저것 찾다보면 purrr 패키지를 만나게 됩니다. 마침 작년 12월 20일에 purrr 패키지 1.0.0 버전이 출시되었으니 새해를 여는 R쓸 이야기의 주인공으로 purrr 패키지를 골라봤습니다.\n\n\n\n“It’s designed to make your pure functions purrr”\n\npurrr 패키지가 세상에 처음으로 선을 보인건 2015년 9월입니다. 9월 29일 rstudio blog에 purrr 0.1.0을 올리며 쓴 포스트를 보면 왜 purrr 패키지를 만들었는지 알 수 있죠. “이 패키지는 당신의 순수한 함수를 그르릉되게 만들도록 설계되었습니다.” 이 문장의 표현대로 purrr 패키지는 R의 함수형 프로그래밍(FP)의 빈틈을 채워주는 패키지입니다.\n그런데 이름은 왜 purrr로 정해졌을까요? purr라는 단어의 원래 뜻은 “그르렁대다”입니다. 그 영향으로 로고에는 귀여운 고양이가 담겨있죠. tidyverse 깃허브를 구경하다 보면, 당시 개발자들이 훗날 purrr가 될 새로운 패키지에 어떤 이름을 붙일지 고민한 흔적을 확인할 수 있습니다. 그 흔적을 살펴보면 purrr라는 작명의 이유를 찾을 수 있죠.\n당시 함수형 프로그래밍 패키지 이름의 첫 번째 후보는 purr였습니다. 순수한 함수(pure function)와 어울리게 pure로도 읽을 수 있고, 함수(function → purpose → purr)라는 단어의 흔적도 담을 수 있으니 괜찮아 보입니다. 또 다른 후보는 funr이었어요. fun한 패키지면서도 function, 즉 함수형 프로그래밍의 의미를 담으려 했죠. funr 외에도 funcr, funkr, funker 등이 function의 흔적이 담긴 이름 후보들이었습니다. 최종적으로는 purr에 R이 더해져 purrr이 되었죠.\n\n\n그런데 여기서 이야기하는 함수형 프로그래밍(FP, Functional Programming)은 뭘까요? 프로그래밍은 크게 명령형 프로그래밍(Imperative Programming)과 선언형 프로그래밍(Declarative Programming)으로 구분할 수 있습니다. 물론 엄밀하게 구분하면 아래와 같은 지도같이 더 복잡하게 구분할 수도 있는데, 우리는 purrr 패키지를 이해하는 게 우선이니 명령형과 선언형으로만 구분해 보겠습니다.\n\n\nOverview of the various programming paradigms according to Peter Van Roy\n\n명령형 프로그래밍은 프로그래밍의 상태와 상태를 변형시키는 구문의 관점에서 연산을 설명합니다. 우리가 일반적으로 누군가에게 명령(혹은 부탁)을 할 때 어떤 동작을 할 것인지를 표현하는 것처럼, 명령형 프로그래밍은 컴퓨터에게도 컴퓨터가 수행할 명령을 순서대로 말하는 방식을 의미합니다. 즉 명령형 프로그래밍은 컴퓨터에게 무엇(What)을 할 것인지에 방점을 찍어 설명하는 게 아니라 어떻게(How)할 것인지에 중심을 두고 설명합니다.\n반면 선언형 프로그래밍은 어떻게(How)가 메인이 아니라 무엇(What)이 메인인 프로그래밍 방법입니다. 웹 페이지나 블로그의 코드를 생각해 보죠. 우리는 블로그의 코드를 작성할 때 제목과 본문, 그림, 폰트와 같이 무엇(What)이 화면에 나타나야 하는지를 코드로 표현합니다. 이런 접근방식을 선언형 프로그래밍이라고 합니다.\n함수형 프로그래밍은 선언형 프로그래밍에 속합니다. 이름에서 알 수 있듯이 함수를 조합해서 소프트웨어를 만드는 방식을 의미하죠. 함수형 프로그래밍은 거의 모든 것을 함수로 접근합니다. 아무리 작은 것도 함수로 표현하려고 합니다. 이렇게 하면 코드 가독성이 높아지고, 코드의 유지보수가 용이해진다는 장점이 있어요. 참고로 함수형 프로그래밍은 람다 대수라는 대수 체계를 기반으로 발전했는데, 그래서 lambda라는 이름이 purrr 패키지의 또다른 후보이기도 했죠."
  },
  {
    "objectID": "posts/230101_purrr/index.html#all-about-tibble",
    "href": "posts/230101_purrr/index.html#all-about-tibble",
    "title": "pure function과 친해지려면 purrr 합시다",
    "section": "All about tibble",
    "text": "All about tibble\nas.tibble\n아이리스(붓꽃) 데이터가 담겨있는 iris 데이터를 가지고 살펴보겠습니다. 총 150개의 로(row)와 5개의 칼럼(column)으로 이뤄진 데이터프레임(data.frame)입니다. 만일 코드에 그냥 iris라고 입력한다면 콘솔창에는 150개의 행을 보실 수 있을텐데요. 그걸 막기 위해 iris 데이터의 머릿부분만 불러오라는 함수 head( )를 써보았어요.\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n이번엔 tibble 패키지를 이용해볼까요. 여기서 사용할 함수는 as_tibble( )입니다. 무언가를 tibble로 만들어주는 고마운 함수입니다. 새로운 iris tibble 녀석을 tbl_iris에 할당했습니다. 그리고 불러와봅시다. tibble은 그냥 tbl_iris라고 입력해도 콘솔창을 다 뒤덮지않는군요. 10개의 행을 보여주고는 나머지 140개가 남아있다고 깨알같이 설명해줍니다. 게다가 5개의 칼럼이 어떤 녀석인지 밑에다가 자료형을 설명해주고 있군요. 착한 녀석이죠. 혹여나 이러한 편의를 무시하고 모든 행을 다 보고 싶은 경우에는 옵션을 통해 바꿔줄 수 있습니다.\n\nlibrary(tibble)\n\ntbl_iris <- as_tibble(iris)\ntbl_iris\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# … with 140 more rows\n\n# 행이 n개를 넘어가면 m개만 출력하고 싶다면\n# options(tibble.print_max = n, tibble.print_min = m)\n\n# 모든 행을 다 보고 싶다면\n# option(tibble.print_max = Inf)\n\n# 콘솔창의 폭은 고려말고 모든 열을 다 보고 싶다면\n# option(tibble.width = Inf)\n\n\ntibble\n본격적으로 tibble을 만들어봅니다. tibble( )을 이용하면 후딱 tibble을 생성할 수 있답니다. tibble( ) 함수는 data.frame( ) 함수와는 다르게 변수의 이름을 바꾸지 않아요. 예를 들어볼게요. 오렌지 맨숀라는 칼럼에 숫자 1을 넣은 data.frame을 만들어볼거에요. 동일하게 tibble로도 만들어보고요.\n\n# 오렌지 맨숀이라는 이름의 칼럼을 가진 데이터를 만들어봅니다\n\nlibrary(tibble)\n\ndata.frame(`오렌지 맨숀` = 1)\n\n  오렌지.맨숀\n1           1\n\ntibble(`오렌지 맨숀` = 1)\n\n# A tibble: 1 × 1\n  `오렌지 맨숀`\n          <dbl>\n1             1\n\n\n칼럼 이름에 공백이 들어가게 되면 data.frame은 공백을 온점으로 바꿔줍니다. 오렌지 맨숀 대신 오렌지.맨숀이 되었죠? 반면 tibble은 변수의 이름을 바꾸지 않고 그대로 내비두죠. 이러한 tibble의 유연함은 공백말고 다른 비정상적인 문자도 칼럼 이름에 넣을 수 있게 했어요.\n\n# tibble은 비정상적 문자도 칼럼명에 넣을 수 있습니다\n# 물론 백틱(`)으로 묶어야 합니다\n\ntb <- tibble(\n  `:^)` = \"smile\", \n  ` ` = \"space\",\n  `2021` = \"number\"\n)\n\ntb\n\n# A tibble: 1 × 3\n  `:^)` ` `   `2021`\n  <chr> <chr> <chr> \n1 smile space number\n\n\n\ntribble\n\ntibble을 만들 수 있는 또다른 방법은 함수 tribble을 사용하는겁니다. 스타 트렉의 커크 함장에게 눈처럼 내리는 동물이 바로 트리블이랍니다. 트리블은 복실복실한 털과 귀여운 목소리 탓에 애완용으로 많이 키워졌는데 다만 한가지 주의해야할 부분은 바로 번식이랍니다. 한 번 번식을 시작하면 끝도 없이 증식해버려서 자칫하면 손을 쓸 수 없을지도 몰라요.\ntibble 패키지에 있는 tribble은 transposed tibble의 줄임말입니다. 단어 그대로 전치된 티블이라는 뜻이지요. 기존의 tibble 입력 형식이 colname = data 같은 가로형이었다면 tribble에서는 세로형으로 입력할 수 있지요. 간단하게 적은 양의 데이터를 코드로 입력할 때에는 tribble을 쓰면 편리합니다.\n\n# tribble 함수에서 칼럼명은 ~로 시작해야 합니다\n# 데이터 구분은 ,로 하고요\n\ntribble(\n  ~x, ~y, ~z,\n  \"a\", 21, \"2000\",\n  \"b\", 31, \"1990\"\n)\n\n# A tibble: 2 × 3\n  x         y z    \n  <chr> <dbl> <chr>\n1 a        21 2000 \n2 b        31 1990 \n\n\n\ntibble_row\ntibble을 만들 수 있는 또 다른 방법. tibble_row( )가 있어요. 기본적으로 data.frame과 tibble은 벡터들의 모음입니다. 여기서 잠깐, 벡터는 동일한 유형의 데이터가 여러개 묶여있는 형식을 뜻해요. 수치형 벡터도 있을 테고, 문자형 벡터도 있을 거고요, 논리형 벡터도 존재해요. 함수 등과 같이 특별한 타입의 데이터들은 벡터가 아니여요. class를 가지고 있는 일부 요소들은 벡터이기도 하고 아닌 녀석도 있죠.\ntibble_row 이야기를 하는데 갑자기 벡터 이야기를 해서 뜬금없다고 생각할 수 있지만 다 이유가 있답니다. 기존 함수들로는 벡터가 아닌 데이터(스칼라)를 tibble 안에 담을 수 없었어요. 하지만 tibble_row 함수와 함께라면 스칼라도 tibble 안에 넣을 수 있게 되죠. tibble_row 함수는 한 행(row)을 차지하는 데이터프레임을 구성해줍니다. 즉 한 열에 크기가 1인 녀석만 들어갈 수 있지만 그 대신 스칼라 데이터도 넣을 수 있게 된 거죠. 참고로 저장되는 스칼라는 list 형태로 포장됩니다.\n\n# vector가 아닌 scalar 데이터를 만들어봅니다\n# lm(linear model)과 time 데이터를 써 보겠습니다\n\nmodel <- lm(y ~ x, data.frame(x = 1:5, y = 3:7), model = FALSE)\ntime <- Sys.time()\n\ntibble(time)\n\n# A tibble: 1 × 1\n  time               \n  <dttm>             \n1 2023-01-01 16:07:50\n\n\nmodel의 경우 vector가 아니여서 tibble에 담기지 않아요. 반면 time 데이터는 들어갈 수 있어요. 하지만 tibble_row 함수를 사용한다면 어떨까요. tibble_row와 함께라면 vector와 scalar 상관없이 tibble에 담을 수 있습니다.\n\ntibble_row(model)\n\n# A tibble: 1 × 1\n  model \n  <list>\n1 <lm>"
  },
  {
    "objectID": "posts/230101_purrr/index.html#all-about-purrr",
    "href": "posts/230101_purrr/index.html#all-about-purrr",
    "title": "pure function과 친해지려면 purrr 합시다",
    "section": "All about purrr",
    "text": "All about purrr\nmap\npurrr 패키지의 알파이자 오메가인 map( ) 함수를 살펴보겠습니다. 아까 위에서 함수형 프로그래밍은 거의 모든 것을 함수로 생각한다고 했죠? 함수형 프로그래밍에서는 함수조차도 값으로 취급합니다. 그래서 함수를 다루는 함수도 존재하죠.\n예를 들어 1부터 10까지의 숫자를 제곱한다고 해봅시다. 명령형 프로그래밍에선 반복문을 이용해 숫자들을 제곱해 나갈겁니다. 반면 함수형 프로그래밍에선 인수를 제곱하는 함수를 또 다른 함수의 인수로 전달하는 함수의 함수, 이름하여 고차 함수(고계 함수)를 이용해 접근합니다.\n대표적인 게 바로 하스켈의 map함수입니다. 하스켈의 map함수는 purrr에서도 동일하게 등장합니다. map함수의 map은 수학에서 의미하는 매핑(mapping, 사상), 즉 일반적인 의미의 함수를 뜻합니다. 참고로 하스켈은 순수 함수형 프로그래밍 언어인데요, 하스켈 코드는 부작용(side effect)이 없다(!)는 장점을 가지고 있기도 하죠.\n\n\nxkce_Haskell\n\nr에서 명령형 프로그래밍 방법과 함수형 프로그래밍 방법에 따라 1부터 10까지의 숫자들을 제곱해 보겠습니다. 먼저 나만의 소중한 제곱 함수를 만들어놓고 시작해 보죠. for loop에서는 1부터 10까지 각각의 i에 my_square( ) 함수를 적용했습니다. 함수형 프로그래밍에선 고차함수 map( )에 my_square( )라는 함수를 값으로 취급해 넣었습니다. 당연히 두 결과는 같습니다.\n\nlibrary(purrr)\n\n# 나만의 소중한 제곱 함수\nmy_square &lt;- function(x) {\n  x^2\n}\n\n# 명령형 프로그래밍(for loop)\nfor (i in 1:10){\n  print(my_square(i))\n}\n\n[1] 1\n[1] 4\n[1] 9\n[1] 16\n[1] 25\n[1] 36\n[1] 49\n[1] 64\n[1] 81\n[1] 100\n\n# 함수형 프로그래밍(map)\n1:10 |&gt;\n  map(my_square)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n[[6]]\n[1] 36\n\n[[7]]\n[1] 49\n\n[[8]]\n[1] 64\n\n[[9]]\n[1] 81\n\n[[10]]\n[1] 100\n\n\n전통적인 명령형 함수에서는 모든 함수에 이름이 부여되어야 했지만 함수형 언어에서는 익명으로 처리할 수도 있습니다. 기존 R에서는 function(x) {...} 구문으로 표시해왔지만 R 4.1.0에서는 하스켈 문법과 동일하게 \\(역빗금)으로 익명 함수 구문을 표현할 수 있게 되었습니다. 여기서 \\(역빗금)은 람다를 의미하죠.\ndog, cats, rats 이렇게 세 단어 중 “at”가 포함된 단어를 골라내는 함수를 적용해보겠습니다. 기존 R 문법 스타일로는 “at”를 찾으라는 함수를 function(x) grepl(\"at\", x) 이렇게 표시했지만 R 4.1.0부터는 \\(x) grepl(\"at\", x)라고만 해도 됩니다.\n\n# 기존 R 문법에서 익명 함수 처리\nc(\"dogs\", \"cats\", \"rats\") |&gt;\n  {function(x) grepl(\"at\", x)}()\n\n[1] FALSE  TRUE  TRUE\n\n# R 4.1.0에서 익명 함수 처리\nc(\"dogs\", \"cats\", \"rats\") |&gt;\n  {\\(x) grepl(\"at\", x)}()\n\n[1] FALSE  TRUE  TRUE\n\n# 제곱함수도 익명 함수 구문으로 처리\n1:10 |&gt;\n  map(\\(x) x^2)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 9\n\n[[4]]\n[1] 16\n\n[[5]]\n[1] 25\n\n[[6]]\n[1] 36\n\n[[7]]\n[1] 49\n\n[[8]]\n[1] 64\n\n[[9]]\n[1] 81\n\n[[10]]\n[1] 100\n\n\npurrr 패키지에는 map( ) 함수만 해도 map_dbl( ), map_lgl( ), map_int( ), map_int( ) 등 딸린 식구들이 많습니다. 거기에 map2, pmap, imap, keep, compact, pluck, modify 등 다양한 함수들이 넘쳐나죠. R쓸 패키지 이야기는 이 정도로 마무리하고 purrr에 딸려있는 나머지 다양한 함수들은 추후에 조금씩 풀어나가 보도록 하겠습니다."
  },
  {
    "objectID": "posts/230108_quarto_yaml/index.html",
    "href": "posts/230108_quarto_yaml/index.html",
    "title": "뜯어먹는 Quarto ①YAML",
    "section": "",
    "text": "R & stats illustrations by @allison_horst\n\n\n지난 게시물에선 R Markdown의 차세대 포맷, Quarto의 등장 배경에 대해 살펴봤습니다. Quarto를 한 문장으로 정리해 보면 이렇게 이야기할 수 있습니다. Quarto는 “마크다운 등 일반 텍스트 형식(.qmd, .rmd, .md)과 혼합 형식(.ipynb, jupyter notebook)을 pandoc과 knitr 패키지를 통해 PDF/Word/HTML/책/웹사이트/프레젠테이션 등 다양한 형태로 렌더링 하는 명령줄 인터페이스(CLI)다”라고요.\nR Studio나 VS code 같은 IDE로 Quarto를 이용하면 Quarto의 CLI의 모습을 엿보기 어렵지만 명령 프롬프트를 이용하면 바로 확인할 수 있습니다. 아래 이미지는 iTerm에서 quarto --help라는 명령어를 입력하면 나오는 Quarto의 개괄입니다.\n\nquarto --help\n\n\n  Usage:   quarto \n  Version: 1.2.313\n\n  Description:\n\n    Quarto CLI\n\n  Options:\n\n    -h, --help     - Show this help.                            \n    -V, --version  - Show the version number for this program.  \n\n  Commands:\n\n    render          [input] [args...]     - Render files or projects to various document types.        \n    preview         [file] [args...]      - Render and preview a document or website project.          \n    serve           [input]               - Serve a Shiny interactive document.                        \n    create          [type] [commands...]  - Create a Quarto project or extension                       \n    create-project  [dir]                 - Create a project for rendering multiple documents          \n    convert         &lt;input&gt;               - Convert documents to alternate representations.            \n    pandoc          [args...]             - Run the version of Pandoc embedded within Quarto.          \n    run             [script] [args...]    - Run a TypeScript, R, Python, or Lua script.                \n    add             &lt;extension&gt;           - Add an extension to this folder or project                 \n    install         [target...]           - Installs an extension or global dependency.                \n    publish         [provider] [path]     - Publish a document or project. Available providers include:\n    check           [target]              - Verify correct functioning of Quarto installation.         \n    help            [command]             - Show this help or the help of a sub-command.               \n\n\n\n\n\n\nQuarto라는 녀석이 CLI라는 건 그렇게 중요하지 않습니다. 왜냐면 우리가 Quarto를 이용해서 얻고자 하는 건 글을 쓰고, 블로그를 쓰고, 책을 출간하고, 발표자료를 만들려고 하는 거니까요. 그러려면 우선 Quarto 문서(.qmd)를 작성해야 합니다. 이번 게시물에선 Quarto 문서, 그 자체에 집중해서 이야기를 나눠보도록 하겠습니다. 먼저 Quarto 문서가 어떻게 구성되어 있는지 살펴보겠습니다. Quarto 문서는 크게 3가지 요소로 구분할 수 있습니다.\n\n\n\n\n\n\nMetadata: YAML header\nText: Markdown\nCode: knitr or jupyter\n\n이 세 가지 요소를 잘 버무려서 Quarto 문서를 작성하면 다양한 형태의 콘텐츠를 제작할 수 있습니다. 지금 이 게시물 역시 Metadata와 Text, Code 이렇게 3가지 요소로 만든 qmd 파일을 html로 렌더링 한 거죠.\n\n\n\n먼저 Metadata가 담겨있는 YAML header입니다. 지금 이 게시글의 YAML header는 요런 모습입니다.\n---\ntitle: '뜯어먹는 Quarto ①YAML'\ndate: '2023-01-08'\ncategories: ['R Markdown', 'Quarto', 'YAML']\ndescription: \"YAML Ain't Markup Language\"\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\nYAML header의 내용을 보면 꽤나 직관적입니다. title에는 게시물 제목이, date에는 작성 시점이, cateogories에는 이 게시물의 카테고리가 표시되어 있죠. YAML header에는 이 문서의 메타데이터를 표시해 줍니다. 메타데이터는 다른 데이터를 설명해 주는 데이터를 뜻합니다. 메타데이터의 메타(Meta)는 about(~에 관하여)과 같은 의미를 갖고 있죠. 이론을 대상으로 하는 이론을 뜻하는 메타이론(metatheory), 수학으로 수학 자체를 연구하는 메타수학(Metamathematics)의 메타와 같아요.\n\n\n\n\n두 번째는 텍스트 항목입니다.\n## Quarto 뜯어보기\n\n지난 게시물에선 R Markdown의 차세대 포맷, Quarto의 등장 배경에 대해 살펴봤습니다. \nQuarto에서는 마크업 언어의 일종인 마크다운(Markdown)을 이용해 텍스트를 작성합니다. HTML 문서를 무작정 작성하려고 하면 온갖 다양한 태그를 사용하게 되는데 그걸 일일이 작성하긴 어려우니까요. 마크다운(Markdown)을 이용하면 훨씬 쓰기 쉽고, 읽기 쉬운 형태의 문서를 쓸 수 있습니다.\n\n\n\n\n마지막은 코드입니다. R을 사용하는 사람들은 knitr 엔진을, python을 사용하는 사람들은 jupyter 엔진을 활용해 인라인 코드를 작성하고, 시각화를 구현할 수 있습니다. 이런 식으로 말이죠.\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")"
  },
  {
    "objectID": "posts/230108_quarto_yaml/index.html#quarto의-기본-구조",
    "href": "posts/230108_quarto_yaml/index.html#quarto의-기본-구조",
    "title": "My document",
    "section": "Quarto의 기본 구조",
    "text": "Quarto의 기본 구조"
  },
  {
    "objectID": "posts/230108_quarto_yaml/index.html#yaml은-마크업-문서가-아니야",
    "href": "posts/230108_quarto_yaml/index.html#yaml은-마크업-문서가-아니야",
    "title": "뜯어먹는 Quarto ①YAML",
    "section": "YAML은 마크업 문서가 아니야",
    "text": "YAML은 마크업 문서가 아니야\nQuarto 문서의 3가지 요소 중 오늘은 YAML에 대해서 조금 더 이야기를 나눠보도록 하겠습니다. YAML은 Yet Another Markup Language라는 뜻을 가진 마크업 언어입니다. [야믈], [야멜] 등으로 읽을 수 있겠습니다. YAML은 2001년 클라크 에반스가 고안한 언어로 기존의 JSON이 가지고 있는 단점(주석을 달 수 없다, 문법이 유연하지 않다)들을 해소하기 위해 만들어졌습니다.\nYAML은 마크업 언어지만 스스로 마크업 언어가 아니라고 이야기합니다. YAML을 또 다르게 풀어보면 YAML Ain’t Markup Language라고도 할 수 있거든요. “YAML은 마크업 문서가 아니다”라고 이야기하는 이유는 바로 YAML의 정체성을 마크업이 아닌 데이터에 두겠다는 거죠. JSON과 XML과 비교해 압도적으로 간결하고 가독성이 좋은 YAML은 그 형식을 살려 다양한 분야의 설정파일 역할을 하고 있습니다.\nQuarto에서도 마찬가지입니다. 서두에서 이야기한 것처럼 YAML header에는 메타데이터가 담겨있습니다. Quarto 문서의 다양한 설정을 YAML header에 담아두면 됩니다. 간단한 구조와 간결한 문법을 활용해서 말이죠. Quarto는 매번 모든 옵션을 수동으로 입력하지 않도록 하기 위해 YAML header를 활용합니다. 입력된 메타데이터들은 최종적으로 퍼블리싱되는 포맷에 영향을 주죠. 퍼블리싱, 렌더링 과정에 참여하는 pandoc, quarto, knitr이 YAML header에 담긴 정보를 읽고 처리합니다."
  },
  {
    "objectID": "posts/230108_quarto_yaml/index.html#about-yaml",
    "href": "posts/230108_quarto_yaml/index.html#about-yaml",
    "title": "뜯어먹는 Quarto ①YAML",
    "section": "About YAML",
    "text": "About YAML\n\nYAML Ain’t Markup Language\n세 요소 중에서도 YAML에 대해서 조금 더 이야기를 나눠보도록 하겠습니다. YAML은 Yet Another Markup Language라는 뜻을 가진 마크업 언어입니다. [야믈], [야멜] 등으로 읽을 수 있겠습니다. YAML은 2001년 클라크 에반스가 고안한 언어로 기존의 JSON이 가지고 있는 단점(주석을 달 수 없다, 문법이 유연하지 않다)들을 해소하기 위해 만들어졌습니다.\nYAML은 마크업 언어지만 스스로 마크업 언어가 아니라고 이야기합니다. YAML을 또 다르게 풀어보면 YAML Ain’t Markup Language라고도 할 수 있거든요. “YAML은 마크업 문서가 아니다”라고 이야기하는 이유는 바로 YAML의 정체성을 마크업이 아닌 데이터에 두겠다는 거죠. 데이터에 방점을 둔 YAML은 JSON과 XML과 비교해 압도적으로 간결하고 가독성 높은 구조로 만들어졌습니다. 직접 한 번 비교해보시면 그 차이가 느껴질겁니다. 이렇게 간결한 구조는 YAML 문서가 여러 프레임워크에서 설정파일로 자리잡는데 큰 힘이 되었어요.\n\nYAMLJSONXML\n\n\n---\nServer:\n  name: Server1\n  owner: John\n  created: 123456\n  status: active\n...\n\n\n{\n  Server: [\n    {\n    name: Server1\n    owner: John\n    created: 123456\n    status: active\n    }\n  ]\n}\n\n\n&lt;Servers&gt;\n  &lt;Server&gt;\n    &lt;name&gt;Server1&lt;/name&gt;\n    &lt;owner&gt;John&lt;/owner&gt;\n    &lt;created&gt;123456&lt;/created&gt;\n    &lt;status&gt;active&lt;/status&gt;\n  &lt;/Server&gt;\n&lt;/Servers&gt;\n\n\n\nQuarto도 마찬가지입니다. 서두에서 이야기한 것처럼 YAML header에는 메타데이터가 담겨있습니다. Quarto 문서의 다양한 설정을 YAML header에 담아두면 됩니다. 간단한 구조와 간결한 문법을 활용해서 말이죠. Quarto는 매번 모든 옵션을 수동으로 입력하지 않도록 하기 위해 YAML header를 활용합니다. 입력된 메타데이터들은 최종적으로 퍼블리싱되는 포맷에 영향을 주죠. 퍼블리싱, 렌더링 과정에 참여하는 pandoc, quarto, knitr이 YAML header에 담긴 정보를 읽고 처리합니다.\n\n\n\nQuarto with YAML\n\n\n\nR & stats illustrations by @allison_horst\n\n\n지금부터는 YAML header에 포함되는 Quarto의 옵션들을 살펴보겠습니다. 우선 가장 기본적인 Output Option입니다. 말 그대로 어떤 결과물을 만들고 싶은지를 선택하는 옵션입니다. 내가 qmd 문서를 HTML로, 혹은 PDF로, 아니면 revealjs 형태로 뽑아내고 싶다면 YAML header의 format 자리에 적어주면 됩니다. format: html 이렇게 말이죠. 참고로 format: html처럼 key값(여기선 format이 해당하겠죠)에 html이라는 value값을 대응시키는 구조를 map형식이라고 합니다.\n---\nformat: html\n---\n---\nformat: revealjs\n---\n참고로 원래 YAML에서는 ---로 열고 ...으로 닫는 게 원칙입니다. 하지만 Quarto의 YAML header에선 그것마저도 귀찮았는지 --- 하나로 열고 닫습니다.\n추가 옵션을 적으려면 적어놓은 옵션 밑에 주르륵 적으면 됩니다. 다만 하위 옵션을 적을 때에는 상위 옵션의 아랫줄에 적어야 하고 들여 쓰기를 사용해야 합니다. YAML은 들여 쓰기로 계층구조를 표현하거든요. YAML에서 들여 쓰기는 2n(2, 4, 6…) 칸을 지원합니다.\n---\nformat:\n  html:\n    toc: true  #하위 옵션은 들여 쓰기로\n    code-fold: true\n---\n또 하나 주의해야할 점, 띄어쓰기기나 줄바꿈을 맞추지 않을 경우엔 옵션이 실행되지 않습니다. YAML은 민감한 친구거든요.\n---\nformat:html  # format과 html 사이에 띄어쓰기가 없기 때문에 작동 X\n---\n---\nformat:\nhtml  # 들여 쓰기가 없기 때문에 작동 X \n---\n---\nformat:\n  html:  # 들여 쓰기는 했지만 html: 이후 value값이 없어서 작동 X\n---\n\n제대로 된 YAML 구조는 이렇습니다.\n---\nformat: html  # format과 html 사이에 띄어쓰기\n---\n---\nformat:\n  html  # 들여 쓰기 2칸\n---\n---\nformat:\n  html:\n    toc: true\n---\nR studio를 사용하고 있다면 YAML 문법을 하나하나 외우고 있을 필요는 없습니다. R studio에선 기본적으로 YAML intelligence 기능이 있거든요. 옵션을 자동완성 해주거나, 잘못된 문법이 있을 경우 강조 표시로 오류를 확인할 수 있습니다. YAML intelligence 기능을 사용하려면 Quarto CLI 0.9.44 이상의 버전이어야 합니다.\n간단하게나마 HTML format의 옵션을 살펴보겠습니다.\n\n\n\n\n\n\n\nOption\n설명\n\n\n\n\ntitle\n문서 제목\n\n\nsubtitle\n문서 부제\n\n\ndate\n문서 작성 시점\n\n\ndate-modified\n문서 편집 시점\n\n\nauthor\n문서의 작성자\n\n\nabstract\n문서 요약\n\n\nabstract-title\n문서 요약본의 제목\n\n\ndoi\nDOI(Digital Object Identifier, 디지털객체식별자) 표시\n\n\norder\n문서의 정렬 순서\n\n\n\n위의 표는 HTML format에서 제목과 작성자와 관련된 옵션을 정리한 겁니다. 옵션의 수는 너무나도 많아서 여기에다 정리하긴 어려울 것 같고요. Quarto의 공식 홈페이지를 들어가 보면 HTML option들을 확인할 수 있을 겁니다. 공식 홈페이지에는 HTML뿐 아니라 PDF, MS Word, OpenOffice, ePub, Presentations 등 다양한 포맷들의 option을 정리해두고 있습니다. 주요 포맷들의 option과 guide 링크를 소개하는 것으로 이번 게시물은 마무리하도록 하겠습니다.\n\n\n\nYAML Options\n\n\n\nFormat\nOptions Reference\n\n\n\n\nHTML\nhttps://quarto.org/docs/reference/formats/html.html\n\n\nPDF\nhttps://quarto.org/docs/reference/formats/pdf.html\n\n\nMS Word\nhttps://quarto.org/docs/reference/formats/docx.html\n\n\nOpenOffice\nhttps://quarto.org/docs/reference/formats/odt.html\n\n\nePub\nhttps://quarto.org/docs/reference/formats/epub.html\n\n\nPresentation_revealjs\nhttps://quarto.org/docs/reference/formats/presentations/revealjs.html\n\n\nPresentation_ppt\nhttps://quarto.org/docs/reference/formats/presentations/pptx.html\n\n\nPresentation_beamer\nhttps://quarto.org/docs/reference/formats/presentations/beamer.html"
  },
  {
    "objectID": "posts/230205_quarto_markdown/index.html",
    "href": "posts/230205_quarto_markdown/index.html",
    "title": "뜯어먹는 Quarto ②Markdown",
    "section": "",
    "text": "헤더(Headers) 표현법\n\n# 큰 제목(H1)은 이렇게 표현합니다\n\n## 작은 제목(H2)는 이렇게 표현하고요\n\n### 더 작은 제목(H3)는 이렇게 표현합니다\n우선 게시물의 제목을 표현하는데 사용하는 헤더의 표현 방식입니다. #을 이용해서 레벨을 구분지을 수 있습니다. #을 하나만 사용하면 가장 큰 제목(1st Level Header)를 표현할 수 있고, ##처럼 #을 2개를 사용하면 다음 레벨의 헤더를 쓸 수 있죠. 참고로 오렌지 맨숀 블로그에서 가장 큰 제목은 2nd level의 헤더(H2)와 4th level(4H)를 사용하고 있고요."
  },
  {
    "objectID": "posts/230205_quarto_markdown/index.html#작은-제목h2는-이렇게-표현하고요",
    "href": "posts/230205_quarto_markdown/index.html#작은-제목h2는-이렇게-표현하고요",
    "title": "뜯어먹는 Quarto ②Markdown",
    "section": "작은 제목(H2)는 이렇게 표현하고요",
    "text": "작은 제목(H2)는 이렇게 표현하고요\n\n더 작은 제목(H3)는 이렇게 표현합니다."
  },
  {
    "objectID": "posts/230205_quarto_markdown/index.html#markdown-문법-정리",
    "href": "posts/230205_quarto_markdown/index.html#markdown-문법-정리",
    "title": "뜯어먹는 Quarto ②Markdown",
    "section": "Markdown 문법 정리",
    "text": "Markdown 문법 정리\n\nHeaders\n머리글(Headers) 표현법\n\n# 큰 제목(H1)은 이렇게 표현합니다\n\n## 작은 제목(H2)는 이렇게 표현하고요\n\n### 더 작은 제목(H3)는 이렇게 표현합니다\n우선 게시물의 제목을 표현하는데 사용하는 머리글의 표현 방식입니다. #을 이용해서 머리글의 레벨을 구분지을 수 있습니다. #을 하나만 사용하면 가장 큰 제목(1st Level Header)를 표현할 수 있고, ##처럼 #을 2개를 사용하면 다음 레벨의 헤더를 쓸 수 있죠. #의 갯수를 늘려가면 H1부터 최대 H6 단계까지의 글 제목을 사용할 수 있어요. 참고로 오렌지 맨숀 블로그에서 가장 큰 제목은 2nd level의 헤더(H2)이고 소제목은 4th level(H4)를 사용하고 있습니다.\n\n\n\nText formattings\n주요 텍스트 서식\n\n**bold(강조)**\n*italics(이탤릭)*\n~~strikethrough(취소선)~~\n\nsupersript(윗첨자)^2^\nsubscript(아래첨자)~2~\n이번엔 볼드, 이탤릭같은 텍스트 서식을 마크다운 문법으로 어떻게 표현하는지 살펴보겠습니다. 볼드와 이탤릭은 모두 *를 이용해 표현합니다. **이렇게 별표를 두 번 사용하면 강조가 되고, 하나만 사용하면 이탤릭으로 표현할 수 있죠. 취소선은 ~표시를 활용하면 됩니다. 이렇게 말이죠\n첨자 표시는 ^와 ~를 사용해서 표현할 수 있습니다. 윗첨자는 ^을 이용해서 나타내면 되고, 아래첨자는 ~를 쓰면 됩니다. 취소선에선 ~가 2개 사용됐지만 아래첨자에선 하나만 사용됩니다.\n**밤편지**\n\n이 밤 그날의 *반딧불*을  \n당신의 창 가까이 보낼게요  \n음 사랑^1^한다는 말이에요  \n\n나 우리의 첫 ~~입맞춤~~을 떠올려  \n그럼 언제든 눈~2~을 감고  \n음 가장 먼 곳으로 가요  \n주요 텍스트 서식 문법을 활용해 위와 같은 문서를 작성했다고 해보죠. 마크다운 문법에 따라 아래와 같은 글이 표시될 겁니다.\n밤편지\n이 밤 그날의 반딧불을\n당신의 창 가까이 보낼게요\n음 사랑1한다는 말이에요\n나 우리의 첫 입맞춤을 떠올려\n그럼 언제든 눈2을 감고\n음 가장 먼 곳으로 가요\n\n\n\nList\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n* undordered list2  \n    Countinued(indent 4 spaces)\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nundordered list2\nCountinued(indent 4 spaces)\n\n\nordered list\nitem 2\n\nsub-item 1\n\nsub-sub-item 1"
  },
  {
    "objectID": "posts/230316_GNN_intro_1/index.html",
    "href": "posts/230316_GNN_intro_1/index.html",
    "title": "그래프는 세상 어디에나 있다",
    "section": "",
    "text": "GNN 관련 내용을 공부하면서 찾게 된 좋은 간행물이나 논문 등을 번역 및 정리해서 올리려고 합니다. 그 첫 번째 순서로 지난 2021년 9월 2일 Distill에서 발행된 &lt; A Gentle Introduction to Graph Neural Networks &gt;입니다. 당시 Google Research 소속의 다섯 연구원이 작성한 글인데요, GNN 입문자에게 적당한 설명이 있는 것 같아 정리해 보았습니다.\n\n\n\n\nDistill은 2016년부터 2021년까지 운영된 머신러닝 관련 과학 저널입니다. Explanation, Interactive Articles, Visualization 등 기존의 과학 저널에서 표현하지 않던 스토리텔링을 담아 새로운 과학 출판물을 제작했죠. 저널이니만큼 투고도 가능했지만 그러려면 Distill Template에 맞춰서 제작해야 했습니다.\n전통적인 과학 저작물을 넘어선, 새로운 과학 저널을 꿈꾸었던 Distill의 시도는 성공으로 이어지진 못했습니다. 기존 저널에서도 큰 반향을 일으키진 못했고, 논문을 작성하는 사람들이 Interactive 요소를 담아서 Distill의 Template을 맞추기도 어려웠죠. 결국 2021년 이후 Distill은 무기한 중단 중입니다.\n\n\n그렇다고 Distill이 사라진 건 아닙니다. R에서 이 Distill Template을 참조해 과학 및 기술 커뮤니케이션 용 Markdown을 만들었거든요. 이름하여 Distill for R Markdown, Distill package였죠. 과학, 기술 블로그를 만드는 데 도움을 준 Distill package는 지금은 Quarto의 Blog, Website Format으로 흡수되어 있습니다. 더 많은 사람들에게 과학 아티클을 이해하기 쉽게 표현하려 했던 Distill의 노력은 지금 이 Quarto 블로그에 남아있는 거죠.\n헤어졌던 Distill을 다시 만나게 되어 이상한 기분이 들었는지 서두가 길었습니다. 본격적으로 &lt; A Gentle Introduction to Graph Neural Networks &gt;를 정리해 보겠습니다. Distill의 원 게시글은 D3를 활용한 Interacitve 요소가 풍부하게 담겨있으니 꼭 한번 살펴보세요."
  },
  {
    "objectID": "posts/230316_GNN_intro_1/index.html#getting-started",
    "href": "posts/230316_GNN_intro_1/index.html#getting-started",
    "title": "그래프는 세상 어디에나 있다",
    "section": "Getting started",
    "text": "Getting started\n그래프는 우리 주변에서 흔히 볼 수 있습니다. 현실에 있는 사물은 다른 사물과의 연결로 정의되는 경우가 많죠. 일련의 사물들과 사물들 간의 연결은 자연스럽게 그래프로 표현됩니다. 그래프 연구자들은 GNN(Graph neural networks, 그래프 신경망)을 10년 이상 개발해 왔습니다. 최근엔 기술 발전으로 그 기능과 표현력이 더욱 향상되었죠. GNN은 항균 물질의 발견, 물리학 시뮬레이션, 가짜 뉴스 탐지, 교통 예측 및 추천 시스템 등… 다양한 분야에서 적용되고 있습니다. 이 글에서는 최신1 그래프 신경망에 대해 살펴보고 설명하려고 합니다 이 글은 크게 네 파트로 나뉩니다.\n\n1.첫 번째 파트에서는 어떤 종류의 데이터가 가장 자연스럽게 그래프로 표현되는지, 일반적인 예시와 함께 살펴봅니다.\n2.두 번째 파트에서는 그래프가 다른 유형의 데이터와는 어떻게 다른지, 그래프를 사용할 때 고려해야 하는 지점에 대해 살펴봅니다.\n3.세 번째 파트에서는 그래프 분야의 역사적인 모델링 혁신부터 시작해 모델의 각 부분을 살펴보면서 최신 GNN 모델을 설계해 보겠습니다.\n4.네 번째 파트에서는 실제 작업과 데이터 세트를 적용하면서 GNN 모델의 각 요소가 예측에 어떻게 기여하는지 살펴봅니다.\n\n먼저 그래프가 무엇인지부터 알아봅시다. 그래프는 엔티티(Nodes)들의 관계(Edges)를 나타냅니다. 그래프에는 세 타입의 속성이 존재합니다.\n\nV : Vertex(or Node) attributes, 정점 혹은 Node 속성\nE : Edge(or Link) attributes and directions, Edge 혹은 Link 속성\nU : Global (or Master node) attributes, 전역 혹은 Master Node 속성\n\n\n각각의 Node, Edge, 전체 그래프를 더 자세히 설명하기 위해 정보를 저장할 수도 있습니다. 또 Edge에 방향을 추가할 수도 있습니다. 그래프는 매우 우연한 데이터 구조입니다. 아직까지는 그래프가 약간은 추상적으로 느껴질 수 있지만 다음 섹션부터는 예시를 통해 구체적으로 설명해 보겠습니다."
  },
  {
    "objectID": "posts/230316_GNN_intro_1/index.html#part-1.-graphs-and-where-to-find-them",
    "href": "posts/230316_GNN_intro_1/index.html#part-1.-graphs-and-where-to-find-them",
    "title": "그래프는 세상 어디에나 있다",
    "section": "Part 1. Graphs and where to find them",
    "text": "Part 1. Graphs and where to find them\n그래프의 형태라고 하면 아마도 SNS의 소셜 네트워크를 떠올리는 분이 계실지 모릅니다. 하지만 그래프는 매우 강력하고 일반적인 데이터 표현입니다. 지금부터는 그래프로 모델링할 수 없다고 생각하기 쉬운 이미지 데이터와 텍스트 데이터를 가지고 이야기해 보겠습니다. 이미지와 텍스트를 그래프 구조로 보면 이미지와 텍스트의 대칭성과 구조에 대해 더 많이 배울 수 있습니다. 또 나중에 설명할 다른 그래프 데이터를 이해하는 데에도 도움이 될 수 있어요.\n\n\nImage as graphs\n일반적으로 우리는 이미지 데이터를 처리할 때 이미지 채널2이 있는 직사각형 격자로 생각합니다. 그리고 244 X 244 X 3과 같이 배열(array)로 표현하죠. 이미지 데이터를 표현하는 다른 방법은 각각의 픽셀을 Node로 생각하고 인접한 픽셀 사이를 Edge로 연결하는 겁니다. 바로 그래프 구조죠. 이를테면 가장자리에 위치하지 않은 픽셀은 8개의 이웃 픽셀을 가질 겁니다. 그리고 픽셀의 RGB 값을 나타내는 3차원 vector는 각각의 Node에 저장될 거고요.\n그래프의 연결을 시각화할 수 있는 방법 중 하나는 인접 행렬을 이용하는 것입니다. 아래 예에서는 웃는 얼굴의 픽셀 이미지(5X5)를 가지고 인접 행렬을 만들어봤습니다. 각각 25픽셀씩 Node를 정렬(0-0부터 4-4까지)하고, 두 Node가 연결되어 있는 경우 인접 행렬의 칸을 채웠습니다. 아래의 세 표현 방식은 모두 동일한 이미지를 표현한 방식입니다.\n\n\n\n\n\n\nText as graphs\n텍스트 데이터에서는 각각의 단어, 문자, 토큰3을 Node 삼아 연결해서 그래프화할 수 있습니다. 각각의 문자가 Node가 되고 Edge를 통해 그다음 Node로 연결되는 아주 간단한 방향성 그래프를 만들 수 있죠.\n\n참고로 이렇게 문자 토큰의 시퀀스로 표현하는 방법은 RNN에서 텍스트를 포현하는 방법입니다. 트랜스포머와 같은 다른 모델에서는 텍스트를 완전히 연결된 그래프로 보고 토큰간의 관계를 학습합니다.\n물론 위에서 이야기한 방식이 실제로 텍스트와 이미지가 인코딩 되는 방식은 아닙니다. 모든 이미지와 텍스트 데이터들은 매우 규칙적인 구조를 갖기 때문에 위와 같은 그래프 표현은 불필요할 수 있습니다. 이를테면 이미지는 모든 픽셀들이 서로 이웃해 연결되어 있기 때문에 인접 행렬로 표현하면 띠 모양의 구조를 갖게 됩니다. 텍스트 데이터는 일방향성이기 때문에 인접 행렬로 표현하면 대각선으로만 나오죠.\n\n\n\nGraph-valued data in the wild\n그래프는 익숙한 데이터를 설명하는 데 참으로 유용한 도구입니다. 지금부터는 조금 더 이질적인 구조를 가진 데이터로 넘어가 보겠습니다. 이제부터 나올 데이터들은 이미지와 텍스트처럼 이웃의 개수가 고정되어있지 않고 각 Node별로 이웃 수가 가변적입니다. 이런 데이터들은 그래프 말고 다른 방식으로 표현하기가 어렵습니다.\n\n\n그래프로 보는 분자\n\n\n\n\n분자는 원자와 전자로 이루어져 있는 물질의 구성 요소입니다. 모든 입자는 상호작용하지만 한 쌍의 원자가 서로 안정된 거리에 붙어 있으면 우리는 공유 결합을 형성하고 있다고 말합니다. 공유결합은 두 원자 사이에 공유하는 전자 쌍의 개수에 따라 서로 다른 거리를 갖습니다. 이를테면 단일결합은 한 쌍, 이중결합은 두 쌍, 삼중결합은 세 쌍의 전자를 공유하죠. 결합의 수가 늘어날수록 결합 사이의 거리는 짧아지고 그 세기는 증가합니다. 3D로 표현된 분자 개체를 그래프로 설명하는 건 매우 편리합니다. 분자 그래프에서 Node는 원자이고 Edge는 결합을 나타냅니다. 위에는 매우 일반적인 분자4를 가지고 그래프로 표현한 자료가 있습니다.\n\n\n그래프로 보는 소셜 네트워크\n\n\n\n\n소셜 네트워크는 사람과 기관, 그리고 조직의 집단행동 패턴을 연구하는 도구입니다. 개인을 Node로, 관계를 Edge로 모델링하면 사람들의 그룹을 나타내는 그래프를 만들 수 있습니다. 위의 이미지는 연극 오델로의 캐릭터 간 상호작용을 인접 행렬과 그래프로 표현한 겁니다.\n\n\n그래프로 보는 인용 네트워크\n\n과학자들은 논문을 발표할 때 다른 과학자의 연구를 일상적으로 인용합니다. 이러한 인용 네트워크 역시 그래프로 시각화할 수 있습니다. 각각의 논문은 Node로 표현하고, Node와 Node를 연결하는 Edge는 한 논문과 다른 논문 사이의 인용을 나타낼 수 있죠. 또한 각 Node에 초록의 단어를 임베딩하는 등 각 논문에 대한 정보를 추가할 수도 있습니다.\n\n\n그 외\n\n컴퓨터 비전(CV, Computer Vision)에서는 시각적 장면에 포함된 객체에 태그를 지정하고 싶을 때가 있습니다. 이런 경우에는 객체를 Node로, 객체 간의 관계를 Edge로 처리해서 그래프를 만들 수 있습니다. 머신러닝 모델, 프로그래밍 코드, 수식 역시 그래프로 표현 가능합니다. 이 경우엔 변수를 Node로 연산을 Edge로 보면 되죠. Tensorflow 등에서 등장하는 Dataflow graph(데이터 흐름도)가 바로 그 예시입니다.\n현실 세계에 존재하는 그래프들의 구조는 데이터 유형에 따라 크게 달라질 수 있을 겁니다. 어떤 그래프에선 Node가 많지만 서로 연결이 적을 수도 있고, 또 어떤 그래프에선 Node는 적지만 연결이 엄청나게 많을 수도 있죠. 그래서 그래프 데이터셋은 Node, Edge, Node의 연결성 등의 측면을 고려했을 때 매우 다양한 형태를 가질 수 있습니다."
  },
  {
    "objectID": "posts/230317_GNN_intro_2/index.html",
    "href": "posts/230317_GNN_intro_2/index.html",
    "title": "그래프 데이터로 풀 수 있는 문제",
    "section": "",
    "text": "What types of problems have graph structured data?\n앞에서 Part 1에서는 그래프의 몇몇 사례를 설명했습니다. 이런 데이터를 활용해서 어떤 작업을 수행할 수 있을까요? 그래프에 대한 예측 작업을 크게 3가지 레벨로 나눌 수 있습니다. 그래프 수준, Node 수준, Edge 수준 이렇게 말이죠.\n그래프 수준에서는 전체 그래프에 대해서 단일 속성을 예측합니다. Node 수준에서는 각 Node가 가지고 있는 일부 속성을 예측합니다. Edge 수준에서는 그래프에서 Edge 속성은 어떠한지, 또는 Edge가 존재하는지 여부를 예측합니다. 이 세 가지 수준의 예측 문제는 단일 모델 클래스인 GNN으로 다 해결할 수 있습니다. 먼저 세 가지 수준 별로 구체적인 예시를 통해 조금 더 자세히 살펴보도록 하겠습니다.\n\n\nGraph-level task\n그래프 수준에서의 목표는 전체 그래프의 속성을 예측하는 것입니다. 예를 들면 분자식을 그래프로 표현한 경우에, 분자가 어떤 냄새를 풍기는지 혹은 질병과 관련된 수용체에 결합할지를 예측할 수 있죠.\n\n\n\n이러한 접근방식은 라벨을 이미지에 연결하는 MNIST, CIFAR의 이미지 분류 문제와 비슷합니다. 텍스트 데이터로 보자면, 전체 문장의 분위기나 감정을 파악하는 이른바 감정 분석이 비슷한 접근이라고 할 수 있을 겁니다.\n\n\n\nNode-level task\nNode 수준의 예측 작업은 하나의 그래프 안에서 각 Node의 특성이나 역할을 예측하는 게 주목적입니다.\nNode 수준 예측 문제의 대표적인 예는 ’재커리 가라테 클럽 데이터’입니다. 제커리 가라테 클럽 데이터는 클럽 내 정치적 불화로 클럽이 둘로 갈라지면서, 한 곳에만 충성을 맹세한 사람들로 구성된 소셜 네트워크 그래프입니다. 조금 더 스토리를 설명하자면 가라테 강사 Mr. Hi와 관리자 John A 사이에 불화가 생겨 가라테 클럽이 분열됩니다. 회원의 절반 가량이 Mr. Hi를 중심으로 새로운 가라테 클럽을 결성하게 되죠.\n여튼 그래프에서 Node는 개별 가라테 수련생을 나타내고, Edge는 가라테 클럽 밖에서의 회원들 간의 상호 작용을 나타냅니다. 여기서 예측문제는 불화 이후 특정 회원이 Mr. Hi와 John A 중 어느 쪽에 충성하게 될지 분류하는 거죠. 이 경우 특정 Node와 Mr. Hi와의 거리, 혹은 John A와의 거리는 충성도와 높은 상관관계가 있습니다.\n\n\n\n이미지 분석에 비유를 해보자면, Node 수준의 예측 문제는 이미지 안에서 각 픽셀의 역할에 레이블을 지정하는 이미지 분할(image segmentation)과 유사한 접근입니다. 텍스트 분석에서는 문장 안에서 각 단어의 품사를 예측하는 것과 비슷하죠.\n\n\n\nEdge-level task\n마지막으로 남은 예측 문제는 Edge 예측입니다.\nEdge 수준의 예측의 한 가지 예는 이미지 장면 이해(Image scene understanding)입니다. 딥러닝 모델은 이미지에서 객체를 식별하는 것 외에도 객체 간의 관계를 예측하는 데 사용할 수 있습니다. 이를 Edge 수준 분류라고 표현할 수 있죠. 이미지의 객체(Node)들이 주어지면 Node 가운데 어떤 Node가 Edge를 서로 공유하는지, 혹은 그 Edge의 값이 무엇인지 예측합니다. 각 개체 간의 연결을 발견하기 위해선 그래프를 완전 그래프(Complete graph, 모든 Node간에 Edge가 존재하는 그래프)로 설정한 뒤 예측된 값에 따라 Edge를 잘라내면서 희소 그래프(Sparse graph, Node 개수보다 Edge 개수가 적은 그래프)에 도달할 수 있습니다.\n\n\n\n원본 이미지에서 각 선수, 심판, 관중, 매트 등 5개의 엔티티(Entities)로 세분화해 그들 사이의 관계를 표현해봅니다\n\n\n\n\n\n왼쪽에는 엔티티 구분 전에 구축된 초기 그래프가 있습니다. 오른쪽은 Edge 라벨링된 결과 그래프입니다.\n\n\n\n\n\n\nThe challenges of using graphs in machine learning\n그렇다면 신경망을 통해 위에서 살펴본 다양한 그래프 작업을 해결하려면 어떻게 해야 할까요? 가장 먼저 해야 할 건 신경망과 호환되도록 그래프를 어떻게 표현할지 생각하는 겁니다.\n머신러닝 모델은 일반적으로 직사각형이나 격자모양의 배열을 input 값으로 받습니다. 따라서 이를 딥러닝과 호환되는 형식으로 표현하는 방법은 직관적이지 않을 수 있습니다. 그래프에는 Node, Edge, 글로벌 컨텍스트, 연결성 등 예측에 잠재적으로 사용할 수 있는 4개의 정보가 있습니다. 앞의 3개는 비교적 간단합니다. 예를 들어서 Node의 경우 각각의 Node에 인덱스 \\(i\\)를 할당하고 \\(node_i\\)의 특징을 Node 특징 행렬(Node feature matrix) \\(N\\)에 넣을 수 있을 겁니다. 이러한 행렬에는 다양한 예가 있지만 특별한 기술이 들어갈 필요 없이 처리할 수 있습니다.\n하지만 그래프의 연결성을 표현하는 건 복잡합니다. 아마도 가장 확실한 방법은 쉽게 텐서화(Tensorisable)할 수 있는 인접 행렬을 사용하는 것일 겁니다. 하지만 이 방법은 몇 가지 단점이 있습니다. 어떤 그래프의 Node 수는 수백만 개에 달할 수 있습니다. 그리고 Node별 Edge 수는 매우 가변적이죠. 이로 인해 인접 행렬은 희소 행렬(Sparse matrix)이 될 가능성이 높아 공간이 비효율적인 경우가 많습니다.\n또 다른 문제는 동일한 연결성을 인코딩할 수 있는 인접 행렬이 많다는 겁니다. 동일한 연결성을 나타내지만 다른 모양의 인접 행렬이 심층 신경망에서 동일한 결과를 생성한다는 보장이 없죠. 즉 다시 말해 순열 불변(Permutation invariance, 입력 벡터 요소의 순서와 상관없이 같은 출력을 생성하는 특성)이 아니라는 겁니다. 예를 들어서 앞서 설명한 오셀로 그래프는 아래 두 인접 행렬로 표현할 수 있습니다.\n\n\n아래 예는 4개의 Node로 구성된 작은 그래프를 표현할 수 있는 모든 인접 행렬을 나타낸 겁니다. 인접행렬의 개수는 \\(4! = 24\\)개로, 상당한 수가 나옵니다. 오셀로 그래프와 같이 더 큰 데이터에서는 인접 행렬의 수는 엄청나게 늘어날 겁니다.\n\n\n\n메모리 효율을 고려한다면 인접성 목록으로 희소 행렬(sparse matrices)을 표현할 수도 있습니다. 인접성 목록의 k번째 항목에는 Node \\(n_i\\)와 Node \\(n_j\\) 사이의 Edge \\(e_k\\)의 연결성을 나타냅니다. 희소 행렬이니만큼 Edge 수가 행렬의 항목 수 \\(n^2_{nodes}\\)) 보다 훨씬 적을 테고, 그만큼 그래프에서 연결되어 있지 않는 부분에 대한 계산과 저장을 피할 수 있습니다. 예시에서 본 그림에서는 Node, Edge, Global에 스칼라 값을 사용했지만, 대부분의 실제 텐서 표현에서는 그래프의 각 속성당 벡터를 사용합니다."
  },
  {
    "objectID": "posts/test/index.html",
    "href": "posts/test/index.html",
    "title": "test",
    "section": "",
    "text": "import torch\nprint(\"PyTorch has verson {}\".format(torch.__version__))\n\nPyTorch has verson 2.0.0\n\n\n\nimport torch\nfrom torch_geometric.data import Data\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype = torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype = torch.float)\n\ndata = Data(x = x, edge_index = edge_index)\n\nData(edge_index = [2, 4], x = [3, 1])\n\nData(x=[2], edge_index=[2])"
  },
  {
    "objectID": "posts/230401_GNN_intro_3/index.html",
    "href": "posts/230401_GNN_intro_3/index.html",
    "title": "그래프 신경망",
    "section": "",
    "text": "GNN(Graph Neural Networks)\n이제부터는 그래프가 순열 불변(Permutation invariant)의 행렬 형식이 되어 있다고 하고, 그래프 예측 작업을 해결하기 위해 GNN을 사용하는 방법을 살펴보겠습니다. GNN은 그래프의 모든 속성(노드, 엣지, 전역)에 대해 그래프 대칭성(순열 불변성)을 유지하는 최적화된 변환 과정입니다. 이번 글에선 Graph Nets architecture schematics를 활용한 “메시지 전달 신경망(Message Passing Neural Network)” 프레임워크를 이용해서 GNN을 구축해보겠습니다. GNN은 “그래프-인, 그래프-아웃” 아키텍처를 채택합니다. 이 아키텍쳐는 GNN 모델이 노드, 엣지 및 전역에 정보가 담겨있는 그래프를 입력값으로 받아들이고 입력된 그래프의 연결성을 변화시키지 않으면서 임베딩을 점진적으로 변환합니다.\n\n\nThe Simplest GNN\n우선 그래프의 연결성을 사용하지 않는 가장 간단한 GNN 아키텍처부터 시작하겠습니다. 이전 다이어그램에서는 단순하게 표현하기 위해 스칼라를 사용해서 그래프 속성을 표현했지만 실제로는 피쳐 벡터를 사용합니다.\n이 GNN은 그래프의 각 구성요소에 대해 별도의 다층 퍼셉트론(MLP)을 사용합니다. 우리는 이걸 GNN 레이어라고 부릅니다. 각 노드 벡터에 대해 MLP를 적용하고 학습된 노드 벡터를 다시 가져옵니다. 각 에지에 대해서도 동일한 작업을 수행해서 엣지별 임베딩을 학습합니다. 또 전체 그래프에 대해서도 단일 임베딩을 학습하는 전역 컨텍스트 벡터에 대해서도 동일한 작업을 수행합니다.\n\n\n\n\n\n간단한 GNN의 단일 레이어 이미지입니다. 그래프가 입력값이고 각 구성요소(V, E, U)는 MLP에 의해 업데이트되어 새로운 그래프를 생성합니다.\nGNN은 입력된 그래프의 연결성을 업데이트하지 않기 때문에 입력 그래프와 동일한 인접성 목록(adjacency list)과 동일한 수의 피쳐 벡터로 GNN 출력 그래프를 설명합니다. 하지만 출력 그래프에는 노드, 엣지 및 전역 컨텍스트가 업데이트되므로 임베딩이 업데이트 되죠. 정리해보면 GNN은 입력한 그래프의 연결성을 변경하지 않고 임베딩을 점진적으로 변환합니다.\n\n\n\nGNN Predictions by Pooling Information\n자, 이제 간단한 GNN을 구축했습니다. 그렇다면 위에서 설명한 작업에서 어떻게 예측을 할 수 있는 걸까요?\n여기서는 이진 분류의 경우를 설명하겠지만, 이 프레임워크는 쉽게 다중 클래스나 회귀로 확장할 수 있습니다. 그래프에 이미 노드 정보가 포함되어 있다면, 노드에 대한 이진 예측을 위해 각 노드 임베딩에 선형 분류기(linear classifier)를 적용하면 될 겁니다.\n하지만 물론 항상 간단한 일만 있는 건 아니겠죠. 예를 들어 그래프 엣지에는 정보가 있지만 노드에는 정보가 없는 경우라면 어떨까요? 노드 예측을 위해선 엣지에서 정보를 수집해서 노드에 해당 정보를 제공할 수 있는 방법이 필요합니다. 그 방법은 바로 풀링(Pooling)입니다. 풀링은 2단계로 구성됩니다.\n\n1.풀링할 각 항목에 대해 각 임베딩을 수집해 행렬로 연결\n2.수집된 임베딩은 합계 연산을 통해 집계\n\n풀링 연산은 \\(\\rho\\)로 표현하고, 엣지에서 노드로 정보를 수집하는 것을 \\(P_{E_{n} \\rightarrow V_{n}}\\)으로 나타냅니다.\n엣지 수준의 정보만 있다면 풀링을 이용해서 정보를 필요한 곳으로 라우팅 하세요. 모델은 아래와 같습니다.\n\n\n\n만약 노드 수준의 정보만 있고, 이진 엣지 수준 정보를 예측하는 경우에도 아래 모델을 이용하면 됩니다.\n\n\n\n노드 수준의 정보만 있고, 이진 글로벌 속성을 예측해야 하는 경우에는 어떨까요? 이 경우엔 사용 가능한 모든 노드 정보를 한데 모아 집계합니다. 이러한 접근은 CNN의 Global Average Pooling 레이어와 유사합니다. 엣지 정보만 있을 때도 마찬가지고요.\n\n\n\n보통 분자 속성을 예측할 때가 이런 경우입니다. 예를 들어 원자 정보와 연결성이 있는 경우에 분자의 독성 여부와 특정한 향기(장미) 여부를 확인한다면 위 모델을 사용하면 됩니다. 예제에서 등장하는 분류 모델 \\(c\\)는 다른 Differentiable Model로도 대체할 수 있고, 혹은 선형 모델을 이용해 다중 클래스 분류에도 적용할 수 있습니다.\n\n\n\n지금까지 간단한 GNN 모델을 구축하고, 그래프의 서로 다른 부분 간의 정보를 라우팅하면서 이진 예측을 하는 구조를 살펴봤습니다. 이 풀링 기법은 보다 정교한 GNN 모델을 구축하기 위한 빌딩 블록 역할을 할 겁니다. 만약 새로운 그래프 속성이 있다면, 한 속성에서 다른 속성으로 정보를 전달하는 방법을 정의하기만 하면 됩니다.\n지금까지 살펴본 GNN 공식에서는 GNN 레이어 내부에서 그래프의 연결성을 전혀 사용하지 않다는 다는 점 유의하시길 바랍니다. 각 노드는 독립적으로 처리됩니다. 엣지도 마찬가지고, 전역 컨텍스트도 마찬가지 입니다. 예측을 위해 정보를 풀링할 때만 그래프의 연결성을 사용합니다.\n\n\n\nPassing messages between parts of the graph\n지금부터는 GNN 레이어 내부에서 그래프의 연결성을 사용하는 방법을 살펴보겠습니다. 학습된 임베딩이 그래프 연결성을 인식하도록 하기 위해선 GNN 레이어 내에서 풀링을 사용하면 됩니다. 이렇게 하면 더 정교한 예측을 할 수 있죠. 이웃한 노드나 엣지가 서로 정보를 교환해서 해당 노드의 상태를 업데이트하는 이른바 Message Passing을 이용하면 이런 정교한 예측을 수행할 수 있습니다.\nMessage Passing은 3단계로 진행됩니다.\n\n\n그래프의 각 노드에 대해 인접한 모든 노드 임베딩을 수집\n합계 합수를 통해 모든 임베딩(메시지)을 집계합\n풀링된 모든 메시지는 학습된 신경망(업데이트 함수)을 통해 전달\n\n\n풀링이 노드나 엣지에 적용되는 것처럼, Message Passing도 마찬가지 입니다. 여튼 이 단계는 그래프의 연결성을 괄요하기 위한 핵심 과정입니다. 이제부터는 GNN 레이어에서 Message Passing를 더욱 정교하게 변형하여 표현력과 성능이 향상된 GNN 모델을 표현해보겠습니다.\n\n\n\n이렇게 일련의 연산을 적용하면 가장 간단한 유형의 MP GNN 계층이 됩니다.\n이러한 접근 방식은 합성곱(standard convolution)을 연상시킵니다. MP와 합성곱은 본질적으로 요소의 값을 업데이트하기 위해 요소의 이웃 정보를 집계하고 처리하는 연산입니다. 그래프에서 요소는 노드이고 이미지에선 픽셀이죠. 차이점이라면 이미지에선 각 픽셀마다 정해진 수의 인접요소가 있지만 그래프에선 인접 노드의 수가 가변적이라는 거겠죠.\nMP GNN 레이어를 쌓아올리면 결국 전체 그래프의 정보를 통합할 수도 있습니다. 그리고 세 레이어를 지나면 노드 하나는 자신으로부터 세 단계 떨어진 노드에 대한 정보를 갖게 될 겁니다. 새로운 정보 소스를 포함하도록 아키텍처 다이어그램을 업데이트 해보겠습니다.\n\n\n위 다이어그램은 1도 거리의 인접 노드를 풀링해서 그래프의 노드 표현을 업데이트하는 GCN(Graph Convolutional Network) 아키텍처의 모식도입니다.\n\n\n\nLearning edge representations\n우리가 사용할 데이터셋이 항상 노드, 엣지, 전역 컨텍스트에 모든 유형의 정보를 포함하는 건 아닐겁니다. 노드에 대한 예측을 하고 싶지만 데이터셋에 엣지 정보만 있는 경우에는 풀링을 사용해서 엣지에서 노드로 정보를 라우팅하는 방법을 소개해드렸습니다. 하지만 이 방법은 모델의 최종 예측 단계에서만 가능합니다. 그럴 땐 MP를 사용하여 GNN 레이어 안에서 노드와 엣지간의 정보를 공유할 수 있을겁니다.\n앞서 이웃 노드에서 정보를 수집해 사용했던 것처럼 엣지에도 적용할 수 있습니다. 이웃 엣지의 정보를 풀링하고 업데이트 함수로 변환한 뒤 저장하는 식으로 이웃 엣지의 정보를 통합할 수 있습니다.\n하지만 그래프에 저장된 노드와 엣지 정보는 크기나 모양이 반드시 같은 건 아니기에 이를 결합하는 방식이 명확하지는 않습니다. 이럴 때 쓸 수 있는 방법은 엣지 공간에서 노드 공간으로, 혹은 노드 공간에서 엣지 공간으로 선형 매핑을 학습하는 겁니다. 혹은 업데이트 함수 전에 이들을 서로 연결할 수도 있습니다.\n\n\n\n어떤 그래프 속성을 먼저 업데이트할지는 GNN을 구성할 때 결정해야할 사항 중 하나입니다. 노드 임베딩을 엣지 임베딩보다 먼저 업데이트할지, 아니면 그 반대로 할지 선택하면 됩니다. 혹은 ‘직조’ 방식(노드-노드(선형), 엣지-엣지(선형), 노드-엣지(엣지 레이어), 엣지-노드(노드 레이어)의 4가지 방식을 결합해서 업데이트 하는 방식)으로 업데이트 할 수도 있습니다.\n\n\n\n\n\nAdding global representations\n지금까지 설명한 네트워크는 한 가지 결합이 있습니다. 바로, 그래프에서 서로 멀리 떨어져 있는 노드끼리는 메시지 전달을 여러 번 적용하더라도 효율적으로 전달하지 못할 수 있다는 겁니다. 한 노드의 레이어가 k개일 경우, 정보는 최대 k단계까지만 전파됩니다. 서로 멀리 있는 노드나 노드 그룹에 의존해서 예측 작업을 해야할 경우 문제가 될 수 있죠. 해결책은 모든 노드가 서로에게 정보를 전달할 수 있게 하는 겁니다. 하지만 이 경우에도 그래프의 사이즈가 큰 경우 계산 비용이 빠르게 증가한다는 문제가 있습니다. 물론 분자 같은 작은 그래프를 가지고 할 경우에는 이 접근 방식(Virtual Edges, 가상 엣지)을 사용해서 문제를 풀 수 있습니다.\n또 하나의 해결책은 그래프의 전역 표현, 이른바 마스터 노드(혹은 Context Vector)를 사용하는 겁니다. 글로벌 컨텍스트 벡터는 네트워크의 다른 모든 노드와 엣지에 연결되어 있어 정보를 전달하는 다리 역할을 합니다. 이를 통해 그래프 전체에 대한 표현을 구축할 수 있죠. 이런 마스터 노드를 이용하면 다른 방법으로 학습할 수 있었던 것보다 훨씬 더 풍부하고 복잡한 그래프 표현을 만들 수 있습니다.\n\n\n\n이 방식에서는 모든 그래프의 속성들이 학습된 표현을 갖고 있기 때문에 풀링 과정 중에서 우리가 관심있는 속성의 정보를 나머지 속성 정보에 대해 conditioning하여 활용할 수 있습니다. 예를 들어보겠습니다. 하나의 노드에 대해서 우리는 인접 노드, 연결된 엣지 정보, 전역 정보를 고려할 수 있을겁니다. 모든 가능한 정보 소스에 대해 새로운 노드 임베딩을 conditioning하려면 그냥 간단히 연결만 하면 됩니다. 추가로 선형 맵을 통해 동일한 공간에 맵핑을 해서 추가하거나 feature-wise modulation layer(featurize-wise attention 메커니즘의 일종)를 적용할 수도 있습니다."
  },
  {
    "objectID": "posts/230403_spinner-package/index.html",
    "href": "posts/230403_spinner-package/index.html",
    "title": "r에서 Spinner로 만드는 Graph Net",
    "section": "",
    "text": "오늘 소개할 R package는 Spinner package입니다. 로고에도 그려진 것처럼 Spinner는 실을 만드는 방적기, 방적공을 의미합니다. Spinner package는 토치(Torch)를 기반으로 Graph Net을 구현해주는 패키지입니다. 자세한 내용은 Spinner package를 만든 Giancarlo Vercellino의 Rpub을 참조하세요.\n\n\n\nGraph Net은 그래프(혹은 구조화된 데이터)를 처리하기 위해 설계된 신경망 아키텍처입니다. Distill의 &lt;A Gentle Introduction to Graph Neural Networks&gt; 논문을 정리해보면서 이미 Graph Net을 살펴본 바 있습니다. 이웃한 노드나 엣지가 서로 정보를 교환해서 각각의 노드의 상태를 업데이트하는 Massage Passing을 이용한 Layer를 다루었죠. 그 중에서 노드에서 노드로, 엣지에서 엣지로, 노드에서 엣지로, 엣지에서 노드로, 혹은 이 4가지 방법을 모두 결합해서 마치 천을 직조하듯 구성한 Weave Layer도 살펴봤습니다.\n기본적인 Graph Net의 연산과 마찬가지로 Spinner package는 그래프의 노드와 엣지 간에 정보를 전파하는 메시지 전달 연산(Message-Passing Operations), 그리고 수신된 메시지를 기반으로 새로운 노드, 엣지의 Feature를 계산하는 업데이트 함수로 구성됩니다.\n\n\n\n\n\nSpinner package는 그래프 샘플링(Graph Sampling)과 특징 추출(Feature Extraction)이라는 두 가지 작업에서부터 시작됩니다. 거대한 그래프의 경우에는 샘플링 값을 설정하고 Graph Density Threshold를 조정해서 하위 그래프를 샘플링할 수 있습니다. 그런 다음 Spinner package는 특징(Feature)을 추출합니다. 그래프에 Feature 값이 없는 경우에는 알고리즘은 Null value, 인접 임베딩 또는 라플라시안 임베딩을 이용해서 New Feature를 계산합니다. Null value는 관련 정보가 없다는 의미이고, 인접 임베딩은 그래프의 인접 행렬을 통해 노드 간의 관계를 포착합니다. 라플라시안 임베딩은 라플라시안 행렬을 분해하여 로컬 및 글로벌 속성을 포착합니다. 결측값이 있는 특징의 경우 empirical distribution을 사용하여 무작위 대입을 수행합니다.\n\n\n\n\nSpinner가 생성한 레이어는 Message Passing과 graph-independent forward network로 구성됩니다. Message Passing에서 그래프의 각 노드는 인접 노드로부터 메시지를 받고, 받은 메시지는 노드의 Feature 표현을 업데이트하는 데 사용됩니다. update_order 조건을 사용하면 다양한 옵션을 사용할 수 있죠. 업데이트의 조합은 선형 변환을 기반으로 합니다. graph-independent forward network는 업데이트된 Feature 표현을 가져와 DNN 변환을 적용합니다. 이 과정은 선택한 수의 레이어에 대해 반복되므로 알고리즘이 기능을 세분화하고 그래프의 더 복잡한 표현을 구축할 수 있습니다.\n\n\n\n\nGraph Net Layers가 완료되면 optional skip shortcut을 적용할 수 있습니다. skip shortcut을 사용하면 알고리즘이 특정 레이어를 건너뛰고 입력을 출력 레이어에 직접 연결하여 알고리즘의 효율성을 개선할 수 있죠. 출력 단계에선 Regression Tasks에 대한 선형 변환(Continuous range에 매핑하는 선형 변환 / Label Feature의 경우엔 확률 분포에 매핑하는 softmax/sigmoid activation)이 이뤄집니다. 마지막 단계에선 주어진 그래프 특징에 대한 예측 값 또는 확률을 나타내는 그래프 넷 알고리즘의 최종 출력을 생성합니다.\n\n\n\n\n\n이제부터 본격적으로 그래프를 가지고 진행해보겠습니다. r에서 그래프를 그리기 위해 igraph package와 ggplot2 환경에서 그래프를 그리게 해주는 ggnetwork package를 이용하겠습니다. 우선 100개의 노드를 가지고 있는 작은 더미 그래프를 만들어보죠. 그래프에는 노드와 엣지에 각각 2개의 Feature를 넣어두겠습니다. 먼저 하나는 정규화된 연결 중심성(Degree Centrality, 한 노드에 연결된 엣지의 개수)이고, 또 하나는 cut of betweenness statstics입니다. 컨텍스트/글로벌 그래프에 대한 특징 값은 따로 없습니다.\n\nlibrary(igraph)\nlibrary(ggplot2)\nlibrary(ggnetwork)\n\nset.seed(1004)\ndummy_graph &lt;- random.graph.game(100, 0.05) # 100개의 노드, 노드간 엣지 연결 확률 0.05인 그래프 생성\n\n# Feature 넣어주기\nV(dummy_graph)$node_feat1 &lt;- degree(dummy_graph, normalized = T) + runif(50)\nV(dummy_graph)$node_feat2 &lt;- as.character(cut(betweenness(dummy_graph, normalized = T), 3))\n\nE(dummy_graph)$edge_feat1 &lt;- degree(line.graph(dummy_graph), normalized = T) + runif(ecount(dummy_graph))\nE(dummy_graph)$edge_feat2 &lt;- as.character(cut(betweenness(line.graph(dummy_graph), normalized = T), 2))\n\nggplot(ggnetwork(dummy_graph), aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_edges(aes(color = edge_feat2)) + \n  geom_nodes(aes(size = node_feat1, color = node_feat2)) + \n  theme_void() + \n  guides(size = 'none', color = 'none') + \n  scale_color_manual(values = viridis::viridis(15, direction = -1, option = \"B\")[c(3, 6, 9, 12, 15)])\n\n\n\n\n\n\n\n\n\nspinner 함수에 필요한 최소한의 파라미터는 그래프, 예측 대상(노드나 엣지), 노드, 에지 및 컨텍스트 Feature에 대한 레이블입니다. (위에서도 이야기 했지만 Feature가 없는 경우엔 임베딩 방법을 사용하여 새로운 특징을 계산합니다. Feature가 없는 경우 기본 임베딩 크기는 5이고 relative arguments를 사용하여 노드, 엣지 및 컨텍스트에 대해 수정할 수 있습니다) 이번 연습에서는 모든 노드와 엣지의 Feature를 사용하고(기본 옵션으로 컨텍스트를 5개의 0 벡터로 초기화) 엣지에 예측 타깃을 설정하여 2-folds, 3-repetitions의 cross-validation을 해보겠습니다.\n\nlibrary(spinner)\n\nexample1 &lt;- spinner(dummy_graph, target = \"edge\", \n                    node_labels = c(\"node_feat1\", \"node_feat2\"), \n                    edge_labels = c(\"edge_feat1\", \"edge_feat2\"), \n                    holdout = 0.6, \n                    reps = 3, \n                    folds = 2, \n                    n_layers = 1)\n\nepoch:  10    Train loss:  0.6820657    Val loss:  0.6711463 \nepoch:  20    Train loss:  0.6089707    Val loss:  0.6455721 \nepoch:  30    Train loss:  0.6605015    Val loss:  0.6717189 \nepoch:  40    Train loss:  0.5759389    Val loss:  0.6358511 \nearly stop at epoch:  41    Train loss:  0.6066641    Val loss:  0.6683025 \nepoch:  10    Train loss:  0.7671983    Val loss:  0.661452 \nepoch:  20    Train loss:  0.7404004    Val loss:  0.6647233 \nepoch:  30    Train loss:  0.7611908    Val loss:  0.7213398 \nearly stop at epoch:  39    Train loss:  0.7686964    Val loss:  0.6944773 \nepoch:  10    Train loss:  0.6721007    Val loss:  0.6914219 \nepoch:  20    Train loss:  0.7303004    Val loss:  0.7528074 \nepoch:  30    Train loss:  0.6592697    Val loss:  0.7057204 \nepoch:  40    Train loss:  0.698299    Val loss:  0.6622039 \nearly stop at epoch:  44    Train loss:  0.6732623    Val loss:  0.7268654 \nepoch:  10    Train loss:  0.6426511    Val loss:  0.7335425 \nepoch:  20    Train loss:  0.7605699    Val loss:  0.7579686 \nepoch:  30    Train loss:  0.7845948    Val loss:  0.7324713 \nepoch:  40    Train loss:  0.7046131    Val loss:  0.7116204 \nearly stop at epoch:  48    Train loss:  0.5067006    Val loss:  0.7423382 \nepoch:  10    Train loss:  0.5613942    Val loss:  0.6729948 \nepoch:  20    Train loss:  0.6164793    Val loss:  0.6531799 \nepoch:  30    Train loss:  0.6119072    Val loss:  0.683926 \nearly stop at epoch:  32    Train loss:  0.6206366    Val loss:  0.6946394 \nepoch:  10    Train loss:  0.896782    Val loss:  0.7952279 \nepoch:  20    Train loss:  0.9012119    Val loss:  0.7725604 \nepoch:  30    Train loss:  0.493989    Val loss:  0.7581556 \nepoch:  40    Train loss:  0.63601    Val loss:  0.7295729 \nepoch:  50    Train loss:  0.9077    Val loss:  0.7525882 \nepoch:  60    Train loss:  0.4619842    Val loss:  0.7336836 \nepoch:  70    Train loss:  0.9050267    Val loss:  0.7550592 \nepoch:  80    Train loss:  0.8885249    Val loss:  0.7225138 \nepoch:  90    Train loss:  0.8951436    Val loss:  0.7863429 \nepoch:  100    Train loss:  0.892521    Val loss:  0.7861573 \nepoch:  10    Train loss:  0.7193506    Val loss:  0.6954241 \nepoch:  20    Train loss:  0.6814125    Val loss:  0.6942275 \nepoch:  30    Train loss:  0.6652368    Val loss:  0.7037159 \nearly stop at epoch:  34    Train loss:  0.6795753    Val loss:  0.7075669 \ntime: 14.264 sec elapsed\n\n\n\n함수를 돌리면 나오는 결과값에는 출력에는 그래프(원본 or 샘플링), 모델 설명 및 요약, 새 그래프 데이터에 대한 예측, 교차 검증 및 요약 오류, 손실 함수에 대한 플롯(최종 학습 및 테스트용) 및 시간 로그가 포함되어 있습니다.\n\nexample1$model_description\n\n[1] \"model with 1 GraphNet layers, 1 classification tasks and 1 regression tasks (1029 parameters)\"\n\nexample1$model_summary\n\n$GraphNetLayer1\nAn `nn_module` containing 1,027 parameters.\n\n── Modules ─────────────────────────────────────────────────────────────────────\n• context_to_edge: &lt;nn_pooling_from_context_to_edges_layer&gt; #18 parameters\n• context_to_node: &lt;nn_pooling_from_context_to_nodes_layer&gt; #24 parameters\n• edge_to_context: &lt;nn_pooling_from_edges_to_context_layer&gt; #20 parameters\n• edge_to_node: &lt;nn_pooling_from_edges_to_nodes_layer&gt; #16 parameters\n• node_to_context: &lt;nn_pooling_from_nodes_to_context_layer&gt; #25 parameters\n• node_to_edge: &lt;nn_pooling_from_nodes_to_edges_layer&gt; #15 parameters\n• node_fusion: &lt;nn_linear&gt; #3 parameters\n• edge_fusion: &lt;nn_linear&gt; #3 parameters\n• context_fusion: &lt;nn_linear&gt; #3 parameters\n• independent_layer: &lt;nn_graph_independent_forward_layer&gt; #900 parameters\n\n$classif1\nAn `nn_module` containing 0 parameters.\n\n$regr1\nAn `nn_module` containing 2 parameters.\n\n── Parameters ──────────────────────────────────────────────────────────────────\n• weight: Float [1:1, 1:1]\n• bias: Float [1:1]\n\nexample1$cv_errors\n\n  reps folds     train validation\n1    1     1 0.6066641  0.6683025\n2    1     2 0.7686964  0.6944773\n3    2     1 0.6732623  0.7268654\n4    2     2 0.5067006  0.7423382\n5    3     1 0.6206366  0.6946394\n6    3     2 0.8925210  0.7861573\n\nexample1$summary_errors\n\n                train validation.validation                  test \n            0.6795753             0.7187967             0.7075669 \n\nexample1$history + theme_minimal()"
  },
  {
    "objectID": "news/220827_quarto/index.html",
    "href": "news/220827_quarto/index.html",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "",
    "text": "RStudio는 자사의 2022년 컨퍼런스 rstudio::conf(2022)에서 발표한 여러 소식 가운데 가장 중요한 소식으로 이렇게 4가지를 꼽았습니다.\n\nRStudio의 이름은 Posit으로 바꾼다\n새로운 오픈소스 기반의 과학기술 출판 시스템, Quarto\nShiny 생태계의 새로운 발전\ntidymodel의 업데이트\n\n1번은 이미 이 포스트에서 다루었죠? 그 연장선이라고 볼 수 있는 Quarto가 이번 게시물의 주제입니다. Quarto는 R Markdown에 이은 RStudio의 차세대 R 출판 플랫폼입니다. 기존의 R Markdown을 이용하면 R code sript를 Word, HTML, PDF, PPT 등 다양한 문서 형식으로 만들 수 있었습니다. 웹을 통한 출판(Bookdown)까지도 가능했죠.\n\n그런데 이 R Markdwon이 어느새 10년 가까이 지났습니다. 기능의 편리함은 지적할만한 게 없었지만 R Markdown 생태계가 너무 커져버렸죠. 관련 생태계가 커졌다는 건 오히려 반길 일이지만 덕지덕지 붙어버린 서드파티 패키지들이 많아진 게 문제였습니다. 더 이상 통일된 하나의 R Markdown의 제작과 작업이 되질 못했습니다. 과학, 기술 블로그를 만들 땐 distill package를 사용하고, 웹 프레젠테이션 파일을 만들 땐 xaringan(사륜안) package를 사용하고…\n그래서 등장한 게 바로 이 Quarto입니다. R Markdown과 마찬가지로 Knitr와 Pandoc을 기반으로 하고 있고요. 궁극적으로 R Studio는 Quarto 생태계에 다른 언어를 사용하는 사람들끼리 모을 생각을 하고 있습니다. 그래서 저번 Posit 이야기의 연장선이라고 말씀을 드린 겁니다. 그 이유 때문인지 Quarto는 R의 내장 라이브러리가 아닌 독립 소프트웨어로 제작되었습니다. 새로운 시스템 Quarto 단어가 생소할 텐데, Quarto는 4절판을 의미합니다. 8페이지 분량의 텍스트를 두 번 접어서 네 장을 만드는 형식을 뜻하죠. 출판 역사에 의미가 있는 단어를 골랐다고 합니다.\n\n\n\nhttps://quarto.org/docs/get-started/\nQuarto는 위 링크에서 받을 수 있습니다. 링크를 들어가면 나오는 홈페이지에서도 확인할 수 있지만 Quarto는 R 뿐만 아니라 VS code, Jupyter에서도 활용할 수 있습니다."
  },
  {
    "objectID": "news/220827_quarto/index.html#r-markdown과-차이점",
    "href": "news/220827_quarto/index.html#r-markdown과-차이점",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "R Markdown과 차이점",
    "text": "R Markdown과 차이점\n\n\n\n\n\nQuarto의 구조를 알기 위해선 R Markdown에 대한 이해가 필요합니다. 일단 R Markdown 시스템은 위의 그림과 같습니다. Rmd(R 마크다운) 파일을 knitr package를 통해 md(마크다운) 파일로 만들고, pandoc 라이브러리를 통해 문서, PPT, 웹페이지, 책의 형태로 퍼블리싱되는 거죠. knitr은 2012년 Yihui Xie에 의해 개발된 패키지입니다. Knitr 패키지를 이용하면 동적 리포트를 생성할 수 있게 해주죠. md 파일을 다양한 형식으로 변환할 때에는 pandoc 라이브러리를 활용합니다. 정리해보면 기존 R Markdown은 Rmd 파일을 여러 가지 형태의 문서로 퍼블리싱해주는 시스템이라고 할 수 있겠네요.\n\n\n\nR & stats illustrations by @allison_horst\n\n\nQuarto도 비슷합니다. R Markdown과 마찬가지로 Knitr과 pandoc을 활용합니다. 달라진 건 적용 대상입니다. 기존 시스템에선 Rmd만 가능했다면 이제는 Python도 가능합니다. jupyter까지 활용하게 되면서 Python에서 qmd(Qarto markdown) 파일을 작성하면 jupyter를 통해 md 파일로 변환해 다양한 결과물을 만들어 낼 수 있게 된 거죠.\n\n\nQuarto vs R Markdown\n\n\n\n\n\n\n\n\n구분\nR Markdown\nQuarto\n\n\n\n\n기본 포맷\nhtml_document\npdf_document\nword_document\nhtml\npdf\nword\n\n\n비머 포맷(발표자료)\nbeamer_presentation\nbeamer\n\n\nPPT\npowerpoint_presentation\npptx\n\n\nHTML 슬라이드\nxaringan\nioslides\nrevealjs\n\n\nrevealjs\n\n\n블로그 및 웹사이트\nblogdown\ndistill\nQuarto Websites\nQuarto Blogs\n\n\n책\nbookdown\nQuarto Books\n\n\n인터랙티브\nShiny Documents\nQuarto Interactive Documents\n\n\nPaged HTML\npagedown\n2022 여름 공개 예정\n\n\nJournal Articles\nrticles\n2022 여름 공개 예정\n\n\n대시보드\nflexdashboard\n2022 가을 공개 예정\n\n\n\n다양한 포맷을 만들기 위해 여러 패키지를 사용했던 R Markdown과 달리, Quarto에서는 Quarto 시스템으로 다 들어왔습니다. 예전 R을 활용해 기술 블로그를 만들기 위해 distll package를 사용했지만, 이젠 Quarto의 Quarto Websites, Blogs를 활용하면 됩니다. 이 블로그도 Quarto Blogs를 이용해 만들었습니다. 아직 공개되지 않은 대시보드와 Journal Articles, Paged HTML도 곧 공개될 예정입니다."
  },
  {
    "objectID": "news/220827_quarto/index.html#quarto의-미래",
    "href": "news/220827_quarto/index.html#quarto의-미래",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "Quarto의 미래",
    "text": "Quarto의 미래\n\n\n\nR & stats illustrations by @allison_horst\n\n\nRStudio의 이번 Qaurto 발표는 결국 Posit과 비슷합니다. Python과 Julia 등 다른 언어들까지 포함하는 IDE인 Posit을 발표하고, 새롭게 출시한 Quarto에는 jupyter를 지원하면서 다른 언어 이용자들을 R 커뮤니티에 끌어들이겠다는 겁니다. Python 이용자들도 충분히 웹사이트와 블로그, 책을 만들 수 있다고 유혹하는 것이죠. RStudio의 CEO가 발표한 내용을 살펴보면 미래에는 마치 Google Docs에서 사람들이 자유롭게 문서를 편집하듯이 여러 언어를 사용하는 이용자들이 Quarto 문서를 통해 협업을 하길 구상하고 있더라고요. 물론 아직까지 그런 환경이 갖춰져 있는 건 아니지만, 꽤나 매력적인 미래의 모습입니다. 하루빨리 그런 환경이 오길 바라면서 이번 포스트를 마무리하겠습니다."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "NEWS 🗞",
    "section": "",
    "text": "관심있는 소식을 요약해 정리합니다.\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\n\n\n\nR Markdown의 차세대 포맷, Quarto\n\n\n\nR Markdown\n\n\nQuarto\n\n\n\nR, Python, Julia 모두 Quarto로 모여라\n\n\n\n2022/08/27\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio가 Posit으로 이름을 바꾼다\n\n\n\nR\n\n\nIDE\n\n\n\nRStudio가 갑자기 Posit으로 이름을 고치는 이유는 뭘까\n\n\n\n2022/08/21\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news/220821_Rstudio-is-becoming-Posit/index.html",
    "href": "news/220821_Rstudio-is-becoming-Posit/index.html",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "프로그래밍 언어 그 자체를 가지고 명령어를 통해 작업을 하는 건 많이 어렵습니다. 불편하기도 하고요. 그럴 때 사용하는 게 바로 IDE(통합계발환경, Intergrated Development Environment)입니다. Python을 이용할 때 사용하는 PyCharm이나 Jupyter Notebook, 혹은 MS의 텍스트 에디터 VS Code가 대표적인 IDE라고 할 수 있을겁니다.\nRStudio는 R의 가장 대표 IDE입니다. 그런데 이 RStudio가 지난 7월 말, 본인들의 이름을 바꾼다고 선언했습니다. 아마 8월 중으로 이름표를 새로 바꿀 것 같은데요, 그들이 공개한 RStudio의 새로운 이름은 Posit입니다. RStudio는 왜 갑자기 이름을 Posit으로 바꾸려는걸까요?"
  },
  {
    "objectID": "news/220821_Rstudio-is-becoming-Posit/index.html#rstudio가-이름을-바꾸는-이유는",
    "href": "news/220821_Rstudio-is-becoming-Posit/index.html#rstudio가-이름을-바꾸는-이유는",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "RStudio가 이름을 바꾸는 이유는",
    "text": "RStudio가 이름을 바꾸는 이유는\n\n1. A Broader Focus\n\n“That name has started to feel increasing constraining.”\n\n데이터 관련 분석 프로그래밍, 혹은 데이터 사이언스에서 R은 항상 Python과 비교됩니다. 데이터 관련 공부를 시작하면서 R과 Python 사이의 양자택일은 쉽지 않은 고민이죠. 전반적인 흐름은 Python에게 웃어주고 있는 모양세입니다. 여기에 Julia까지 참전하면서 R의 입지는 점점 줄어들고 있습니다. R 이름을 딱 박고 있는 RStudio 입장에서 반길일이 아니죠.\nRStudio가 여지껏 가만히 있었던 건 아닙니다. RStudio는 이미 Python을 지원하고 있습니다. R 인터페이스로 Python을 할 수 있는 reticulate 패키지도 있고요. 하지만 Python 이용자가 RStudio를 이용하는 건 쉽지 않은 선택입니다. 이미 잘 갖춰진 Python 전용 IDE를 쓰지 뭣하러 RStudio를 씁니까. 아니면 호환성 좋은 VS code를 쓰면 되죠.\nRStudio의 수석과학자 해들리 위컴은 RStudio라는 이름이 가지는 한계를 인정했습니다. 누가봐도 RStudio는 R만 개발할 수 있는 IDE로 느껴집니다. 그래서 그들은 선택을 한 겁니다. 우리 프로그램에 R 이름 뗄 테니까, Python, Julia 등 다른 언어 쓰는 사람들도 우리 개발환경으로 들어오라고요.\n\n\n\n2. A Large Community\nR community는 RStudio를 중심으로 비교적 잘 운영되고 있습니다. 하지만 위에서 언급한것처럼 규모 측면이나 확장성 측면에서 한계도 명확하죠. RStudio는 이번 Posit으로의 개편을 통해 다른 커뮤니티와의 융합을 목적으로 두고 있습니다. 그렇다고 R에서 Python으로의 전환이 이뤄지진 않을 겁니다.\n\n“I’m not going to stop writing R code. I’m not going to learn Python.”\n\n해들리 위컴이 이렇게 밝힌 이상 Python으로의 거대한 전환은 없을 것 같네요. Posit으로의 변화에 발맞춰 또 다른 변화가 있으니 바로 Quarto입니다. 차세대 Rmarkdown인 Quarto에서는 Jupyter, VS code, Observable Javascript를 기본적으로 실행할 수 있다고 합니다. Quarto에 대해서는 다음 포스트를 통해 더 깊이 이야기를 해보도록 하겠습니다. 여튼 개편될 Posit은 아마 10월 이후에나 만나볼 수 있을 것 같습니다. 홈페이지는 10월 중으로 오픈 예정이라고 합니다."
  },
  {
    "objectID": "news/220821_Rstudio-is-becoming-Posit/index.html#posit의-뜻은",
    "href": "news/220821_Rstudio-is-becoming-Posit/index.html#posit의-뜻은",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "Posit의 뜻은",
    "text": "Posit의 뜻은\nPosit을 사전에서 찾아보면 설치하다, ~을 사실로 가정하다, 아이디어 및 이론을 제시하다로 나옵니다. 토론 과정에서 아이디어를 제시하는 경우 posit이라는 단어를 쓰는 셈인거죠. RStudio(IDE 이름이 회사 이름이기도 합니다)에서는 posit이라는 단어가 데이터 분석가, 데이터 과학자들의 업무와 잘 어울린다는 판단을 했고, RStudio의 새로운 이름으로 Posit을 결정했다고 발표했습니다. 회사명도 Posit으로 바뀔 예정입니다.\n조금 더 지켜봐야겠지만 R을 공부하는 제 입장에서 이번 RStudio의 변화는 반길만한 일입니다. 여러 언어 환경에 있는 사람들을 한 IDE에 모아둘 수 있다면 협업도 더 원활하게 이뤄질테니까요. 앞으로 발표될 Posit에 대한 정보는 꾸준히 정리해보겠습니다."
  },
  {
    "objectID": "posts/230403_spinner-package/index.html#spinner-package",
    "href": "posts/230403_spinner-package/index.html#spinner-package",
    "title": "r에서 Spinner로 만드는 Graph Net",
    "section": "",
    "text": "오늘 소개할 R package는 Spinner package입니다. 로고에도 그려진 것처럼 Spinner는 실을 만드는 방적기, 방적공을 의미합니다. Spinner package는 토치(Torch)를 기반으로 Graph Net을 구현해주는 패키지입니다. 자세한 내용은 Spinner package를 만든 Giancarlo Vercellino의 Rpub을 참조하세요.\n\n\n\nGraph Net은 그래프(혹은 구조화된 데이터)를 처리하기 위해 설계된 신경망 아키텍처입니다. Distill의 &lt;A Gentle Introduction to Graph Neural Networks&gt; 논문을 정리해보면서 이미 Graph Net을 살펴본 바 있습니다. 이웃한 노드나 엣지가 서로 정보를 교환해서 각각의 노드의 상태를 업데이트하는 Massage Passing을 이용한 Layer를 다루었죠. 그 중에서 노드에서 노드로, 엣지에서 엣지로, 노드에서 엣지로, 엣지에서 노드로, 혹은 이 4가지 방법을 모두 결합해서 마치 천을 직조하듯 구성한 Weave Layer도 살펴봤습니다.\n기본적인 Graph Net의 연산과 마찬가지로 Spinner package는 그래프의 노드와 엣지 간에 정보를 전파하는 메시지 전달 연산(Message-Passing Operations), 그리고 수신된 메시지를 기반으로 새로운 노드, 엣지의 Feature를 계산하는 업데이트 함수로 구성됩니다.\n\n\n\n\n\nSpinner package는 그래프 샘플링(Graph Sampling)과 특징 추출(Feature Extraction)이라는 두 가지 작업에서부터 시작됩니다. 거대한 그래프의 경우에는 샘플링 값을 설정하고 Graph Density Threshold를 조정해서 하위 그래프를 샘플링할 수 있습니다. 그런 다음 Spinner package는 특징(Feature)을 추출합니다. 그래프에 Feature 값이 없는 경우에는 알고리즘은 Null value, 인접 임베딩 또는 라플라시안 임베딩을 이용해서 New Feature를 계산합니다. Null value는 관련 정보가 없다는 의미이고, 인접 임베딩은 그래프의 인접 행렬을 통해 노드 간의 관계를 포착합니다. 라플라시안 임베딩은 라플라시안 행렬을 분해하여 로컬 및 글로벌 속성을 포착합니다. 결측값이 있는 특징의 경우 empirical distribution을 사용하여 무작위 대입을 수행합니다.\n\n\n\n\nSpinner가 생성한 레이어는 Message Passing과 graph-independent forward network로 구성됩니다. Message Passing에서 그래프의 각 노드는 인접 노드로부터 메시지를 받고, 받은 메시지는 노드의 Feature 표현을 업데이트하는 데 사용됩니다. update_order 조건을 사용하면 다양한 옵션을 사용할 수 있죠. 업데이트의 조합은 선형 변환을 기반으로 합니다. graph-independent forward network는 업데이트된 Feature 표현을 가져와 DNN 변환을 적용합니다. 이 과정은 선택한 수의 레이어에 대해 반복되므로 알고리즘이 기능을 세분화하고 그래프의 더 복잡한 표현을 구축할 수 있습니다.\n\n\n\n\nGraph Net Layers가 완료되면 optional skip shortcut을 적용할 수 있습니다. skip shortcut을 사용하면 알고리즘이 특정 레이어를 건너뛰고 입력을 출력 레이어에 직접 연결하여 알고리즘의 효율성을 개선할 수 있죠. 출력 단계에선 Regression Tasks에 대한 선형 변환(Continuous range에 매핑하는 선형 변환 / Label Feature의 경우엔 확률 분포에 매핑하는 softmax/sigmoid activation)이 이뤄집니다. 마지막 단계에선 주어진 그래프 특징에 대한 예측 값 또는 확률을 나타내는 그래프 넷 알고리즘의 최종 출력을 생성합니다.\n\n\n\n\n\n이제부터 본격적으로 그래프를 가지고 진행해보겠습니다. r에서 그래프를 그리기 위해 igraph package와 ggplot2 환경에서 그래프를 그리게 해주는 ggnetwork package를 이용하겠습니다. 우선 100개의 노드를 가지고 있는 작은 더미 그래프를 만들어보죠. 그래프에는 노드와 엣지에 각각 2개의 Feature를 넣어두겠습니다. 먼저 하나는 정규화된 연결 중심성(Degree Centrality, 한 노드에 연결된 엣지의 개수)이고, 또 하나는 cut of betweenness statstics입니다. 컨텍스트/글로벌 그래프에 대한 특징 값은 따로 없습니다.\n\nlibrary(igraph)\nlibrary(ggplot2)\nlibrary(ggnetwork)\n\nset.seed(1004)\ndummy_graph &lt;- random.graph.game(100, 0.05) # 100개의 노드, 노드간 엣지 연결 확률 0.05인 그래프 생성\n\n# Feature 넣어주기\nV(dummy_graph)$node_feat1 &lt;- degree(dummy_graph, normalized = T) + runif(50)\nV(dummy_graph)$node_feat2 &lt;- as.character(cut(betweenness(dummy_graph, normalized = T), 3))\n\nE(dummy_graph)$edge_feat1 &lt;- degree(line.graph(dummy_graph), normalized = T) + runif(ecount(dummy_graph))\nE(dummy_graph)$edge_feat2 &lt;- as.character(cut(betweenness(line.graph(dummy_graph), normalized = T), 2))\n\nggplot(ggnetwork(dummy_graph), aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_edges(aes(color = edge_feat2)) + \n  geom_nodes(aes(size = node_feat1, color = node_feat2)) + \n  theme_void() + \n  guides(size = 'none', color = 'none') + \n  scale_color_manual(values = viridis::viridis(15, direction = -1, option = \"B\")[c(3, 6, 9, 12, 15)])\n\n\n\n\n\n\n\n\n\nspinner 함수에 필요한 최소한의 파라미터는 그래프, 예측 대상(노드나 엣지), 노드, 에지 및 컨텍스트 Feature에 대한 레이블입니다. (위에서도 이야기 했지만 Feature가 없는 경우엔 임베딩 방법을 사용하여 새로운 특징을 계산합니다. Feature가 없는 경우 기본 임베딩 크기는 5이고 relative arguments를 사용하여 노드, 엣지 및 컨텍스트에 대해 수정할 수 있습니다) 이번 연습에서는 모든 노드와 엣지의 Feature를 사용하고(기본 옵션으로 컨텍스트를 5개의 0 벡터로 초기화) 엣지에 예측 타깃을 설정하여 2-folds, 3-repetitions의 cross-validation을 해보겠습니다.\n\nlibrary(spinner)\n\nexample1 &lt;- spinner(dummy_graph, target = \"edge\", \n                    node_labels = c(\"node_feat1\", \"node_feat2\"), \n                    edge_labels = c(\"edge_feat1\", \"edge_feat2\"), \n                    holdout = 0.6, \n                    reps = 3, \n                    folds = 2, \n                    n_layers = 1)\n\nepoch:  10    Train loss:  0.6820657    Val loss:  0.6711463 \nepoch:  20    Train loss:  0.6089707    Val loss:  0.6455721 \nepoch:  30    Train loss:  0.6605015    Val loss:  0.6717189 \nepoch:  40    Train loss:  0.5759389    Val loss:  0.6358511 \nearly stop at epoch:  41    Train loss:  0.6066641    Val loss:  0.6683025 \nepoch:  10    Train loss:  0.7671983    Val loss:  0.661452 \nepoch:  20    Train loss:  0.7404004    Val loss:  0.6647233 \nepoch:  30    Train loss:  0.7611908    Val loss:  0.7213398 \nearly stop at epoch:  39    Train loss:  0.7686964    Val loss:  0.6944773 \nepoch:  10    Train loss:  0.6721007    Val loss:  0.6914219 \nepoch:  20    Train loss:  0.7303004    Val loss:  0.7528074 \nepoch:  30    Train loss:  0.6592697    Val loss:  0.7057204 \nepoch:  40    Train loss:  0.698299    Val loss:  0.6622039 \nearly stop at epoch:  44    Train loss:  0.6732623    Val loss:  0.7268654 \nepoch:  10    Train loss:  0.6426511    Val loss:  0.7335425 \nepoch:  20    Train loss:  0.7605699    Val loss:  0.7579686 \nepoch:  30    Train loss:  0.7845948    Val loss:  0.7324713 \nepoch:  40    Train loss:  0.7046131    Val loss:  0.7116204 \nearly stop at epoch:  48    Train loss:  0.5067006    Val loss:  0.7423382 \nepoch:  10    Train loss:  0.5613942    Val loss:  0.6729948 \nepoch:  20    Train loss:  0.6164793    Val loss:  0.6531799 \nepoch:  30    Train loss:  0.6119072    Val loss:  0.683926 \nearly stop at epoch:  32    Train loss:  0.6206366    Val loss:  0.6946394 \nepoch:  10    Train loss:  0.896782    Val loss:  0.7952279 \nepoch:  20    Train loss:  0.9012119    Val loss:  0.7725604 \nepoch:  30    Train loss:  0.493989    Val loss:  0.7581556 \nepoch:  40    Train loss:  0.63601    Val loss:  0.7295729 \nepoch:  50    Train loss:  0.9077    Val loss:  0.7525882 \nepoch:  60    Train loss:  0.4619842    Val loss:  0.7336836 \nepoch:  70    Train loss:  0.9050267    Val loss:  0.7550592 \nepoch:  80    Train loss:  0.8885249    Val loss:  0.7225138 \nepoch:  90    Train loss:  0.8951436    Val loss:  0.7863429 \nepoch:  100    Train loss:  0.892521    Val loss:  0.7861573 \nepoch:  10    Train loss:  0.7193506    Val loss:  0.6954241 \nepoch:  20    Train loss:  0.6814125    Val loss:  0.6942275 \nepoch:  30    Train loss:  0.6652368    Val loss:  0.7037159 \nearly stop at epoch:  34    Train loss:  0.6795753    Val loss:  0.7075669 \ntime: 14.264 sec elapsed\n\n\n\n함수를 돌리면 나오는 결과값에는 출력에는 그래프(원본 or 샘플링), 모델 설명 및 요약, 새 그래프 데이터에 대한 예측, 교차 검증 및 요약 오류, 손실 함수에 대한 플롯(최종 학습 및 테스트용) 및 시간 로그가 포함되어 있습니다.\n\nexample1$model_description\n\n[1] \"model with 1 GraphNet layers, 1 classification tasks and 1 regression tasks (1029 parameters)\"\n\nexample1$model_summary\n\n$GraphNetLayer1\nAn `nn_module` containing 1,027 parameters.\n\n── Modules ─────────────────────────────────────────────────────────────────────\n• context_to_edge: &lt;nn_pooling_from_context_to_edges_layer&gt; #18 parameters\n• context_to_node: &lt;nn_pooling_from_context_to_nodes_layer&gt; #24 parameters\n• edge_to_context: &lt;nn_pooling_from_edges_to_context_layer&gt; #20 parameters\n• edge_to_node: &lt;nn_pooling_from_edges_to_nodes_layer&gt; #16 parameters\n• node_to_context: &lt;nn_pooling_from_nodes_to_context_layer&gt; #25 parameters\n• node_to_edge: &lt;nn_pooling_from_nodes_to_edges_layer&gt; #15 parameters\n• node_fusion: &lt;nn_linear&gt; #3 parameters\n• edge_fusion: &lt;nn_linear&gt; #3 parameters\n• context_fusion: &lt;nn_linear&gt; #3 parameters\n• independent_layer: &lt;nn_graph_independent_forward_layer&gt; #900 parameters\n\n$classif1\nAn `nn_module` containing 0 parameters.\n\n$regr1\nAn `nn_module` containing 2 parameters.\n\n── Parameters ──────────────────────────────────────────────────────────────────\n• weight: Float [1:1, 1:1]\n• bias: Float [1:1]\n\nexample1$cv_errors\n\n  reps folds     train validation\n1    1     1 0.6066641  0.6683025\n2    1     2 0.7686964  0.6944773\n3    2     1 0.6732623  0.7268654\n4    2     2 0.5067006  0.7423382\n5    3     1 0.6206366  0.6946394\n6    3     2 0.8925210  0.7861573\n\nexample1$summary_errors\n\n                train validation.validation                  test \n            0.6795753             0.7187967             0.7075669 \n\nexample1$history + theme_minimal()"
  },
  {
    "objectID": "daily/211014/index.html#today-function-reduce",
    "href": "daily/211014/index.html#today-function-reduce",
    "title": "accumulate() : Accumulate intermediate results",
    "section": "",
    "text": "오늘의 함수는 purrr 패키지의 accumulate() 함수입니다. Two-Table Verbs 함수를 사용해서 3개 이상의 데이터테이블을 처리할 땐 reduce() 함수를 사용합니다. 그런데 그와 유사한 accumulate() 함수는 중간 단계를 모두 유지해줍니다.\n\n\n\n\naccumulate(.x, .f, ..., .init, .dir = c(\"forward\", \"backward\"))\n\naccumulate2(.x, .y, .f, ..., .init)\n\n\n\n\n\n.x : 리스트나 atomic vector가 들어갑니다  .f : accumulate() 함수에서는 Two-Table Verbs 함수가, accumulate2() 함수에는 그 이상의 함수를 사용할 수 있습니다.  .dir : accumulate의 방향을 정합니다.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(purrr)\n\nnumber &lt;- sample(10)\nnumber\n\n [1]  6 10  8  9  3  2  7  4  1  5\n\n# reduce 함수로 다 더하면?\nnumber |&gt; reduce(`+`)\n\n[1] 55\n\n# accumulate는 각 단계를 유지해서 누적합을 계산합니다.\nnumber |&gt; accumulate(`+`)\n\n [1]  6 16 24 33 36 38 45 49 50 55"
  },
  {
    "objectID": "daily/211013/index.html#today-function-reduce",
    "href": "daily/211013/index.html#today-function-reduce",
    "title": "reduce() : Reduce a list to a single value",
    "section": "",
    "text": "오늘의 함수는 purrr 패키지의 reduce() 함수입니다. r에서 데이터테이블을 join하거나 교집합(intersect)을 한다거나 혹은 합집합(union)을 하려면 테이블이 2개일 경우에만 가능합니다. 그래서 이런 함수들을 Two-Table Verbs라고도 하죠. 그런데 그 이상의 데이터테이블을 가지고 교집합, 합집한 등의 함수를 적용하고 싶다면 어떻게 해야할까요? 그럴 때 사용하는 함수가 바로 reduce()입니다. reduce()함수는 벡터의 요소를 하나의 값으로 결합, 반복해주는 작업을 실행합니다. 이런 식입니다. 1:3에다가 f라는 함수를 reduce()하면 f(f(1, 2), 3) 이런 식으로 적용합니다.\n\n\n\n\nreduce(.x, .f, ..., .init, .dir = c(\"forward\", \"backward\"))\n\nreduce2(.x, .y, .f, ..., .init)\n\n\n\n\n\n.x : 리스트나 atomic vector가 들어갑니다  .f : reduce() 함수에서는 Two-Table Verbs 함수가, reduce2() 함수에는 그 이상의 함수를 사용할 수 있습니다.  .dir : reduce의 방향을 정합니다.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(purrr)\n\n# +로 예를 들어봅시다 1부터 3까지 reduce 함수로 더해봅니다\n1:3 |&gt; reduce(`+`)\n\n[1] 6\n\nreduce(1:3, `+`)\n\n[1] 6\n\n# 이번엔 1부터 10까지 곱해보겠습니다\nreduce(1:10, `*`)\n\n[1] 3628800\n\n# 10!과 값이 당연히 같습니다\nfactorial(10)\n\n[1] 3628800\n\n# dplyr 패키지의 join 함수를 reduce 함수와 함께 써보겠습니다\ndfs &lt;- list(\n  age = tibble(name = \"John\", age = 30),\n  sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n  trt = tibble(name = \"Mary\", treatment = \"A\")\n)\ndfs\n\n$age\n# A tibble: 1 × 2\n  name    age\n  &lt;chr&gt; &lt;dbl&gt;\n1 John     30\n\n$sex\n# A tibble: 2 × 2\n  name  sex  \n  &lt;chr&gt; &lt;chr&gt;\n1 John  M    \n2 Mary  F    \n\n$trt\n# A tibble: 1 × 2\n  name  treatment\n  &lt;chr&gt; &lt;chr&gt;    \n1 Mary  A        \n\ndfs |&gt;reduce(full_join)\n\n# A tibble: 2 × 4\n  name    age sex   treatment\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n1 John     30 M     &lt;NA&gt;     \n2 Mary     NA F     A        \n\n\n\n\n\nreduce를 적용할 함수 f가 덧셈이나 곱셈처럼 순서가 안 중요한 함수일 수 있지만 대부분의 다른 함수에서는 순서가 중요할 수 있습니다.\n\n# + 는 방향을 뒤로해도 결과가 달라지지 않습니다. 당연하게도\nreduce(1:3, `+`)\n\n[1] 6\n\nreduce(1:3, `+`, .dir = \"backward\")\n\n[1] 6\n\n# 하지만 다른 함수는 순서가 중요합니다\nstr(reduce(1:4, list))\n\nList of 2\n $ :List of 2\n  ..$ :List of 2\n  .. ..$ : int 1\n  .. ..$ : int 2\n  ..$ : int 3\n $ : int 4\n\nstr(reduce(1:4, list, .dir = \"backward\"))\n\nList of 2\n $ : int 1\n $ :List of 2\n  ..$ : int 2\n  ..$ :List of 2\n  .. ..$ : int 3\n  .. ..$ : int 4"
  },
  {
    "objectID": "news/220821_Rstudio-is-becoming-Posit/index.html#rstudio-is-becoming-posit",
    "href": "news/220821_Rstudio-is-becoming-Posit/index.html#rstudio-is-becoming-posit",
    "title": "RStudio가 Posit으로 이름을 바꾼다",
    "section": "",
    "text": "프로그래밍 언어 그 자체를 가지고 명령어를 통해 작업을 하는 건 많이 어렵습니다. 불편하기도 하고요. 그럴 때 사용하는 게 바로 IDE(통합계발환경, Intergrated Development Environment)입니다. Python을 이용할 때 사용하는 PyCharm이나 Jupyter Notebook, 혹은 MS의 텍스트 에디터 VS Code가 대표적인 IDE라고 할 수 있을겁니다.\nRStudio는 R의 가장 대표 IDE입니다. 그런데 이 RStudio가 지난 7월 말, 본인들의 이름을 바꾼다고 선언했습니다. 아마 8월 중으로 이름표를 새로 바꿀 것 같은데요, 그들이 공개한 RStudio의 새로운 이름은 Posit입니다. RStudio는 왜 갑자기 이름을 Posit으로 바꾸려는걸까요?"
  },
  {
    "objectID": "news/220827_quarto/index.html#quarto가-뭐지",
    "href": "news/220827_quarto/index.html#quarto가-뭐지",
    "title": "R Markdown의 차세대 포맷, Quarto",
    "section": "",
    "text": "RStudio는 자사의 2022년 컨퍼런스 rstudio::conf(2022)에서 발표한 여러 소식 가운데 가장 중요한 소식으로 이렇게 4가지를 꼽았습니다.\n\nRStudio의 이름은 Posit으로 바꾼다\n새로운 오픈소스 기반의 과학기술 출판 시스템, Quarto\nShiny 생태계의 새로운 발전\ntidymodel의 업데이트\n\n1번은 이미 이 포스트에서 다루었죠? 그 연장선이라고 볼 수 있는 Quarto가 이번 게시물의 주제입니다. Quarto는 R Markdown에 이은 RStudio의 차세대 R 출판 플랫폼입니다. 기존의 R Markdown을 이용하면 R code sript를 Word, HTML, PDF, PPT 등 다양한 문서 형식으로 만들 수 있었습니다. 웹을 통한 출판(Bookdown)까지도 가능했죠.\n\n그런데 이 R Markdwon이 어느새 10년 가까이 지났습니다. 기능의 편리함은 지적할만한 게 없었지만 R Markdown 생태계가 너무 커져버렸죠. 관련 생태계가 커졌다는 건 오히려 반길 일이지만 덕지덕지 붙어버린 서드파티 패키지들이 많아진 게 문제였습니다. 더 이상 통일된 하나의 R Markdown의 제작과 작업이 되질 못했습니다. 과학, 기술 블로그를 만들 땐 distill package를 사용하고, 웹 프레젠테이션 파일을 만들 땐 xaringan(사륜안) package를 사용하고…\n그래서 등장한 게 바로 이 Quarto입니다. R Markdown과 마찬가지로 Knitr와 Pandoc을 기반으로 하고 있고요. 궁극적으로 R Studio는 Quarto 생태계에 다른 언어를 사용하는 사람들끼리 모을 생각을 하고 있습니다. 그래서 저번 Posit 이야기의 연장선이라고 말씀을 드린 겁니다. 그 이유 때문인지 Quarto는 R의 내장 라이브러리가 아닌 독립 소프트웨어로 제작되었습니다. 새로운 시스템 Quarto 단어가 생소할 텐데, Quarto는 4절판을 의미합니다. 8페이지 분량의 텍스트를 두 번 접어서 네 장을 만드는 형식을 뜻하죠. 출판 역사에 의미가 있는 단어를 골랐다고 합니다.\n\n\n\nhttps://quarto.org/docs/get-started/\nQuarto는 위 링크에서 받을 수 있습니다. 링크를 들어가면 나오는 홈페이지에서도 확인할 수 있지만 Quarto는 R 뿐만 아니라 VS code, Jupyter에서도 활용할 수 있습니다."
  },
  {
    "objectID": "daily/211012/index.html#today-function-enframe",
    "href": "daily/211012/index.html#today-function-enframe",
    "title": "enframe() : Convert vectors to data frames",
    "section": "",
    "text": "오늘의 함수는 tibble 패키지의 enframe() 함수입니다. enframe() 함수는 atomic vector나 리스트를 1개 혹은 2개의 칼럼을 가진 데이터프레임으로 만들어줍니다. 리스트를 enframe() 함수에 넣고 돌리면 중첩된 tibble이 나옵니다. 만일 2개의 칼럼의 데이터프레임을 vector 혹은 리스트로 변환하고 싶으면 deframe() 함수를 사용하면 됩니다.\n\n\n\n\nenframe(x, name = \"name\", value = \"value\")\n\ndeframe(x)\n\n\n\n\n\nx : enframe() 함수에는 벡터가, deframe() 함수에는 1~2열 짜리 데이터프레임이 들어갑니다  name, value : name과 value로 지정하고 싶은 텍스트를 입력합니다. 만약 name이 NULL이라면 1열의 데이터프레임이 출력됩니다.\n\n\n\n\n\nlibrary(tibble)\n\n# 1부터 3까지 Unnamed Numeric vector를 enframe에 넣으면\nenframe(1:3)\n\n# A tibble: 3 × 2\n   name value\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# 이번엔 Named Numeric vector를 입력해봅니다\nenframe(c(a = 1, b = 2, c = 3))\n\n# A tibble: 3 × 2\n  name  value\n  &lt;chr&gt; &lt;dbl&gt;\n1 a         1\n2 b         2\n3 c         3\n\n# list를 입력하면 중첩된 tibble이 나옵니다\nlist_example &lt;- list(\n  a = 1,\n  b = \"orange\",\n  c = 2:3,\n  d = c(delta = 4)\n)\n\nenframe(list_example)\n\n# A tibble: 4 × 2\n  name  value    \n  &lt;chr&gt; &lt;list&gt;   \n1 a     &lt;dbl [1]&gt;\n2 b     &lt;chr [1]&gt;\n3 c     &lt;int [2]&gt;\n4 d     &lt;dbl [1]&gt;\n\n# deframe은 1~2개의 칼럼을 가지고 있는 데이터프레임만 사용가능합니다\ndeframe(enframe(3:1))\n\n1 2 3 \n3 2 1 \n\ndeframe(tibble(a = as.list(1:3)))\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3"
  },
  {
    "objectID": "posts/220918_quant/index.html#tidyquant-package",
    "href": "posts/220918_quant/index.html#tidyquant-package",
    "title": "내가 원하는 주식 종목 정보 한번에 불러오기",
    "section": "",
    "text": "R을 활용해 주식을 분석하는 방법엔 다양한 선택지가 있습니다. 주식정보 사이트에서 데이터를 크롤링해 분석하는 방법, 그리고 패키지를 활용하는 방법 등… R의 퀀트 분석에서 가장 유명한 패키지는 아마 quantmod package일 겁니다. quantmod package를 이용하면 주식, 환율, 원자재 등 다양한 경제 데이터를 활용해 분석할 수 있습니다. 하지만 오늘은 tidyquant package를 활용해 퀀트 분석을 정리해보려고 합니다.\ntidyquant package는 zoo, xts, quantmod, TTR 등의 정량 데이터 및 시계열 데이터 분석 패키지를 통합해 제공해주고 있습니다. 거기에 패키지 이름에서 알 수 있듯 tidyverse 생태계의 도구를 사용해서 퀀트 분석을 할 수 있도록 설계되어 있죠. ggplot2를 이용한 시각화도 물론 가능합니다. 그럼 본격적으로 tidyquant package를 이용해 퀀트 분석을 시작해보겠습니다."
  },
  {
    "objectID": "posts/220320_geofacet/index.html#geo_grid를-활용한-시각화",
    "href": "posts/220320_geofacet/index.html#geo_grid를-활용한-시각화",
    "title": "득표율을 한 눈에! 득표율 지도 시각화",
    "section": "",
    "text": "FiveThirtyEight의 2020 미 대선 선거결과 시각화\n\n\n해외 언론에서 선거 결과를 시각화한 기사를 볼 때마다 드는 생각이 있습니다. “아 우리나라도 저렇게 격자형태로 시각화하면 멋드러지지 않을까…” 국내에서는 시군구 혹은 읍면동 단위로 색을 칠하는 형태가 대부분이지 그 안에 그래프를 넣어서 시각화하기가 힘들어요. 미국은 50개 주에 1개의 특별구로 이루어졌으니, 필요한 격자는 51개 뿐이지만 우리나라의 시군구는 250개. 큰 권역 구분 정도는 다양한 시각화를 시도할 수 있지만 시군구 단위로 하기엔 부담이 될 수 있는거죠.\n\n\n\n\n그래도 해보고 싶습니다. 우리나라도 시군구 단위로 멋드러지게 만들고 싶어요. 그래서(!) 시군구 단위 그리드 만들어 봤습니다. 활용한 패키지는 geofacet입니다. geofacet은 말 그대로 지리적 정보(geo)로 면(facet)을 분할해 볼 수 있는 패키지인데요, 이 패키지가 좋은 건 Grid Designer라는 기능을 통해 자기만의 그리드를 만들 수 있다는 거죠. 그래서 지도를 펼치고 250개 시군구의 위치를 하나하나 지정해가며 만들어 봤습니다. geofacet package에도 제출해 놓았습니다. 여기에서 확인할 수 있어요.\n\nlibrary(readr)\nmygrid &lt;- read_csv(\"kr_sgg.csv\", col_types = cols(code = col_character()))\n\nhead(mygrid[,c(1,3,4,2)])\n\n# A tibble: 6 × 4\n  code    row   col name               \n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;              \n1 11110     5     7 서울특별시 종로구  \n2 11140     6     7 서울특별시 중구    \n3 11170     7     7 서울특별시 용산구  \n4 11200     6     8 서울특별시 성동구  \n5 11215     7     8 서울특별시 광진구  \n6 11230     5     8 서울특별시 동대문구\n\n\n만들어 놓은 대한민국 시군구 단위 그리드 구조는 아주 간단합니다. 이름, row, col, code 정도로 이루어져 있죠. geofacet 함수는 그리드의 행(row)과 열(col)을 인식해서 그 모양에 맞춰 facet해 주는 구조입니다. 이 그리드를 가지고 그려보면 이런 모양이 나옵니다.\n\ngeofacet::grid_preview(mygrid)\n\n\n\n\n\n\n\n\n짜잔~ 면적이 서로 다른 시군구를 동일한 면적 단위로 표현했기때문에 실제 위치와는 차이가 있을 수 있습니다. 시군구 그리드에 적용된 코드는 행정안전부에서 제공하고 있는 행정표준코드를 따라서 만들어 놓았습니다. 종로구(11110), 중구(11140) 이런식으로 말이죠. 시군구 단위의 여러 데이터들을 합쳐서 시각화, 분석할 일 있으면 행정코드 기준으로 정리한다면 간단하게 할 수 있을 겁니다."
  },
  {
    "objectID": "posts/230316_GNN_intro_1/index.html#gnn-publication",
    "href": "posts/230316_GNN_intro_1/index.html#gnn-publication",
    "title": "그래프는 세상 어디에나 있다",
    "section": "",
    "text": "GNN 관련 내용을 공부하면서 찾게 된 좋은 간행물이나 논문 등을 번역 및 정리해서 올리려고 합니다. 그 첫 번째 순서로 지난 2021년 9월 2일 Distill에서 발행된 &lt; A Gentle Introduction to Graph Neural Networks &gt;입니다. 당시 Google Research 소속의 다섯 연구원이 작성한 글인데요, GNN 입문자에게 적당한 설명이 있는 것 같아 정리해 보았습니다.\n\n\n\n\nDistill은 2016년부터 2021년까지 운영된 머신러닝 관련 과학 저널입니다. Explanation, Interactive Articles, Visualization 등 기존의 과학 저널에서 표현하지 않던 스토리텔링을 담아 새로운 과학 출판물을 제작했죠. 저널이니만큼 투고도 가능했지만 그러려면 Distill Template에 맞춰서 제작해야 했습니다.\n전통적인 과학 저작물을 넘어선, 새로운 과학 저널을 꿈꾸었던 Distill의 시도는 성공으로 이어지진 못했습니다. 기존 저널에서도 큰 반향을 일으키진 못했고, 논문을 작성하는 사람들이 Interactive 요소를 담아서 Distill의 Template을 맞추기도 어려웠죠. 결국 2021년 이후 Distill은 무기한 중단 중입니다.\n\n\n그렇다고 Distill이 사라진 건 아닙니다. R에서 이 Distill Template을 참조해 과학 및 기술 커뮤니케이션 용 Markdown을 만들었거든요. 이름하여 Distill for R Markdown, Distill package였죠. 과학, 기술 블로그를 만드는 데 도움을 준 Distill package는 지금은 Quarto의 Blog, Website Format으로 흡수되어 있습니다. 더 많은 사람들에게 과학 아티클을 이해하기 쉽게 표현하려 했던 Distill의 노력은 지금 이 Quarto 블로그에 남아있는 거죠.\n헤어졌던 Distill을 다시 만나게 되어 이상한 기분이 들었는지 서두가 길었습니다. 본격적으로 &lt; A Gentle Introduction to Graph Neural Networks &gt;를 정리해 보겠습니다. Distill의 원 게시글은 D3를 활용한 Interacitve 요소가 풍부하게 담겨있으니 꼭 한번 살펴보세요."
  },
  {
    "objectID": "posts/230316_GNN_intro_1/index.html#footnotes",
    "href": "posts/230316_GNN_intro_1/index.html#footnotes",
    "title": "그래프는 세상 어디에나 있다",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n이 글은 2021년 9월 2일에 출간되었습니다↩︎\n픽셀이 가지고 있는 색상 정보↩︎\n문법적으로 더 이상 나눌 수 없는 언어요소↩︎\nCitronellal 분자↩︎"
  },
  {
    "objectID": "posts/230108_quarto_yaml/index.html#quarto-뜯어보기",
    "href": "posts/230108_quarto_yaml/index.html#quarto-뜯어보기",
    "title": "뜯어먹는 Quarto ①YAML",
    "section": "",
    "text": "R & stats illustrations by @allison_horst\n\n\n지난 게시물에선 R Markdown의 차세대 포맷, Quarto의 등장 배경에 대해 살펴봤습니다. Quarto를 한 문장으로 정리해 보면 이렇게 이야기할 수 있습니다. Quarto는 “마크다운 등 일반 텍스트 형식(.qmd, .rmd, .md)과 혼합 형식(.ipynb, jupyter notebook)을 pandoc과 knitr 패키지를 통해 PDF/Word/HTML/책/웹사이트/프레젠테이션 등 다양한 형태로 렌더링 하는 명령줄 인터페이스(CLI)다”라고요.\nR Studio나 VS code 같은 IDE로 Quarto를 이용하면 Quarto의 CLI의 모습을 엿보기 어렵지만 명령 프롬프트를 이용하면 바로 확인할 수 있습니다. 아래 이미지는 iTerm에서 quarto --help라는 명령어를 입력하면 나오는 Quarto의 개괄입니다.\n\nquarto --help\n\n\n  Usage:   quarto \n  Version: 1.2.313\n\n  Description:\n\n    Quarto CLI\n\n  Options:\n\n    -h, --help     - Show this help.                            \n    -V, --version  - Show the version number for this program.  \n\n  Commands:\n\n    render          [input] [args...]     - Render files or projects to various document types.        \n    preview         [file] [args...]      - Render and preview a document or website project.          \n    serve           [input]               - Serve a Shiny interactive document.                        \n    create          [type] [commands...]  - Create a Quarto project or extension                       \n    create-project  [dir]                 - Create a project for rendering multiple documents          \n    convert         &lt;input&gt;               - Convert documents to alternate representations.            \n    pandoc          [args...]             - Run the version of Pandoc embedded within Quarto.          \n    run             [script] [args...]    - Run a TypeScript, R, Python, or Lua script.                \n    add             &lt;extension&gt;           - Add an extension to this folder or project                 \n    install         [target...]           - Installs an extension or global dependency.                \n    publish         [provider] [path]     - Publish a document or project. Available providers include:\n    check           [target]              - Verify correct functioning of Quarto installation.         \n    help            [command]             - Show this help or the help of a sub-command.               \n\n\n\n\n\n\nQuarto라는 녀석이 CLI라는 건 그렇게 중요하지 않습니다. 왜냐면 우리가 Quarto를 이용해서 얻고자 하는 건 글을 쓰고, 블로그를 쓰고, 책을 출간하고, 발표자료를 만들려고 하는 거니까요. 그러려면 우선 Quarto 문서(.qmd)를 작성해야 합니다. 이번 게시물에선 Quarto 문서, 그 자체에 집중해서 이야기를 나눠보도록 하겠습니다. 먼저 Quarto 문서가 어떻게 구성되어 있는지 살펴보겠습니다. Quarto 문서는 크게 3가지 요소로 구분할 수 있습니다.\n\n\n\n\n\n\nMetadata: YAML header\nText: Markdown\nCode: knitr or jupyter\n\n이 세 가지 요소를 잘 버무려서 Quarto 문서를 작성하면 다양한 형태의 콘텐츠를 제작할 수 있습니다. 지금 이 게시물 역시 Metadata와 Text, Code 이렇게 3가지 요소로 만든 qmd 파일을 html로 렌더링 한 거죠.\n\n\n\n먼저 Metadata가 담겨있는 YAML header입니다. 지금 이 게시글의 YAML header는 요런 모습입니다.\n---\ntitle: '뜯어먹는 Quarto ①YAML'\ndate: '2023-01-08'\ncategories: ['R Markdown', 'Quarto', 'YAML']\ndescription: \"YAML Ain't Markup Language\"\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\nYAML header의 내용을 보면 꽤나 직관적입니다. title에는 게시물 제목이, date에는 작성 시점이, cateogories에는 이 게시물의 카테고리가 표시되어 있죠. YAML header에는 이 문서의 메타데이터를 표시해 줍니다. 메타데이터는 다른 데이터를 설명해 주는 데이터를 뜻합니다. 메타데이터의 메타(Meta)는 about(~에 관하여)과 같은 의미를 갖고 있죠. 이론을 대상으로 하는 이론을 뜻하는 메타이론(metatheory), 수학으로 수학 자체를 연구하는 메타수학(Metamathematics)의 메타와 같아요.\n\n\n\n\n두 번째는 텍스트 항목입니다.\n## Quarto 뜯어보기\n\n지난 게시물에선 R Markdown의 차세대 포맷, Quarto의 등장 배경에 대해 살펴봤습니다. \nQuarto에서는 마크업 언어의 일종인 마크다운(Markdown)을 이용해 텍스트를 작성합니다. HTML 문서를 무작정 작성하려고 하면 온갖 다양한 태그를 사용하게 되는데 그걸 일일이 작성하긴 어려우니까요. 마크다운(Markdown)을 이용하면 훨씬 쓰기 쉽고, 읽기 쉬운 형태의 문서를 쓸 수 있습니다.\n\n\n\n\n마지막은 코드입니다. R을 사용하는 사람들은 knitr 엔진을, python을 사용하는 사람들은 jupyter 엔진을 활용해 인라인 코드를 작성하고, 시각화를 구현할 수 있습니다. 이런 식으로 말이죠.\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")"
  },
  {
    "objectID": "posts/230101_purrr/index.html#purrr-package",
    "href": "posts/230101_purrr/index.html#purrr-package",
    "title": "pure function과 친해지려면 purrr 합시다",
    "section": "",
    "text": "데이터를 요리조리 만지다보면, 혹은 R을 조금 더 본격 프로그래밍적으로 접근하고 싶어서 이것저것 찾다보면 purrr 패키지를 만나게 됩니다. 마침 작년 12월 20일에 purrr 패키지 1.0.0 버전이 출시되었으니 새해를 여는 R쓸 이야기의 주인공으로 purrr 패키지를 골라봤습니다.\n\n\n\n“It’s designed to make your pure functions purrr”\n\npurrr 패키지가 세상에 처음으로 선을 보인건 2015년 9월입니다. 9월 29일 rstudio blog에 purrr 0.1.0을 올리며 쓴 포스트를 보면 왜 purrr 패키지를 만들었는지 알 수 있죠. “이 패키지는 당신의 순수한 함수를 그르릉되게 만들도록 설계되었습니다.” 이 문장의 표현대로 purrr 패키지는 R의 함수형 프로그래밍(FP)의 빈틈을 채워주는 패키지입니다.\n그런데 이름은 왜 purrr로 정해졌을까요? purr라는 단어의 원래 뜻은 “그르렁대다”입니다. 그 영향으로 로고에는 귀여운 고양이가 담겨있죠. tidyverse 깃허브를 구경하다 보면, 당시 개발자들이 훗날 purrr가 될 새로운 패키지에 어떤 이름을 붙일지 고민한 흔적을 확인할 수 있습니다. 그 흔적을 살펴보면 purrr라는 작명의 이유를 찾을 수 있죠.\n당시 함수형 프로그래밍 패키지 이름의 첫 번째 후보는 purr였습니다. 순수한 함수(pure function)와 어울리게 pure로도 읽을 수 있고, 함수(function → purpose → purr)라는 단어의 흔적도 담을 수 있으니 괜찮아 보입니다. 또 다른 후보는 funr이었어요. fun한 패키지면서도 function, 즉 함수형 프로그래밍의 의미를 담으려 했죠. funr 외에도 funcr, funkr, funker 등이 function의 흔적이 담긴 이름 후보들이었습니다. 최종적으로는 purr에 R이 더해져 purrr이 되었죠.\n\n\n그런데 여기서 이야기하는 함수형 프로그래밍(FP, Functional Programming)은 뭘까요? 프로그래밍은 크게 명령형 프로그래밍(Imperative Programming)과 선언형 프로그래밍(Declarative Programming)으로 구분할 수 있습니다. 물론 엄밀하게 구분하면 아래와 같은 지도같이 더 복잡하게 구분할 수도 있는데, 우리는 purrr 패키지를 이해하는 게 우선이니 명령형과 선언형으로만 구분해 보겠습니다.\n\n\nOverview of the various programming paradigms according to Peter Van Roy\n\n명령형 프로그래밍은 프로그래밍의 상태와 상태를 변형시키는 구문의 관점에서 연산을 설명합니다. 우리가 일반적으로 누군가에게 명령(혹은 부탁)을 할 때 어떤 동작을 할 것인지를 표현하는 것처럼, 명령형 프로그래밍은 컴퓨터에게도 컴퓨터가 수행할 명령을 순서대로 말하는 방식을 의미합니다. 즉 명령형 프로그래밍은 컴퓨터에게 무엇(What)을 할 것인지에 방점을 찍어 설명하는 게 아니라 어떻게(How)할 것인지에 중심을 두고 설명합니다.\n반면 선언형 프로그래밍은 어떻게(How)가 메인이 아니라 무엇(What)이 메인인 프로그래밍 방법입니다. 웹 페이지나 블로그의 코드를 생각해 보죠. 우리는 블로그의 코드를 작성할 때 제목과 본문, 그림, 폰트와 같이 무엇(What)이 화면에 나타나야 하는지를 코드로 표현합니다. 이런 접근방식을 선언형 프로그래밍이라고 합니다.\n함수형 프로그래밍은 선언형 프로그래밍에 속합니다. 이름에서 알 수 있듯이 함수를 조합해서 소프트웨어를 만드는 방식을 의미하죠. 함수형 프로그래밍은 거의 모든 것을 함수로 접근합니다. 아무리 작은 것도 함수로 표현하려고 합니다. 이렇게 하면 코드 가독성이 높아지고, 코드의 유지보수가 용이해진다는 장점이 있어요. 참고로 함수형 프로그래밍은 람다 대수라는 대수 체계를 기반으로 발전했는데, 그래서 lambda라는 이름이 purrr 패키지의 또다른 후보이기도 했죠."
  },
  {
    "objectID": "posts/220904_Ragg/index.html#한글이-깨진다",
    "href": "posts/220904_Ragg/index.html#한글이-깨진다",
    "title": "한글 폰트 깨짐 현상 Ragg package로 부셔드림",
    "section": "",
    "text": "R에서 데이터를 잘 정제해서 시각화를 만들면 항상 한글의 벽에 부딫히곤 합니다. 한글을 인식하지 못하는 경우에는 인코딩을 해결하면 깨짐현상을 막을 수 있죠. 그렇다면 이미지를 추출할 때 한글이 깨지는 경우는 어떻게 할까요? 여기 그 예시가 있습니다. 대한민국의 주요 도시의 위치를 나타내기 위해 이런 데이터 셋을 만들어봤어요. tibble package에서 소개했던 tibble::tribble 함수를 이용해봤습니다. 세계화 시대에 맞춰 도시명에는 한글과 영어, 그리고 한자까지 포함했고요.\n\nlibrary(tibble)\n\nROK_city &lt;- tribble(\n  ~City, ~Lat, ~Lon,\n  \"울산(Ulsan, 蔚山)\", 35.549999, 129.316666,\n  \"광주(Gwangju, 光州)\", 35.166668, 126.916664,\n  \"대전(Daejeon, 大田)\", 36.351002, 127.385002,\n  \"대구(Daegu, 大邱)\", 35.866669, 128.600006,\n  \"부산(Busan, 釜山)\", 35.166668, 129.066666,\n  \"청주(Chungju, 淸州)\", 36.981304, 127.935905,\n  \"원주(Wonju, 原州)\", 37.342220, 127.920158,\n  \"인천(Incheon, 仁川)\", 37.456257, 126.705208,\n  \"서울(Seoul)\", 37.532600,127.024612\n)\n\n\n이 데이터셋을 바탕으로 지도를 그려봤습니다. 지도의 제목은 &lt;🇰🇷대한민국(大韓民國)의 주요 도시 위치&gt;로 해봤습니다. 그래프 제목에 이모지 정도는 써 줘야 그래도 웹 3.0 시대를 살고 있다고 할 수 있지 않겠습니까? 그렇게 만들어본 그래프의 모습입니다.\n\n\n\n\n처참한 모습입니다. 영어를 제외한 모든 글자를 인식하지 못하는군요. 하지만 걱정하지 마세요. 해결책이 있습니다. 바로 Ragg package를 이용하면 됩니다."
  },
  {
    "objectID": "posts/220527_palmerpenguins-package/index.html#palmerpenguins-package",
    "href": "posts/220527_palmerpenguins-package/index.html#palmerpenguins-package",
    "title": "iris 대신 penguins package 씁시다",
    "section": "",
    "text": "오늘 소개할 R package는 palmerpenguins package입니다. 남극의 파머 군도에 있는 3곳의 섬에서 관찰된 3종의 펭귄 데이터가 담겨져 있죠.\n\n\n\n파머 군도에 있는 Dreams Island, Torgersen Island, Biscoe Point에는 세 종의 펭귄이 살고 있습니다. 턱끈 펭귄(Chinstrap), 젠투 펭귄(Gentoo), 아델리 펭귄(Adélie) 이렇게 말이죠. palmerpenguins package에는 이 세 펭귄의 크기, 성별 정보가 담겨있습니다. 펭귄들의 데이터는 미국의 장기 생태 연구 네트워크(US Long Term Ecological Research Network)에서 운영하는 프로그램의 일부로, 파머 군도에서 2007년부터 2009년까지 크리스틴 고먼 박사에 의해 수집됐습니다.\n\n\n\n\nR을 이용하는 유저 중에 iris 데이터를 한 번이라도 안 써본 유저는 없을 겁니다. iris 데이터는 로널드 피셔(Ronald Fisher)의 1936년 논문에 포함되어 있던 유서 깊은 자료입니다. R에 기본적으로 내장되어 있는 데이터이기도 하고 기본적인 R 연산, 시각화를 공부하는데 iris만한 데이터가 없죠. 그런데 이 iris 데이터를 이제 그만 쓰자는 목소리가 나오고 있어요. 바로 로널드 피셔 때문이죠.\n\n\n\n\n피셔는 통계학자이자 유전학자이자 진화생물학자였습니다. 현대 통계학에 지대한 공을 세운 학자로 알려져있습니다. 통계학자 앤더스 할(Anders Hald)은 피셔를 두고 현대 통계학의 토대를 거의 혼자서 만들어낸 천재로 지칭할 정도죠. Bootstrap을 처음으로 제안한 브래들리 에프론(스탠퍼드 대학교 통계학과 교수)도 로널드 피셔를 20세기 통계에서 가장 중요한 인물이라고 말할 정도입니다.\nF-검정, F-분포의 F가 바로 피셔의 F입니다. 피셔가 F-분포를 처음 제안했고, 조지 W 스네데코가 이후에 완성하면서 처음 제안한 피셔를 기려 F-분포, F-검정이라고 명명한거죠. 그래서 F-분포를 피셔-스네데코 분포라고도 합니다\n전체 대상(모집단)의 특성(모수)을 파악하기 위해 표본을 추출해 추론하는 건 현대 통계에서 아주 당연한 접근방식이죠? 이 흐름을 만든 게 바로 로널드 피셔입니다. 피셔는 모집단과 표본집단을 구분짓고, 일부(표본집단)를 통해 전체(모집단)에 대한 분석이 가능하다는 걸 귀무가설로 증명해 냈습니다. 귀무가설(null hypothesis)도 피셔가 정의한 개념입니다.\n그리고 이걸 발전시켜서 추측통계학, 이른바 추계학(stochastic)을 탄생시키죠. 추계학은 통계의 범위를 수학뿐만 아니라 여론조사, 제품검사, 의약품의 효과 등 사회과학의 방법론까지 확장시켰습니다. 20세기 통계에서 가장 중요한 인물이라고 칭하는 게 부족함이 없어보입니다.\n그런데 그 대단한 피셔가 우생학자로도 유명했습니다. BLM 시위 이후 피셔의 우생학자로서의 삶이 다시 재조명되면서 과학 분야 전반에서 정화의 흐름이 나오고 있습니다. 영국의 명문대학 유니버시티 칼리지 런던은 피셔의 이름이 붙은 연구 센터의 이름을 Center for Computational Biology로 바꾸기도 했죠. 그래서 iris를 과연 계속 써야하는지에 대한 논의가 나온 겁니다. 그 대안으로 떠오른 데이터셋이 바로 palmerpenguins package의 펭귄 데이터입니다."
  },
  {
    "objectID": "posts/220220_ggbump-package/index.html#ggbump-package",
    "href": "posts/220220_ggbump-package/index.html#ggbump-package",
    "title": "bump chart를 그리고 싶을 때, ggbump package",
    "section": "",
    "text": "ggplot2는 grammar of graphics(a.k.a. gg)을 토대로 시각화를 만드는 패키지입니다. 2는 ver.2의 의미를 담았죠. gg는 릴랜드 윌킨스의 동명의 책 The Grammar of Graphics에서 따온 건데, 이 책에서 릴랜드는 데이터를 어떻게 시각적으로 표현할 것인지에 대해 다룹니다. gg에 대한 이야기는 나중에 다른 포스트에서 다루도록 하겠습니다.\nggplot2 패키지의 문법 기반 위에서 돌아가는 서브 패키지들은 보통 gg라는 접두사로 시작됩니다. ggbump 역시 ggplot2의 일원이라고 이해할 수 있어요. 그렇다면 bump는 무엇을 의미하는 걸까요? 자동차의 범퍼, 혹은 놀이동산의 범퍼카를 떠올리면 bump의 의미를 유추할 수 있어요. bump는 바로, 충돌을 의미합니다. 충돌과 차트, 어떤 연관이 있는 걸까요?\n\n\n\n\n\n\n\n2022 May Bumps, Corpus Christi College\n\n\n영국의 케임브리지 대학에는 The bump라고 불리는 조정 경기가 있습니다. 케임브리지를 가로지르는 캠 강(river Cam) 은 나란히 경주하기에는 너무 좁아서 한 줄로 경주하는 독특한 조정 경주를 진행해왔어요. 19세기 초부터 시작된 이 경기 이름이 바로 The bump입니다. The bump의 경주 방식은 이렇습니다. 우선 강을 따라 한 줄로 경기를 시작합니다. 각 선수들은 전속력으로 노를 저어 앞에 있는 보트를 따라잡고 충돌(bump)하죠. 그렇게 되면 앞에 있는 조정 팀을 추월한 것으로 인정, 순위가 올라가게 됩니다. 주최 측에서는 경기의 진행 상황을 매핑하는 차트를 그려서 제공했는데, 이 차트를 bump chart라고 불렀습니다. 아래 차트는 2020년 사순절에 치러진 대회(Lent Bump)의 남자부 경기 결과입니다. 어떤 차트인지 감이 오죠?\n\n\n\n\n\n\n로고에는 3개의 노드(점), 노드에 연결된 시그모이드 곡선이 보입니다. 시그모이드(Sigmoid) 곡선은 S자 모양의 부드러운 곡선을 의미합니다. Sigmoid라는 단어의 뜻이 S자 모양이거든요. 시그모이드 곡선은 로지스틱 방정식, 정규분포의 누적분포함수에서 확인할 수 있습니다. 아래 차트를 보면 정규분포의 누적분포함수의 부드러운 S자 곡선을 확인할 수 있습니다.\n\nlibrary(tidyverse)\n\n# ggplot2에서 주요 확률분포 곡선을 그릴 때는 stat_function을 활용하면 됩니다\n# 정규분포(norm)의 누적분포함수를 그릴 땐 fun = pnorm 조건을 쓰세요\n# 마찬가지로 지수분포(exp)에서 누적분포함수를 그릴 땐 fun = pexp 조건을 쓰면 됩니다.\n\nggplot(data.frame(X = c(-3, 3)), aes(x = X)) +\n  stat_function(fun = pnorm, colour = \"black\", size = 1) +\n  ggtitle(\"Cumulative Normal Distribution of X ~ N(0,1)\") +\n  theme_classic()\n\n\n\n\n\n\n\n# 참고로 접두사 p는 누적분포함수(CDF)를 의미하고, \n# 접두사 q는 누적분포함수(CDF)의 역함수인 분위수함수를, \n# 접두사 r은 무작위 난수 샘플을 의미합니다\n\nggbump package를 활용하면 시그모이드 곡선도 그릴 수 있습니다. 그럼 본격적으로 ggbump 패키지에 대해서 살펴보도록 하죠."
  },
  {
    "objectID": "posts/210502_tibble-package/index.html#tibble-package",
    "href": "posts/210502_tibble-package/index.html#tibble-package",
    "title": "data frame의 진화, tibble package",
    "section": "",
    "text": "tidyverse 패키지를 사용하면 data.frame 대신 사용하게되는 tibble. 오늘 알아볼 R package는 tibble입니다. tibble 패키지의 역사부터 기존의 data.frame과는 어떻게 다른지 정리해봅니다.\n\n\n\n2014년 1월, dplyr 패키지에선 data.frame을 tbl_df이라는 서브클래스로 사용했습니다. 이전의 data.frame과 다르게 출력된 결과가 콘솔창을 다 뒤덮지도 않고 칼럼명 아래에 자료형을 표현해주는 강점이 있었죠. 이 tbl_df가 지금의 tibble 패키지의 시초입니다. tbl_df를 [티블-디프]로 읽다가 뒤에 df는 떨어져나가고 tbl남 남아 결국엔 tibble이 되었죠. 참고로 패키지를 만든 해들리 위컴은 뉴질랜드 사람인데, 뉴질랜드인들이 table을 tibble이라고 발음한다고 합니다.\n\n\n\n\n위대한 패키지 tidyverse의 일원인만큼 tibble 로고의 뒷 배경은 tidyverse 세계관을 공유하고 있습니다. 우주 배경을 뒤에 두고 표가 그려져있죠. 그 위엔 TIBBLE 이라는 이름표가 적혀있고요. 폰트 스타일은 스타트랙을 닮았는데, 스타트랙에는 tibble과 유사한 tribble이라는 크리쳐가 등장합니다. tribble은 tibble 패키지의 함수로도 등장하는데 이건 뒤에서 설명 드리겠습니다. tibble 이름표를 잘 보면 TI33으로도 읽을 수 있는데 공학용 계산기로 유명한 텍사스 인스트루먼트(TI)에서 만든 동명의 모델이 있죠. (물론 의도한지는 모르겠지만요)"
  },
  {
    "objectID": "daily/211004/index.html#today-function-pull",
    "href": "daily/211004/index.html#today-function-pull",
    "title": "pull() : Extract a single column",
    "section": "",
    "text": "오늘의 함수는 dplyr 패키지의 pull() 함수입니다.  pull() 함수는 $ 연산자와 비슷한 기능을 합니다.  $ 연산자는 R에서 데이터 객체의 특정 부분을 추출할 때 사용하는데요.  pull() 함수는 파이프 연산자 내에서 $보다 사용하기 편리하다는 장점이 있습니다.\n\n\n\n\npull(.data, var = -1, name = NULL, ...)\n\n\n\n\n\n.data : data.frame, tibble을 넣을 수 있습니다. 거기에 dbplyr, dtplyr package의 data.table backend도 가능합니다.  var : 추출할 변수의 이름을 넣습니다. 숫자도 가능한데 양수는 왼쪽부터 순서, 음수는 오른쪽부터 순서를 나타냅니다.  name : 변수 이름을 알 경우엔 name이라는 파라미터를 써도 됩니다.\n\n\n\n\n입력한 데이터와 동일한 사이즈의 vector가 나옵니다.\n\n\n\n\n\nlibrary(dplyr)\n\n# mtcars 데이터를 가지고 pull() 함수의 예를 들어보겠습니다.\n# mtcars 데이터의 구조는 이러합니다.\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n# -1을 입력하면 mtcars 데이터의 맨 오른쪽 칼럼인 carb가 나옵니다\nmtcars |&gt; pull(-1)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n# 칼럼 명 'carb'을 바로 써도 같은 결과가 나옵니다\nmtcars |&gt; pull(carb)\n\n [1] 4 4 1 1 2 1 4 2 2 4 4 3 3 3 4 4 4 1 2 1 1 2 2 4 2 1 2 2 4 6 8 2\n\n\n\n\n\n\ndplyr에 있는 또다른 비슷한 함수인 select와의 차이점은 뭘까요? 일단 결과 값이 다릅니다.  pull은 단일 열을 벡터로 변환해 결과로 내보냅니다. 반면 select는 하나 이상의 열을 데이터프레임으로 변환하죠.\n\nfruits &lt;- data.frame(orange = 1:5, lemon = 5:1)\n\n# select를 써서 orange 열(1개의 열)을 가져오면 data.frame이 나옵니다\nfruits |&gt; select(orange) |&gt;str()\n\n'data.frame':   5 obs. of  1 variable:\n $ orange: int  1 2 3 4 5\n\n# 이번엔 pull을 이용하면 int value가 들어간 벡터가 나옵니다\nfruits |&gt; pull(orange) |&gt; str()\n\n int [1:5] 1 2 3 4 5\n\n# data.frame에서 pull과 의미가 동일한 함수 -&gt; .[, \"name\"]\nfruits %&gt;% .[ , \"orange\"] %&gt;% str()\n\n int [1:5] 1 2 3 4 5"
  },
  {
    "objectID": "daily/240108/index.html",
    "href": "daily/240108/index.html",
    "title": "사랑하는 소년이 얼음 밑에 살아서",
    "section": "",
    "text": "시간의흐름 인스타그램 이미지\n\n\n책의 첫인상은 ’매우 아담하다’였다. 내 엄지와 검지를 길게 주욱 펼쳐 최대한의 한 뼘을 만들면 이 책의 세로를 품을 수 있을 정도로 자그마하다. 크기 정보를 찾아보니 가로 105mm, 세로 175mm. 내가 산 책 중에 아마 가장 작은 책일 것이다. 이렇게 자그마한 책에 어떤 시들이, 어떻게 담겨있을까?\n책을 펼친다. 이 책은 보통의 책의 방식을 따르지 않는다. 보통의 책이라면 책 등을 잡고 좌우로 페이지를 넘기는 게 정석이다. 이 책은 좌우로 보는 게 아니라 가로로 돌려서 위아래로 올리며 읽어야 한다. 마치 연극 대본을 읽는 듯.\n본문 서체의 인상이 좋다. 찾아보니 초행이라는 서체를 활용했다고 한다. 서체의 이름도 멋이 있다. 초행은 1957년에 제작된 &lt;동아출판사 새백과사전&gt; 초반본에 사용된 본문 활자인 동아 명조를 재해석한 서체다. 당시 6.5pt의 작은 크기로 조판했던 동아 명조를 바탕으로 제작해서 작은 크기에도 선명하게 보이는 특징이 있다.\n이쯤 되니 아담하다는 첫인상에 ’아름답다’는 또 다른 인상을 추가해야겠다는 마음이 든다. 이 책이 아름답다고 느낀 건 나만의 취향이 아닌 듯하다. 이 책을 포함해 시간의흐름 시인선 세 권이 &lt;2023 서울국제도서전&gt;에서 ’한국에서 가장 아름다운 책’에 선정되었으니.\n책을 읽는다. 소녀와 소년의 이야기다. 소녀, 소년의 대사도 있지만 대본처럼 지문이 있다. 대본의 어느 페이지를 펼치더라도 시가 있다.\n\n소녀 멀구나.  소년 그리운 만큼 멀구나.  소녀 깊겠지.  소년 그리운 만큼 깊겠지.   소녀 바다는 수심(水深)이 있으니까.  소년 수심(愁心)이 있으니까.  소녀 그래서 물결이 지나 봐.  소년 그래서 주름이 지나 봐.\n\n문득 어린이가 쓴 동시를 읽고 있다는 느낌이 들기도 한다. 시를 잘은 모르지만 대본에 등장하는 친구들처럼 대화를 하다가 말꼬리를 잡고, 단어를 가지고 말장난을 치는 과정이 시를 만드는 과정과 크게 다를까. 이 책은 한정원 시인의 시집이지만 시집에 등장하는 소녀가, 소년이, 노파가, 베개가, 모서리가 곧 시인인 듯했다.\n\n소년 조심해.\n울다가 웃으면 어른이 된다.\n\n시의 내용이 설명적이거나 직관적이진 않는다. 혹은 소녀와 소년의 우주를 이해하기엔 내가 너무나 많이 울다가 웃었을지도 모르겠다.\n다른 누군가의 우주를 이해하기 위해선 깊은 생각이 필요하다. 소년의 우주도 그렇고, 소녀의 우주도 그렇고, 내 건너편에 앉아있는 직원 A의 우주도 그렇다. 이 책은 그런 깊은 생각을 차분히 길러주기 좋은 시집일지 모른다.\n좋은 사람에게서 좋은 시집을 추천받았다. 올해의 첫인상이 좋다."
  },
  {
    "objectID": "daily/240108/index.html#section",
    "href": "daily/240108/index.html#section",
    "title": "사랑하는 소년이 얼음 밑에 살아서",
    "section": "",
    "text": "시간의흐름 인스타그램 이미지\n\n\n책의 첫인상은 ’매우 아담하다’였다. 내 엄지와 검지를 길게 주욱 펼쳐 최대한의 한 뼘을 만들면 이 책의 세로를 품을 수 있을 정도로 자그마하다. 크기 정보를 찾아보니 가로 105mm, 세로 175mm. 내가 산 책 중에 아마 가장 작은 책일 것이다. 이렇게 자그마한 책에 어떤 시들이, 어떻게 담겨있을까?\n책을 펼친다. 이 책은 보통의 책의 방식을 따르지 않는다. 보통의 책이라면 책 등을 잡고 좌우로 페이지를 넘기는 게 정석이다. 이 책은 좌우로 보는 게 아니라 가로로 돌려서 위아래로 올리며 읽어야 한다. 마치 연극 대본을 읽는 듯.\n본문 서체의 인상이 좋다. 찾아보니 초행이라는 서체를 활용했다고 한다. 서체의 이름도 멋이 있다. 초행은 1957년에 제작된 &lt;동아출판사 새백과사전&gt; 초반본에 사용된 본문 활자인 동아 명조를 재해석한 서체다. 당시 6.5pt의 작은 크기로 조판했던 동아 명조를 바탕으로 제작해서 작은 크기에도 선명하게 보이는 특징이 있다.\n이쯤 되니 아담하다는 첫인상에 ’아름답다’는 또 다른 인상을 추가해야겠다는 마음이 든다. 이 책이 아름답다고 느낀 건 나만의 취향이 아닌 듯하다. 이 책을 포함해 시간의흐름 시인선 세 권이 &lt;2023 서울국제도서전&gt;에서 ’한국에서 가장 아름다운 책’에 선정되었으니.\n책을 읽는다. 소녀와 소년의 이야기다. 소녀, 소년의 대사도 있지만 대본처럼 지문이 있다. 대본의 어느 페이지를 펼치더라도 시가 있다.\n\n소녀 멀구나.  소년 그리운 만큼 멀구나.  소녀 깊겠지.  소년 그리운 만큼 깊겠지.   소녀 바다는 수심(水深)이 있으니까.  소년 수심(愁心)이 있으니까.  소녀 그래서 물결이 지나 봐.  소년 그래서 주름이 지나 봐.\n\n문득 어린이가 쓴 동시를 읽고 있다는 느낌이 들기도 한다. 시를 잘은 모르지만 대본에 등장하는 친구들처럼 대화를 하다가 말꼬리를 잡고, 단어를 가지고 말장난을 치는 과정이 시를 만드는 과정과 크게 다를까. 이 책은 한정원 시인의 시집이지만 시집에 등장하는 소녀가, 소년이, 노파가, 베개가, 모서리가 곧 시인인 듯했다.\n\n소년 조심해.\n울다가 웃으면 어른이 된다.\n\n시의 내용이 설명적이거나 직관적이진 않는다. 혹은 소녀와 소년의 우주를 이해하기엔 내가 너무나 많이 울다가 웃었을지도 모르겠다.\n다른 누군가의 우주를 이해하기 위해선 깊은 생각이 필요하다. 소년의 우주도 그렇고, 소녀의 우주도 그렇고, 내 건너편에 앉아있는 직원 A의 우주도 그렇다. 이 책은 그런 깊은 생각을 차분히 길러주기 좋은 시집일지 모른다.\n좋은 사람에게서 좋은 시집을 추천받았다. 올해의 첫인상이 좋다."
  },
  {
    "objectID": "diary.html",
    "href": "diary.html",
    "title": "DIARY 🤯",
    "section": "",
    "text": "이것 저것 잡다한 생각들\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\n\n\n\n사랑하는 소년이 얼음 밑에 살아서\n\n\n\nBook\n\n\nReview\n\n\n\n시간의 흐름 시인선 첫번째 주인공 한정원\n\n\n\n2024/01/08\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "diary/240108/index.html",
    "href": "diary/240108/index.html",
    "title": "사랑하는 소년이 얼음 밑에 살아서",
    "section": "",
    "text": "시간의흐름 인스타그램 이미지\n\n\n책의 첫인상은 ’매우 아담하다’였다. 내 엄지와 검지를 길게 주욱 펼쳐 최대한의 한 뼘을 만들면 이 책의 세로를 품을 수 있을 정도로 자그마하다. 크기 정보를 찾아보니 가로 105mm, 세로 175mm. 내가 산 책 중에 아마 가장 작은 책일 것이다. 이렇게 자그마한 책에 어떤 시들이, 어떻게 담겨있을까?\n책을 펼친다. 이 책은 보통의 책의 방식을 따르지 않는다. 보통의 책이라면 책 등을 잡고 좌우로 페이지를 넘기는 게 정석이다. 이 책은 좌우로 보는 게 아니라 가로로 돌려서 위아래로 올리며 읽어야 한다. 마치 연극 대본을 읽는 듯.\n본문 서체의 인상이 좋다. 찾아보니 초행이라는 서체를 활용했다고 한다. 서체의 이름도 멋이 있다. 초행은 1957년에 제작된 &lt;동아출판사 새백과사전&gt; 초반본에 사용된 본문 활자인 동아 명조를 재해석한 서체다. 당시 6.5pt의 작은 크기로 조판했던 동아 명조를 바탕으로 제작해서 작은 크기에도 선명하게 보이는 특징이 있다.\n이쯤 되니 아담하다는 첫인상에 ’아름답다’는 또 다른 인상을 추가해야겠다는 마음이 든다. 이 책이 아름답다고 느낀 건 나만의 취향이 아닌 듯하다. 이 책을 포함해 시간의흐름 시인선 세 권이 &lt;2023 서울국제도서전&gt;에서 ’한국에서 가장 아름다운 책’에 선정되었으니.\n책을 읽는다. 소녀와 소년의 이야기다. 소녀, 소년의 대사도 있지만 대본처럼 지문이 있다. 대본의 어느 페이지를 펼치더라도 시가 있다.\n\n소녀 멀구나.  소년 그리운 만큼 멀구나.  소녀 깊겠지.  소년 그리운 만큼 깊겠지.   소녀 바다는 수심(水深)이 있으니까.  소년 수심(愁心)이 있으니까.  소녀 그래서 물결이 지나 봐.  소년 그래서 주름이 지나 봐.\n\n문득 어린이가 쓴 동시를 읽고 있다는 느낌이 들기도 한다. 시를 잘은 모르지만 대본에 등장하는 친구들처럼 대화를 하다가 말꼬리를 잡고, 단어를 가지고 말장난을 치는 과정이 시를 만드는 과정과 크게 다를까. 이 책은 한정원 시인의 시집이지만 시집에 등장하는 소녀가, 소년이, 노파가, 베개가, 모서리가 곧 시인인 듯했다.\n\n소년 조심해.\n울다가 웃으면 어른이 된다.\n\n시의 내용이 설명적이거나 직관적이진 않는다. 혹은 소녀와 소년의 우주를 이해하기엔 내가 너무나 많이 울다가 웃었을지도 모르겠다.\n다른 누군가의 우주를 이해하기 위해선 깊은 생각이 필요하다. 소년의 우주도 그렇고, 소녀의 우주도 그렇고, 내 건너편에 앉아있는 직원 A의 우주도 그렇다. 이 책은 그런 깊은 생각을 차분히 길러주기 좋은 시집일지 모른다.\n좋은 사람에게서 좋은 시집을 추천받았다. 올해의 첫인상이 좋다."
  },
  {
    "objectID": "diary/240108/index.html#section",
    "href": "diary/240108/index.html#section",
    "title": "사랑하는 소년이 얼음 밑에 살아서",
    "section": "",
    "text": "시간의흐름 인스타그램 이미지\n\n\n책의 첫인상은 ’매우 아담하다’였다. 내 엄지와 검지를 길게 주욱 펼쳐 최대한의 한 뼘을 만들면 이 책의 세로를 품을 수 있을 정도로 자그마하다. 크기 정보를 찾아보니 가로 105mm, 세로 175mm. 내가 산 책 중에 아마 가장 작은 책일 것이다. 이렇게 자그마한 책에 어떤 시들이, 어떻게 담겨있을까?\n책을 펼친다. 이 책은 보통의 책의 방식을 따르지 않는다. 보통의 책이라면 책 등을 잡고 좌우로 페이지를 넘기는 게 정석이다. 이 책은 좌우로 보는 게 아니라 가로로 돌려서 위아래로 올리며 읽어야 한다. 마치 연극 대본을 읽는 듯.\n본문 서체의 인상이 좋다. 찾아보니 초행이라는 서체를 활용했다고 한다. 서체의 이름도 멋이 있다. 초행은 1957년에 제작된 &lt;동아출판사 새백과사전&gt; 초반본에 사용된 본문 활자인 동아 명조를 재해석한 서체다. 당시 6.5pt의 작은 크기로 조판했던 동아 명조를 바탕으로 제작해서 작은 크기에도 선명하게 보이는 특징이 있다.\n이쯤 되니 아담하다는 첫인상에 ’아름답다’는 또 다른 인상을 추가해야겠다는 마음이 든다. 이 책이 아름답다고 느낀 건 나만의 취향이 아닌 듯하다. 이 책을 포함해 시간의흐름 시인선 세 권이 &lt;2023 서울국제도서전&gt;에서 ’한국에서 가장 아름다운 책’에 선정되었으니.\n책을 읽는다. 소녀와 소년의 이야기다. 소녀, 소년의 대사도 있지만 대본처럼 지문이 있다. 대본의 어느 페이지를 펼치더라도 시가 있다.\n\n소녀 멀구나.  소년 그리운 만큼 멀구나.  소녀 깊겠지.  소년 그리운 만큼 깊겠지.   소녀 바다는 수심(水深)이 있으니까.  소년 수심(愁心)이 있으니까.  소녀 그래서 물결이 지나 봐.  소년 그래서 주름이 지나 봐.\n\n문득 어린이가 쓴 동시를 읽고 있다는 느낌이 들기도 한다. 시를 잘은 모르지만 대본에 등장하는 친구들처럼 대화를 하다가 말꼬리를 잡고, 단어를 가지고 말장난을 치는 과정이 시를 만드는 과정과 크게 다를까. 이 책은 한정원 시인의 시집이지만 시집에 등장하는 소녀가, 소년이, 노파가, 베개가, 모서리가 곧 시인인 듯했다.\n\n소년 조심해.\n울다가 웃으면 어른이 된다.\n\n시의 내용이 설명적이거나 직관적이진 않는다. 혹은 소녀와 소년의 우주를 이해하기엔 내가 너무나 많이 울다가 웃었을지도 모르겠다.\n다른 누군가의 우주를 이해하기 위해선 깊은 생각이 필요하다. 소년의 우주도 그렇고, 소녀의 우주도 그렇고, 내 건너편에 앉아있는 직원 A의 우주도 그렇다. 이 책은 그런 깊은 생각을 차분히 길러주기 좋은 시집일지 모른다.\n좋은 사람에게서 좋은 시집을 추천받았다. 올해의 첫인상이 좋다."
  }
]